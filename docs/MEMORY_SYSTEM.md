# Sistema de Memoria con ChromaDB

## Descripci√≥n General

DaveAgent utiliza un sistema de memoria vectorial avanzado basado en **ChromaDB** y **sentence-transformers** para mantener contexto persistente a trav√©s de sesiones. Esto permite que los agentes "recuerden" conversaciones anteriores, patrones de c√≥digo, decisiones arquitect√≥nicas y preferencias del usuario.

## Arquitectura de Memoria

El sistema de memoria est√° organizado en **4 colecciones vectoriales**:

### 1. **Conversation Memory** (`conversations`)
- **Prop√≥sito**: Almacenar historial de conversaciones entre el usuario y los agentes
- **Contenido**: Pares de pregunta-respuesta con metadatos
- **Uso**: Permite que los agentes recuerden conversaciones previas y proporcionen respuestas consistentes
- **Metadatos**:
  - `agents_used`: Lista de agentes que participaron
  - `tools_called`: Herramientas utilizadas
  - `interaction_id`: ID √∫nico de la interacci√≥n
  - `model`: Modelo LLM utilizado
  - `provider`: Proveedor del LLM

### 2. **Codebase Memory** (`codebase`)
- **Prop√≥sito**: Indexar el c√≥digo fuente del proyecto para b√∫squedas r√°pidas
- **Contenido**: Chunks de c√≥digo con contexto y metadatos
- **Uso**: Permite b√∫squedas sem√°nticas de c√≥digo sin necesidad de herramientas de grep
- **Metadatos**:
  - `file_path`: Ruta relativa del archivo
  - `language`: Lenguaje de programaci√≥n
  - `chunk_index`: √çndice del chunk dentro del archivo
  - `functions`: Lista de funciones en el chunk
  - `classes`: Lista de clases en el chunk

### 3. **Decision Memory** (`decisions`)
- **Prop√≥sito**: Almacenar decisiones arquitect√≥nicas y patrones de soluci√≥n
- **Contenido**: Decisiones tomadas con contexto y razonamiento
- **Uso**: El PlanningAgent puede consultar decisiones previas para mantener consistencia
- **Metadatos**:
  - `decision_summary`: Resumen de la decisi√≥n
  - `category`: Categor√≠a (architecture, design, implementation)
  - `impact`: Nivel de impacto (low, medium, high)

### 4. **User Preferences Memory** (`preferences`)
- **Prop√≥sito**: Guardar preferencias del usuario (estilo de c√≥digo, frameworks, etc.)
- **Contenido**: Preferencias expl√≠citas e impl√≠citas del usuario
- **Uso**: Todos los agentes tienen acceso para personalizar sus respuestas
- **Metadatos**:
  - `category`: Categor√≠a (code_style, framework, tool, workflow)
  - `priority`: Prioridad (low, normal, high)

## Integraci√≥n con Agentes

### **CodeSearcher**
```python
# Tiene acceso a codebase_memory
memory=[self.memory_manager.codebase_memory]
```
- Puede encontrar c√≥digo relevante mediante b√∫squeda sem√°ntica
- Los resultados de b√∫squeda enriquecen el contexto sin necesidad de herramientas

### **Coder**
```python
# Tiene acceso a m√∫ltiples memorias
memory=[
    self.memory_manager.conversation_memory,  # Conversaciones previas
    self.memory_manager.codebase_memory,      # C√≥digo base
    self.memory_manager.preferences_memory    # Preferencias
]
```
- Puede recordar c√≥mo resolvi√≥ problemas similares antes
- Sigue preferencias de estilo de c√≥digo del usuario
- Tiene contexto del c√≥digo base sin necesidad de leerlo expl√≠citamente

### **PlanningAgent**
```python
# Tiene acceso a decision_memory
memory=[self.memory_manager.decision_memory]
```
- Consulta decisiones arquitect√≥nicas previas
- Mantiene consistencia en la planificaci√≥n
- Evita revertir decisiones ya tomadas

## C√≥mo Funciona

### 1. **Indexaci√≥n Autom√°tica de Conversaciones**
Cada interacci√≥n usuario-agente se guarda autom√°ticamente en `conversation_memory`:

```python
await self.memory_manager.add_conversation(
    user_input="Crear una API REST con FastAPI",
    agent_response="He creado la API con FastAPI...",
    metadata={
        "agents_used": ["Planner", "Coder"],
        "tools_called": ["write_file", "edit_file"]
    }
)
```

### 2. **Indexaci√≥n Manual de C√≥digo Base**
Usa el comando `/index` para indexar tu proyecto:

```bash
DaveAgent> /index
```

Esto:
- Escanea el directorio actual recursivamente
- Ignora patrones comunes (node_modules, .git, etc.)
- Divide archivos en chunks de ~1500 caracteres
- Extrae funciones y clases
- Almacena en `codebase_memory` con embeddings

### 3. **Consulta Autom√°tica en Runtime**
Cuando un agente recibe una tarea, **autom√°ticamente** consulta sus memorias:

```python
# AutoGen maneja esto internamente
# 1. El agente recibe: "Fix the authentication bug"
# 2. La memoria se consulta con la query
# 3. Se recuperan los top-k chunks m√°s relevantes (k=5)
# 4. Se agregan al contexto del agente como SystemMessage
# 5. El agente responde con contexto enriquecido
```

### 4. **Persistencia**
Toda la memoria se guarda en: `~/.daveagent/memory/`

La memoria persiste entre sesiones - no necesitas reindexar cada vez.

## Comandos CLI

### `/index`
Indexa el proyecto actual en memoria vectorial:

```bash
DaveAgent> /index
üìö Indexando proyecto en memoria vectorial...
‚úÖ Indexaci√≥n completada!
  ‚Ä¢ Archivos indexados: 45
  ‚Ä¢ Chunks creados: 234
  ‚Ä¢ Archivos omitidos: 12
```

### `/memory`
Muestra estad√≠sticas de memoria:

```bash
DaveAgent> /memory
üß† Estad√≠sticas de Memoria Vectorial

üìö Sistema de memoria activo con 4 colecciones:
  ‚Ä¢ Conversations: Historial de conversaciones
  ‚Ä¢ Codebase: C√≥digo fuente indexado
  ‚Ä¢ Decisions: Decisiones arquitect√≥nicas
  ‚Ä¢ Preferences: Preferencias del usuario

üíæ Ubicaci√≥n: /home/user/.daveagent/memory
üìä Tama√±o total: 12.34 MB
```

### `/memory clear`
Limpia toda la memoria (requiere confirmaci√≥n):

```bash
DaveAgent> /memory clear
‚ö†Ô∏è  ¬øEst√°s seguro de que quieres borrar TODA la memoria?
Esto eliminar√°:
  ‚Ä¢ Historial de conversaciones
  ‚Ä¢ C√≥digo base indexado
  ‚Ä¢ Decisiones arquitect√≥nicas
  ‚Ä¢ Preferencias del usuario

‚ö†Ô∏è  Para confirmar, ejecuta: /memory clear confirm
```

## Configuraci√≥n

### Par√°metros del MemoryManager

```python
MemoryManager(
    persistence_path=None,  # Defaults to ~/.daveagent/memory
    embedding_model="all-MiniLM-L6-v2",  # Sentence transformer model
    k=5,  # Top-k results to retrieve
    score_threshold=0.3  # Minimum similarity score
)
```

### Par√°metros del DocumentIndexer

```python
DocumentIndexer(
    memory=memory,
    chunk_size=1500,  # Characters per chunk
    ignore_patterns=[  # Patterns to ignore
        "node_modules", ".git", "__pycache__",
        ".venv", "dist", "build"
    ]
)
```

## Modelo de Embeddings

Por defecto, se usa **`all-MiniLM-L6-v2`** de Sentence Transformers:
- R√°pido y ligero (~80MB)
- Buen balance entre velocidad y calidad
- Funciona offline (se descarga en la primera ejecuci√≥n)

### Modelos Alternativos

Puedes cambiar el modelo en `MemoryManager`:

```python
# M√°s preciso pero m√°s lento
embedding_model="all-mpnet-base-v2"

# Multiling√ºe
embedding_model="paraphrase-multilingual-MiniLM-L12-v2"

# Espec√≠fico para c√≥digo
embedding_model="microsoft/codebert-base"
```

## Ejemplos de Uso

### Ejemplo 1: Recordar Decisiones
```bash
User: "Should I use SQLAlchemy or raw SQL for this project?"
Planner: [consulta decision_memory]
Planner: "Based on our previous decision (2024-01-15), we chose
          SQLAlchemy for consistency with other services."
```

### Ejemplo 2: Encontrar C√≥digo Similar
```bash
User: "Create an authentication endpoint"
CodeSearcher: [consulta codebase_memory]
CodeSearcher: "Found similar auth code in api/auth.py:45-78.
               I'll use that pattern for consistency."
```

### Ejemplo 3: Mantener Preferencias
```bash
User: "Always use type hints in Python"
[Se guarda en preferences_memory]

[Sesi√≥n posterior]
Coder: [consulta preferences_memory antes de generar c√≥digo]
Coder: [Genera c√≥digo con type hints autom√°ticamente]
```

## Consideraciones de Rendimiento

### Tama√±o de Memoria
- Cada chunk de c√≥digo: ~2KB
- Embedding por chunk: ~1KB
- 1000 chunks ‚âà 3MB de memoria

### Velocidad de Consulta
- Primera consulta: ~200-500ms (carga del modelo)
- Consultas subsecuentes: ~50-100ms
- Indexaci√≥n: ~1-2 archivos/segundo

### L√≠mites Recomendados
- **Proyectos peque√±os** (<100 archivos): Indexar todo
- **Proyectos medianos** (100-500 archivos): Indexar selectivamente
- **Proyectos grandes** (>500 archivos): Usar `max_files` parameter

## Troubleshooting

### "No module named 'chromadb'"
```bash
pip install -r requirements.txt
```

### "Sentence transformer model download failed"
- Requiere conexi√≥n a internet la primera vez
- El modelo se descarga a `~/.cache/torch/sentence_transformers/`

### "Memory directory not writable"
- Verifica permisos en `~/.daveagent/memory/`
- Cambia `persistence_path` si es necesario

### "Out of memory error"
- Reduce `k` (n√∫mero de resultados)
- Reduce `chunk_size`
- Usa un modelo de embeddings m√°s peque√±o

## Roadmap

Mejoras futuras planeadas:

- [ ] **Memoria de errores**: Recordar errores comunes y soluciones
- [ ] **Memoria de tests**: Patrones de testing exitosos
- [ ] **Memoria de refactorings**: Historial de refactorizaciones
- [ ] **Query h√≠brida**: Combinar b√∫squeda sem√°ntica + keyword search
- [ ] **Reranking**: Mejorar relevancia con cross-encoder
- [ ] **Incremental indexing**: Solo indexar archivos modificados
- [ ] **Memory statistics**: Conteo exacto de documentos por colecci√≥n
- [ ] **Memory export/import**: Compartir memoria entre equipos

## Referencias

- [AutoGen AgentChat Memory](https://microsoft.github.io/autogen/dev/user-guide/agentchat-user-guide/tutorial/memory.html)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Sentence Transformers](https://www.sbert.net/)
