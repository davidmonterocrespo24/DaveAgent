{
  "instance_id": "astropy__astropy-12907",
  "model_patch": "",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-12907",
  "model_patch": "",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-12907",
  "model_patch": "",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-12907",
  "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..6e457cc93a 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -199,6 +199,23 @@ def _coord_matrix(model, pos, noutp):\n         else:\n             mat[-model.n_outputs:, -model.n_inputs:] = m\n         return mat\n+    \n+    # Handle CompoundModel by calling _separable recursively\n+    if isinstance(model, CompoundModel):\n+        # Get the coordinate matrix for the compound model\n+        coord_mat = _separable(model)\n+        # Pad or adjust the matrix based on position\n+        if pos == 'left':\n+            # Place at the beginning\n+            result = np.zeros((noutp, model.n_inputs))\n+            result[:coord_mat.shape[0], :coord_mat.shape[1]] = coord_mat\n+            return result\n+        else:\n+            # Place at the end\n+            result = np.zeros((noutp, model.n_inputs))\n+            result[-coord_mat.shape[0]:, -coord_mat.shape[1]:] = coord_mat\n+            return result\n+    \n     if not model.separable:\n         # this does not work for more than 2 coordinates\n         mat = np.zeros((noutp, model.n_inputs))\n@@ -215,7 +232,6 @@ def _coord_matrix(model, pos, noutp):\n             mat = np.roll(mat, (noutp - model.n_outputs))\n     return mat\n \n-\n def _cstack(left, right):\n     \"\"\"\n     Function corresponding to '&' operation.\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-12907",
  "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..6099f63465 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -242,7 +242,7 @@ def _cstack(left, right):\n         cright = _coord_matrix(right, 'right', noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0]:, -right.shape[1]:] = right\n \n     return np.hstack([cleft, cright])\n \n@@ -314,4 +314,4 @@ def _separable(transform):\n # Maps modeling operators to a function computing and represents the\n # relationship of axes as an array of 0-es and 1-s\n _operators = {'&': _cstack, '|': _cdot, '+': _arith_oper, '-': _arith_oper,\n-              '*': _arith_oper, '/': _arith_oper, '**': _arith_oper}\n+              '*': _arith_oper, '/': _arith_oper, '**': _arith_oper}\n\\ No newline at end of file\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-13033",
  "model_patch": "diff --git a/astropy/timeseries/core.py b/astropy/timeseries/core.py\nindex c279f35f87..8c9ffed6ea 100644\n--- a/astropy/timeseries/core.py\n+++ b/astropy/timeseries/core.py\n@@ -66,24 +66,34 @@ class BaseTimeSeries(QTable):\n             else:\n                 required_columns = self._required_columns\n \n-            plural = 's' if len(required_columns) > 1 else ''\n-\n-            if not self._required_columns_relax and len(self.colnames) == 0:\n-\n-                raise ValueError(\"{} object is invalid - expected '{}' \"\n-                                 \"as the first column{} but time series has no columns\"\n-                                 .format(self.__class__.__name__, required_columns[0], plural))\n-\n-            elif self.colnames[:len(required_columns)] != required_columns:\n-\n+            if not self._required_columns_relax:\n+                # First check if all required columns are present\n+                missing_columns = [col for col in self._required_columns \n+                                  if col not in self.colnames]\n+                if missing_columns:\n+                    plural = 's' if len(missing_columns) > 1 else ''\n+                    raise ValueError(\"{} object is invalid - missing required \"\n+                                     \"column{}: {}\".format(\n+                                         self.__class__.__name__,\n+                                         plural,\n+                                         \", \".join(f\"'{col}'\" for col in missing_columns)\n+                                     ))\n+            \n+            # Then check the order of columns (only check as many as we have)\n+            num_to_check = min(len(required_columns), len(self.colnames))\n+            if self.colnames[:num_to_check] != required_columns[:num_to_check]:\n+                plural = 's' if len(required_columns[:num_to_check]) > 1 else ''\n                 raise ValueError(\"{} object is invalid - expected '{}' \"\n-                                 \"as the first column{} but found '{}'\"\n-                                 .format(self.__class__.__name__, required_columns[0], plural, self.colnames[0]))\n+                                 \"as the first column{} but found '{}'\".format(\n+                                     self.__class__.__name__,\n+                                     required_columns[0],\n+                                     plural,\n+                                     self.colnames[0] if len(self.colnames) > 0 else \"none\"\n+                                 ))\n \n             if (self._required_columns_relax\n                     and self._required_columns == self.colnames[:len(self._required_columns)]):\n                 self._required_columns_relax = False\n-\n     @contextmanager\n     def _delay_required_column_checks(self):\n         self._required_columns_enabled = False\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-13236",
  "model_patch": "diff --git a/astropy/table/table.py b/astropy/table/table.py\nindex 5afe2127a3..8e0adc1203 100644\n--- a/astropy/table/table.py\n+++ b/astropy/table/table.py\n@@ -1244,2729 +1244,4 @@ class Table:\n         if (not isinstance(data, Column) and not data_is_mixin\n                 and isinstance(data, np.ndarray) and len(data.dtype) > 1):\n             data = data.view(NdarrayMixin)\n-            data_is_mixin = True\n-\n-        # Get the final column name using precedence.  Some objects may not\n-        # have an info attribute. Also avoid creating info as a side effect.\n-        if not name:\n-            if isinstance(data, Column):\n-                name = data.name or default_name\n-            elif 'info' in getattr(data, '__dict__', ()):\n-                name = data.info.name or default_name\n-            else:\n-                name = default_name\n-\n-        if isinstance(data, Column):\n-            # If self.ColumnClass is a subclass of col, then \"upgrade\" to ColumnClass,\n-            # otherwise just use the original class.  The most common case is a\n-            # table with masked=True and ColumnClass=MaskedColumn.  Then a Column\n-            # gets upgraded to MaskedColumn, but the converse (pre-4.0) behavior\n-            # of downgrading from MaskedColumn to Column (for non-masked table)\n-            # does not happen.\n-            col_cls = self._get_col_cls_for_table(data)\n-\n-        elif data_is_mixin:\n-            # Copy the mixin column attributes if they exist since the copy below\n-            # may not get this attribute.\n-            col = col_copy(data, copy_indices=self._init_indices) if copy else data\n-            col.info.name = name\n-            return col\n-\n-        elif data0_is_mixin:\n-            # Handle case of a sequence of a mixin, e.g. [1*u.m, 2*u.m].\n-            try:\n-                col = data[0].__class__(data)\n-                col.info.name = name\n-                return col\n-            except Exception:\n-                # If that didn't work for some reason, just turn it into np.array of object\n-                data = np.array(data, dtype=object)\n-                col_cls = self.ColumnClass\n-\n-        elif isinstance(data, (np.ma.MaskedArray, Masked)):\n-            # Require that col_cls be a subclass of MaskedColumn, remembering\n-            # that ColumnClass could be a user-defined subclass (though more-likely\n-            # could be MaskedColumn).\n-            col_cls = masked_col_cls\n-\n-        elif data is None:\n-            # Special case for data passed as the None object (for broadcasting\n-            # to an object column). Need to turn data into numpy `None` scalar\n-            # object, otherwise `Column` interprets data=None as no data instead\n-            # of a object column of `None`.\n-            data = np.array(None)\n-            col_cls = self.ColumnClass\n-\n-        elif not hasattr(data, 'dtype'):\n-            # `data` is none of the above, convert to numpy array or MaskedArray\n-            # assuming only that it is a scalar or sequence or N-d nested\n-            # sequence. This function is relatively intricate and tries to\n-            # maintain performance for common cases while handling things like\n-            # list input with embedded np.ma.masked entries. If `data` is a\n-            # scalar then it gets returned unchanged so the original object gets\n-            # passed to `Column` later.\n-            data = _convert_sequence_data_to_array(data, dtype)\n-            copy = False  # Already made a copy above\n-            col_cls = masked_col_cls if isinstance(data, np.ma.MaskedArray) else self.ColumnClass\n-\n-        else:\n-            col_cls = self.ColumnClass\n-\n-        try:\n-            col = col_cls(name=name, data=data, dtype=dtype,\n-                          copy=copy, copy_indices=self._init_indices)\n-        except Exception:\n-            # Broad exception class since we don't know what might go wrong\n-            raise ValueError('unable to convert data to Column for Table')\n-\n-        col = self._convert_col_for_table(col)\n-\n-        return col\n-\n-    def _init_from_ndarray(self, data, names, dtype, n_cols, copy):\n-        \"\"\"Initialize table from an ndarray structured array\"\"\"\n-\n-        data_names = data.dtype.names or _auto_names(n_cols)\n-        struct = data.dtype.names is not None\n-        names = [name or data_names[i] for i, name in enumerate(names)]\n-\n-        cols = ([data[name] for name in data_names] if struct else\n-                [data[:, i] for i in range(n_cols)])\n-\n-        self._init_from_list(cols, names, dtype, n_cols, copy)\n-\n-    def _init_from_dict(self, data, names, dtype, n_cols, copy):\n-        \"\"\"Initialize table from a dictionary of columns\"\"\"\n-\n-        data_list = [data[name] for name in names]\n-        self._init_from_list(data_list, names, dtype, n_cols, copy)\n-\n-    def _get_col_cls_for_table(self, col):\n-        \"\"\"Get the correct column class to use for upgrading any Column-like object.\n-\n-        For a masked table, ensure any Column-like object is a subclass\n-        of the table MaskedColumn.\n-\n-        For unmasked table, ensure any MaskedColumn-like object is a subclass\n-        of the table MaskedColumn.  If not a MaskedColumn, then ensure that any\n-        Column-like object is a subclass of the table Column.\n-        \"\"\"\n-\n-        col_cls = col.__class__\n-\n-        if self.masked:\n-            if isinstance(col, Column) and not isinstance(col, self.MaskedColumn):\n-                col_cls = self.MaskedColumn\n-        else:\n-            if isinstance(col, MaskedColumn):\n-                if not isinstance(col, self.MaskedColumn):\n-                    col_cls = self.MaskedColumn\n-            elif isinstance(col, Column) and not isinstance(col, self.Column):\n-                col_cls = self.Column\n-\n-        return col_cls\n-\n-    def _convert_col_for_table(self, col):\n-        \"\"\"\n-        Make sure that all Column objects have correct base class for this type of\n-        Table.  For a base Table this most commonly means setting to\n-        MaskedColumn if the table is masked.  Table subclasses like QTable\n-        override this method.\n-        \"\"\"\n-        if isinstance(col, Column) and not isinstance(col, self.ColumnClass):\n-            col_cls = self._get_col_cls_for_table(col)\n-            if col_cls is not col.__class__:\n-                col = col_cls(col, copy=False)\n-\n-        return col\n-\n-    def _init_from_cols(self, cols):\n-        \"\"\"Initialize table from a list of Column or mixin objects\"\"\"\n-\n-        lengths = set(len(col) for col in cols)\n-        if len(lengths) > 1:\n-            raise ValueError(f'Inconsistent data column lengths: {lengths}')\n-\n-        # Make sure that all Column-based objects have correct class.  For\n-        # plain Table this is self.ColumnClass, but for instance QTable will\n-        # convert columns with units to a Quantity mixin.\n-        newcols = [self._convert_col_for_table(col) for col in cols]\n-        self._make_table_from_cols(self, newcols)\n-\n-        # Deduplicate indices.  It may happen that after pickling or when\n-        # initing from an existing table that column indices which had been\n-        # references to a single index object got *copied* into an independent\n-        # object.  This results in duplicates which will cause downstream problems.\n-        index_dict = {}\n-        for col in self.itercols():\n-            for i, index in enumerate(col.info.indices or []):\n-                names = tuple(ind_col.info.name for ind_col in index.columns)\n-                if names in index_dict:\n-                    col.info.indices[i] = index_dict[names]\n-                else:\n-                    index_dict[names] = index\n-\n-    def _new_from_slice(self, slice_):\n-        \"\"\"Create a new table as a referenced slice from self.\"\"\"\n-\n-        table = self.__class__(masked=self.masked)\n-        if self.meta:\n-            table.meta = self.meta.copy()  # Shallow copy for slice\n-        table.primary_key = self.primary_key\n-\n-        newcols = []\n-        for col in self.columns.values():\n-            newcol = col[slice_]\n-\n-            # Note in line below, use direct attribute access to col.indices for Column\n-            # instances instead of the generic col.info.indices.  This saves about 4 usec\n-            # per column.\n-            if (col if isinstance(col, Column) else col.info).indices:\n-                # TODO : as far as I can tell the only purpose of setting _copy_indices\n-                # here is to communicate that to the initial test in `slice_indices`.\n-                # Why isn't that just sent as an arg to the function?\n-                col.info._copy_indices = self._copy_indices\n-                newcol = col.info.slice_indices(newcol, slice_, len(col))\n-\n-                # Don't understand why this is forcing a value on the original column.\n-                # Normally col.info does not even have a _copy_indices attribute.  Tests\n-                # still pass if this line is deleted.  (Each col.info attribute access\n-                # is expensive).\n-                col.info._copy_indices = True\n-\n-            newcols.append(newcol)\n-\n-        self._make_table_from_cols(table, newcols, verify=False, names=self.columns.keys())\n-        return table\n-\n-    @staticmethod\n-    def _make_table_from_cols(table, cols, verify=True, names=None):\n-        \"\"\"\n-        Make ``table`` in-place so that it represents the given list of ``cols``.\n-        \"\"\"\n-        if names is None:\n-            names = [col.info.name for col in cols]\n-\n-        # Note: we do not test for len(names) == len(cols) if names is not None.  In that\n-        # case the function is being called by from \"trusted\" source (e.g. right above here)\n-        # that is assumed to provide valid inputs.  In that case verify=False.\n-\n-        if verify:\n-            if None in names:\n-                raise TypeError('Cannot have None for column name')\n-            if len(set(names)) != len(names):\n-                raise ValueError('Duplicate column names')\n-\n-        table.columns = table.TableColumns((name, col) for name, col in zip(names, cols))\n-\n-        for col in cols:\n-            table._set_col_parent_table_and_mask(col)\n-\n-    def _set_col_parent_table_and_mask(self, col):\n-        \"\"\"\n-        Set ``col.parent_table = self`` and force ``col`` to have ``mask``\n-        attribute if the table is masked and ``col.mask`` does not exist.\n-        \"\"\"\n-        # For Column instances it is much faster to do direct attribute access\n-        # instead of going through .info\n-        col_info = col if isinstance(col, Column) else col.info\n-        col_info.parent_table = self\n-\n-        # Legacy behavior for masked table\n-        if self.masked and not hasattr(col, 'mask'):\n-            col.mask = FalseArray(col.shape)\n-\n-    def itercols(self):\n-        \"\"\"\n-        Iterate over the columns of this table.\n-\n-        Examples\n-        --------\n-\n-        To iterate over the columns of a table::\n-\n-            >>> t = Table([[1], [2]])\n-            >>> for col in t.itercols():\n-            ...     print(col)\n-            col0\n-            ----\n-               1\n-            col1\n-            ----\n-               2\n-\n-        Using ``itercols()`` is similar to  ``for col in t.columns.values()``\n-        but is syntactically preferred.\n-        \"\"\"\n-        for colname in self.columns:\n-            yield self[colname]\n-\n-    def _base_repr_(self, html=False, descr_vals=None, max_width=None,\n-                    tableid=None, show_dtype=True, max_lines=None,\n-                    tableclass=None):\n-        if descr_vals is None:\n-            descr_vals = [self.__class__.__name__]\n-            if self.masked:\n-                descr_vals.append('masked=True')\n-            descr_vals.append(f'length={len(self)}')\n-\n-        descr = ' '.join(descr_vals)\n-        if html:\n-            from astropy.utils.xml.writer import xml_escape\n-            descr = f'<i>{xml_escape(descr)}</i>\\n'\n-        else:\n-            descr = f'<{descr}>\\n'\n-\n-        if tableid is None:\n-            tableid = f'table{id(self)}'\n-\n-        data_lines, outs = self.formatter._pformat_table(\n-            self, tableid=tableid, html=html, max_width=max_width,\n-            show_name=True, show_unit=None, show_dtype=show_dtype,\n-            max_lines=max_lines, tableclass=tableclass)\n-\n-        out = descr + '\\n'.join(data_lines)\n-\n-        return out\n-\n-    def _repr_html_(self):\n-        out = self._base_repr_(html=True, max_width=-1,\n-                               tableclass=conf.default_notebook_table_class)\n-        # Wrap <table> in <div>. This follows the pattern in pandas and allows\n-        # table to be scrollable horizontally in VS Code notebook display.\n-        out = f'<div>{out}</div>'\n-        return out\n-\n-    def __repr__(self):\n-        return self._base_repr_(html=False, max_width=None)\n-\n-    def __str__(self):\n-        return '\\n'.join(self.pformat())\n-\n-    def __bytes__(self):\n-        return str(self).encode('utf-8')\n-\n-    @property\n-    def has_mixin_columns(self):\n-        \"\"\"\n-        True if table has any mixin columns (defined as columns that are not Column\n-        subclasses).\n-        \"\"\"\n-        return any(has_info_class(col, MixinInfo) for col in self.columns.values())\n-\n-    @property\n-    def has_masked_columns(self):\n-        \"\"\"True if table has any ``MaskedColumn`` columns.\n-\n-        This does not check for mixin columns that may have masked values, use the\n-        ``has_masked_values`` property in that case.\n-\n-        \"\"\"\n-        return any(isinstance(col, MaskedColumn) for col in self.itercols())\n-\n-    @property\n-    def has_masked_values(self):\n-        \"\"\"True if column in the table has values which are masked.\n-\n-        This may be relatively slow for large tables as it requires checking the mask\n-        values of each column.\n-        \"\"\"\n-        for col in self.itercols():\n-            if hasattr(col, 'mask') and np.any(col.mask):\n-                return True\n-        else:\n-            return False\n-\n-    def _is_mixin_for_table(self, col):\n-        \"\"\"\n-        Determine if ``col`` should be added to the table directly as\n-        a mixin column.\n-        \"\"\"\n-        if isinstance(col, BaseColumn):\n-            return False\n-\n-        # Is it a mixin but not [Masked]Quantity (which gets converted to\n-        # [Masked]Column with unit set).\n-        return has_info_class(col, MixinInfo) and not has_info_class(col, QuantityInfo)\n-\n-    @format_doc(_pprint_docs)\n-    def pprint(self, max_lines=None, max_width=None, show_name=True,\n-               show_unit=None, show_dtype=False, align=None):\n-        \"\"\"Print a formatted string representation of the table.\n-\n-        If no value of ``max_lines`` is supplied then the height of the\n-        screen terminal is used to set ``max_lines``.  If the terminal\n-        height cannot be determined then the default is taken from the\n-        configuration item ``astropy.conf.max_lines``.  If a negative\n-        value of ``max_lines`` is supplied then there is no line limit\n-        applied.\n-\n-        The same applies for max_width except the configuration item is\n-        ``astropy.conf.max_width``.\n-\n-        \"\"\"\n-        lines, outs = self.formatter._pformat_table(self, max_lines, max_width,\n-                                                    show_name=show_name, show_unit=show_unit,\n-                                                    show_dtype=show_dtype, align=align)\n-        if outs['show_length']:\n-            lines.append(f'Length = {len(self)} rows')\n-\n-        n_header = outs['n_header']\n-\n-        for i, line in enumerate(lines):\n-            if i < n_header:\n-                color_print(line, 'red')\n-            else:\n-                print(line)\n-\n-    @format_doc(_pprint_docs)\n-    def pprint_all(self, max_lines=-1, max_width=-1, show_name=True,\n-                   show_unit=None, show_dtype=False, align=None):\n-        \"\"\"Print a formatted string representation of the entire table.\n-\n-        This method is the same as `astropy.table.Table.pprint` except that\n-        the default ``max_lines`` and ``max_width`` are both -1 so that by\n-        default the entire table is printed instead of restricting to the size\n-        of the screen terminal.\n-\n-        \"\"\"\n-        return self.pprint(max_lines, max_width, show_name,\n-                           show_unit, show_dtype, align)\n-\n-    def _make_index_row_display_table(self, index_row_name):\n-        if index_row_name not in self.columns:\n-            idx_col = self.ColumnClass(name=index_row_name, data=np.arange(len(self)))\n-            return self.__class__([idx_col] + list(self.columns.values()),\n-                                  copy=False)\n-        else:\n-            return self\n-\n-    def show_in_notebook(self, tableid=None, css=None, display_length=50,\n-                         table_class='astropy-default', show_row_index='idx'):\n-        \"\"\"Render the table in HTML and show it in the IPython notebook.\n-\n-        Parameters\n-        ----------\n-        tableid : str or None\n-            An html ID tag for the table.  Default is ``table{id}-XXX``, where\n-            id is the unique integer id of the table object, id(self), and XXX\n-            is a random number to avoid conflicts when printing the same table\n-            multiple times.\n-        table_class : str or None\n-            A string with a list of HTML classes used to style the table.\n-            The special default string ('astropy-default') means that the string\n-            will be retrieved from the configuration item\n-            ``astropy.table.default_notebook_table_class``. Note that these\n-            table classes may make use of bootstrap, as this is loaded with the\n-            notebook.  See `this page <https://getbootstrap.com/css/#tables>`_\n-            for the list of classes.\n-        css : str\n-            A valid CSS string declaring the formatting for the table. Defaults\n-            to ``astropy.table.jsviewer.DEFAULT_CSS_NB``.\n-        display_length : int, optional\n-            Number or rows to show. Defaults to 50.\n-        show_row_index : str or False\n-            If this does not evaluate to False, a column with the given name\n-            will be added to the version of the table that gets displayed.\n-            This new column shows the index of the row in the table itself,\n-            even when the displayed table is re-sorted by another column. Note\n-            that if a column with this name already exists, this option will be\n-            ignored. Defaults to \"idx\".\n-\n-        Notes\n-        -----\n-        Currently, unlike `show_in_browser` (with ``jsviewer=True``), this\n-        method needs to access online javascript code repositories.  This is due\n-        to modern browsers' limitations on accessing local files.  Hence, if you\n-        call this method while offline (and don't have a cached version of\n-        jquery and jquery.dataTables), you will not get the jsviewer features.\n-        \"\"\"\n-\n-        from .jsviewer import JSViewer\n-        from IPython.display import HTML\n-\n-        if tableid is None:\n-            tableid = f'table{id(self)}-{np.random.randint(1, 1e6)}'\n-\n-        jsv = JSViewer(display_length=display_length)\n-        if show_row_index:\n-            display_table = self._make_index_row_display_table(show_row_index)\n-        else:\n-            display_table = self\n-        if table_class == 'astropy-default':\n-            table_class = conf.default_notebook_table_class\n-        html = display_table._base_repr_(html=True, max_width=-1, tableid=tableid,\n-                                         max_lines=-1, show_dtype=False,\n-                                         tableclass=table_class)\n-\n-        columns = display_table.columns.values()\n-        sortable_columns = [i for i, col in enumerate(columns)\n-                            if col.info.dtype.kind in 'iufc']\n-        html += jsv.ipynb(tableid, css=css, sort_columns=sortable_columns)\n-        return HTML(html)\n-\n-    def show_in_browser(self, max_lines=5000, jsviewer=False,\n-                        browser='default', jskwargs={'use_local_files': True},\n-                        tableid=None, table_class=\"display compact\",\n-                        css=None, show_row_index='idx'):\n-        \"\"\"Render the table in HTML and show it in a web browser.\n-\n-        Parameters\n-        ----------\n-        max_lines : int\n-            Maximum number of rows to export to the table (set low by default\n-            to avoid memory issues, since the browser view requires duplicating\n-            the table in memory).  A negative value of ``max_lines`` indicates\n-            no row limit.\n-        jsviewer : bool\n-            If `True`, prepends some javascript headers so that the table is\n-            rendered as a `DataTables <https://datatables.net>`_ data table.\n-            This allows in-browser searching & sorting.\n-        browser : str\n-            Any legal browser name, e.g. ``'firefox'``, ``'chrome'``,\n-            ``'safari'`` (for mac, you may need to use ``'open -a\n-            \"/Applications/Google Chrome.app\" {}'`` for Chrome).  If\n-            ``'default'``, will use the system default browser.\n-        jskwargs : dict\n-            Passed to the `astropy.table.JSViewer` init. Defaults to\n-            ``{'use_local_files': True}`` which means that the JavaScript\n-            libraries will be served from local copies.\n-        tableid : str or None\n-            An html ID tag for the table.  Default is ``table{id}``, where id\n-            is the unique integer id of the table object, id(self).\n-        table_class : str or None\n-            A string with a list of HTML classes used to style the table.\n-            Default is \"display compact\", and other possible values can be\n-            found in https://www.datatables.net/manual/styling/classes\n-        css : str\n-            A valid CSS string declaring the formatting for the table. Defaults\n-            to ``astropy.table.jsviewer.DEFAULT_CSS``.\n-        show_row_index : str or False\n-            If this does not evaluate to False, a column with the given name\n-            will be added to the version of the table that gets displayed.\n-            This new column shows the index of the row in the table itself,\n-            even when the displayed table is re-sorted by another column. Note\n-            that if a column with this name already exists, this option will be\n-            ignored. Defaults to \"idx\".\n-        \"\"\"\n-\n-        import os\n-        import webbrowser\n-        import tempfile\n-        from .jsviewer import DEFAULT_CSS\n-        from urllib.parse import urljoin\n-        from urllib.request import pathname2url\n-\n-        if css is None:\n-            css = DEFAULT_CSS\n-\n-        # We can't use NamedTemporaryFile here because it gets deleted as\n-        # soon as it gets garbage collected.\n-        tmpdir = tempfile.mkdtemp()\n-        path = os.path.join(tmpdir, 'table.html')\n-\n-        with open(path, 'w') as tmp:\n-            if jsviewer:\n-                if show_row_index:\n-                    display_table = self._make_index_row_display_table(show_row_index)\n-                else:\n-                    display_table = self\n-                display_table.write(tmp, format='jsviewer', css=css,\n-                                    max_lines=max_lines, jskwargs=jskwargs,\n-                                    table_id=tableid, table_class=table_class)\n-            else:\n-                self.write(tmp, format='html')\n-\n-        try:\n-            br = webbrowser.get(None if browser == 'default' else browser)\n-        except webbrowser.Error:\n-            log.error(f\"Browser '{browser}' not found.\")\n-        else:\n-            br.open(urljoin('file:', pathname2url(path)))\n-\n-    @format_doc(_pformat_docs, id=\"{id}\")\n-    def pformat(self, max_lines=None, max_width=None, show_name=True,\n-                show_unit=None, show_dtype=False, html=False, tableid=None,\n-                align=None, tableclass=None):\n-        \"\"\"Return a list of lines for the formatted string representation of\n-        the table.\n-\n-        If no value of ``max_lines`` is supplied then the height of the\n-        screen terminal is used to set ``max_lines``.  If the terminal\n-        height cannot be determined then the default is taken from the\n-        configuration item ``astropy.conf.max_lines``.  If a negative\n-        value of ``max_lines`` is supplied then there is no line limit\n-        applied.\n-\n-        The same applies for ``max_width`` except the configuration item  is\n-        ``astropy.conf.max_width``.\n-\n-        \"\"\"\n-\n-        lines, outs = self.formatter._pformat_table(\n-            self, max_lines, max_width, show_name=show_name,\n-            show_unit=show_unit, show_dtype=show_dtype, html=html,\n-            tableid=tableid, tableclass=tableclass, align=align)\n-\n-        if outs['show_length']:\n-            lines.append(f'Length = {len(self)} rows')\n-\n-        return lines\n-\n-    @format_doc(_pformat_docs, id=\"{id}\")\n-    def pformat_all(self, max_lines=-1, max_width=-1, show_name=True,\n-                    show_unit=None, show_dtype=False, html=False, tableid=None,\n-                    align=None, tableclass=None):\n-        \"\"\"Return a list of lines for the formatted string representation of\n-        the entire table.\n-\n-        If no value of ``max_lines`` is supplied then the height of the\n-        screen terminal is used to set ``max_lines``.  If the terminal\n-        height cannot be determined then the default is taken from the\n-        configuration item ``astropy.conf.max_lines``.  If a negative\n-        value of ``max_lines`` is supplied then there is no line limit\n-        applied.\n-\n-        The same applies for ``max_width`` except the configuration item  is\n-        ``astropy.conf.max_width``.\n-\n-        \"\"\"\n-\n-        return self.pformat(max_lines, max_width, show_name,\n-                            show_unit, show_dtype, html, tableid,\n-                            align, tableclass)\n-\n-    def more(self, max_lines=None, max_width=None, show_name=True,\n-             show_unit=None, show_dtype=False):\n-        \"\"\"Interactively browse table with a paging interface.\n-\n-        Supported keys::\n-\n-          f, <space> : forward one page\n-          b : back one page\n-          r : refresh same page\n-          n : next row\n-          p : previous row\n-          < : go to beginning\n-          > : go to end\n-          q : quit browsing\n-          h : print this help\n-\n-        Parameters\n-        ----------\n-        max_lines : int\n-            Maximum number of lines in table output\n-\n-        max_width : int or None\n-            Maximum character width of output\n-\n-        show_name : bool\n-            Include a header row for column names. Default is True.\n-\n-        show_unit : bool\n-            Include a header row for unit.  Default is to show a row\n-            for units only if one or more columns has a defined value\n-            for the unit.\n-\n-        show_dtype : bool\n-            Include a header row for column dtypes. Default is False.\n-        \"\"\"\n-        self.formatter._more_tabcol(self, max_lines, max_width, show_name=show_name,\n-                                    show_unit=show_unit, show_dtype=show_dtype)\n-\n-    def __getitem__(self, item):\n-        if isinstance(item, str):\n-            return self.columns[item]\n-        elif isinstance(item, (int, np.integer)):\n-            return self.Row(self, item)\n-        elif (isinstance(item, np.ndarray) and item.shape == () and item.dtype.kind == 'i'):\n-            return self.Row(self, item.item())\n-        elif self._is_list_or_tuple_of_str(item):\n-            out = self.__class__([self[x] for x in item],\n-                                 copy_indices=self._copy_indices)\n-            out._groups = groups.TableGroups(out, indices=self.groups._indices,\n-                                             keys=self.groups._keys)\n-            out.meta = self.meta.copy()  # Shallow copy for meta\n-            return out\n-        elif ((isinstance(item, np.ndarray) and item.size == 0)\n-              or (isinstance(item, (tuple, list)) and not item)):\n-            # If item is an empty array/list/tuple then return the table with no rows\n-            return self._new_from_slice([])\n-        elif (isinstance(item, slice)\n-              or isinstance(item, np.ndarray)\n-              or isinstance(item, list)\n-              or isinstance(item, tuple) and all(isinstance(x, np.ndarray)\n-                                                 for x in item)):\n-            # here for the many ways to give a slice; a tuple of ndarray\n-            # is produced by np.where, as in t[np.where(t['a'] > 2)]\n-            # For all, a new table is constructed with slice of all columns\n-            return self._new_from_slice(item)\n-        else:\n-            raise ValueError(f'Illegal type {type(item)} for table item access')\n-\n-    def __setitem__(self, item, value):\n-        # If the item is a string then it must be the name of a column.\n-        # If that column doesn't already exist then create it now.\n-        if isinstance(item, str) and item not in self.colnames:\n-            self.add_column(value, name=item, copy=True)\n-\n-        else:\n-            n_cols = len(self.columns)\n-\n-            if isinstance(item, str):\n-                # Set an existing column by first trying to replace, and if\n-                # this fails do an in-place update.  See definition of mask\n-                # property for discussion of the _setitem_inplace attribute.\n-                if (not getattr(self, '_setitem_inplace', False)\n-                        and not conf.replace_inplace):\n-                    try:\n-                        self._replace_column_warnings(item, value)\n-                        return\n-                    except Exception:\n-                        pass\n-                self.columns[item][:] = value\n-\n-            elif isinstance(item, (int, np.integer)):\n-                self._set_row(idx=item, colnames=self.colnames, vals=value)\n-\n-            elif (isinstance(item, slice)\n-                  or isinstance(item, np.ndarray)\n-                  or isinstance(item, list)\n-                  or (isinstance(item, tuple)  # output from np.where\n-                      and all(isinstance(x, np.ndarray) for x in item))):\n-\n-                if isinstance(value, Table):\n-                    vals = (col for col in value.columns.values())\n-\n-                elif isinstance(value, np.ndarray) and value.dtype.names:\n-                    vals = (value[name] for name in value.dtype.names)\n-\n-                elif np.isscalar(value):\n-                    vals = itertools.repeat(value, n_cols)\n-\n-                else:  # Assume this is an iterable that will work\n-                    if len(value) != n_cols:\n-                        raise ValueError('Right side value needs {} elements (one for each column)'\n-                                         .format(n_cols))\n-                    vals = value\n-\n-                for col, val in zip(self.columns.values(), vals):\n-                    col[item] = val\n-\n-            else:\n-                raise ValueError(f'Illegal type {type(item)} for table item access')\n-\n-    def __delitem__(self, item):\n-        if isinstance(item, str):\n-            self.remove_column(item)\n-        elif isinstance(item, (int, np.integer)):\n-            self.remove_row(item)\n-        elif (isinstance(item, (list, tuple, np.ndarray))\n-              and all(isinstance(x, str) for x in item)):\n-            self.remove_columns(item)\n-        elif (isinstance(item, (list, np.ndarray))\n-              and np.asarray(item).dtype.kind == 'i'):\n-            self.remove_rows(item)\n-        elif isinstance(item, slice):\n-            self.remove_rows(item)\n-        else:\n-            raise IndexError('illegal key or index value')\n-\n-    def _ipython_key_completions_(self):\n-        return self.colnames\n-\n-    def field(self, item):\n-        \"\"\"Return column[item] for recarray compatibility.\"\"\"\n-        return self.columns[item]\n-\n-    @property\n-    def masked(self):\n-        return self._masked\n-\n-    @masked.setter\n-    def masked(self, masked):\n-        raise Exception('Masked attribute is read-only (use t = Table(t, masked=True)'\n-                        ' to convert to a masked table)')\n-\n-    def _set_masked(self, masked):\n-        \"\"\"\n-        Set the table masked property.\n-\n-        Parameters\n-        ----------\n-        masked : bool\n-            State of table masking (`True` or `False`)\n-        \"\"\"\n-        if masked in [True, False, None]:\n-            self._masked = masked\n-        else:\n-            raise ValueError(\"masked should be one of True, False, None\")\n-\n-        self._column_class = self.MaskedColumn if self._masked else self.Column\n-\n-    @property\n-    def ColumnClass(self):\n-        if self._column_class is None:\n-            return self.Column\n-        else:\n-            return self._column_class\n-\n-    @property\n-    def dtype(self):\n-        return np.dtype([descr(col) for col in self.columns.values()])\n-\n-    @property\n-    def colnames(self):\n-        return list(self.columns.keys())\n-\n-    @staticmethod\n-    def _is_list_or_tuple_of_str(names):\n-        \"\"\"Check that ``names`` is a tuple or list of strings\"\"\"\n-        return (isinstance(names, (tuple, list)) and names\n-                and all(isinstance(x, str) for x in names))\n-\n-    def keys(self):\n-        return list(self.columns.keys())\n-\n-    def values(self):\n-        return self.columns.values()\n-\n-    def items(self):\n-        return self.columns.items()\n-\n-    def __len__(self):\n-        # For performance reasons (esp. in Row) cache the first column name\n-        # and use that subsequently for the table length.  If might not be\n-        # available yet or the column might be gone now, in which case\n-        # try again in the except block.\n-        try:\n-            return len(OrderedDict.__getitem__(self.columns, self._first_colname))\n-        except (AttributeError, KeyError):\n-            if len(self.columns) == 0:\n-                return 0\n-\n-            # Get the first column name\n-            self._first_colname = next(iter(self.columns))\n-            return len(self.columns[self._first_colname])\n-\n-    def index_column(self, name):\n-        \"\"\"\n-        Return the positional index of column ``name``.\n-\n-        Parameters\n-        ----------\n-        name : str\n-            column name\n-\n-        Returns\n-        -------\n-        index : int\n-            Positional index of column ``name``.\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b' and 'c'::\n-\n-            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n-            ...           names=('a', 'b', 'c'))\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1 0.1   x\n-              2 0.2   y\n-              3 0.3   z\n-\n-        Get index of column 'b' of the table::\n-\n-            >>> t.index_column('b')\n-            1\n-        \"\"\"\n-        try:\n-            return self.colnames.index(name)\n-        except ValueError:\n-            raise ValueError(f\"Column {name} does not exist\")\n-\n-    def add_column(self, col, index=None, name=None, rename_duplicate=False, copy=True,\n-                   default_name=None):\n-        \"\"\"\n-        Add a new column to the table using ``col`` as input.  If ``index``\n-        is supplied then insert column before ``index`` position\n-        in the list of columns, otherwise append column to the end\n-        of the list.\n-\n-        The ``col`` input can be any data object which is acceptable as a\n-        `~astropy.table.Table` column object or can be converted.  This includes\n-        mixin columns and scalar or length=1 objects which get broadcast to match\n-        the table length.\n-\n-        To add several columns at once use ``add_columns()`` or simply call\n-        ``add_column()`` for each one.  There is very little performance difference\n-        in the two approaches.\n-\n-        Parameters\n-        ----------\n-        col : object\n-            Data object for the new column\n-        index : int or None\n-            Insert column before this position or at end (default).\n-        name : str\n-            Column name\n-        rename_duplicate : bool\n-            Uniquify column name if it already exist. Default is False.\n-        copy : bool\n-            Make a copy of the new column. Default is True.\n-        default_name : str or None\n-            Name to use if both ``name`` and ``col.info.name`` are not available.\n-            Defaults to ``col{number_of_columns}``.\n-\n-        Examples\n-        --------\n-        Create a table with two columns 'a' and 'b', then create a third column 'c'\n-        and append it to the end of the table::\n-\n-            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n-            >>> col_c = Column(name='c', data=['x', 'y'])\n-            >>> t.add_column(col_c)\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1 0.1   x\n-              2 0.2   y\n-\n-        Add column 'd' at position 1. Note that the column is inserted\n-        before the given index::\n-\n-            >>> t.add_column(['a', 'b'], name='d', index=1)\n-            >>> print(t)\n-             a   d   b   c\n-            --- --- --- ---\n-              1   a 0.1   x\n-              2   b 0.2   y\n-\n-        Add second column named 'b' with rename_duplicate::\n-\n-            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n-            >>> t.add_column(1.1, name='b', rename_duplicate=True)\n-            >>> print(t)\n-             a   b  b_1\n-            --- --- ---\n-              1 0.1 1.1\n-              2 0.2 1.1\n-\n-        Add an unnamed column or mixin object in the table using a default name\n-        or by specifying an explicit name with ``name``. Name can also be overridden::\n-\n-            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n-            >>> t.add_column(['a', 'b'])\n-            >>> t.add_column(col_c, name='d')\n-            >>> print(t)\n-             a   b  col2  d\n-            --- --- ---- ---\n-              1 0.1    a   x\n-              2 0.2    b   y\n-        \"\"\"\n-        if default_name is None:\n-            default_name = f'col{len(self.columns)}'\n-\n-        # Convert col data to acceptable object for insertion into self.columns.\n-        # Note that along with the lines above and below, this allows broadcasting\n-        # of scalars to the correct shape for adding to table.\n-        col = self._convert_data_to_col(col, name=name, copy=copy,\n-                                        default_name=default_name)\n-\n-        # Assigning a scalar column to an empty table should result in an\n-        # exception (see #3811).\n-        if col.shape == () and len(self) == 0:\n-            raise TypeError('Empty table cannot have column set to scalar value')\n-        # Make col data shape correct for scalars.  The second test is to allow\n-        # broadcasting an N-d element to a column, e.g. t['new'] = [[1, 2]].\n-        elif (col.shape == () or col.shape[0] == 1) and len(self) > 0:\n-            new_shape = (len(self),) + getattr(col, 'shape', ())[1:]\n-            if isinstance(col, np.ndarray):\n-                col = np.broadcast_to(col, shape=new_shape,\n-                                      subok=True)\n-            elif isinstance(col, ShapedLikeNDArray):\n-                col = col._apply(np.broadcast_to, shape=new_shape,\n-                                 subok=True)\n-\n-            # broadcast_to() results in a read-only array.  Apparently it only changes\n-            # the view to look like the broadcasted array.  So copy.\n-            col = col_copy(col)\n-\n-        name = col.info.name\n-\n-        # Ensure that new column is the right length\n-        if len(self.columns) > 0 and len(col) != len(self):\n-            raise ValueError('Inconsistent data column lengths')\n-\n-        if rename_duplicate:\n-            orig_name = name\n-            i = 1\n-            while name in self.columns:\n-                # Iterate until a unique name is found\n-                name = orig_name + '_' + str(i)\n-                i += 1\n-            col.info.name = name\n-\n-        # Set col parent_table weakref and ensure col has mask attribute if table.masked\n-        self._set_col_parent_table_and_mask(col)\n-\n-        # Add new column as last column\n-        self.columns[name] = col\n-\n-        if index is not None:\n-            # Move the other cols to the right of the new one\n-            move_names = self.colnames[index:-1]\n-            for move_name in move_names:\n-                self.columns.move_to_end(move_name, last=True)\n-\n-    def add_columns(self, cols, indexes=None, names=None, copy=True, rename_duplicate=False):\n-        \"\"\"\n-        Add a list of new columns the table using ``cols`` data objects.  If a\n-        corresponding list of ``indexes`` is supplied then insert column\n-        before each ``index`` position in the *original* list of columns,\n-        otherwise append columns to the end of the list.\n-\n-        The ``cols`` input can include any data objects which are acceptable as\n-        `~astropy.table.Table` column objects or can be converted.  This includes\n-        mixin columns and scalar or length=1 objects which get broadcast to match\n-        the table length.\n-\n-        From a performance perspective there is little difference between calling\n-        this method once or looping over the new columns and calling ``add_column()``\n-        for each column.\n-\n-        Parameters\n-        ----------\n-        cols : list of object\n-            List of data objects for the new columns\n-        indexes : list of int or None\n-            Insert column before this position or at end (default).\n-        names : list of str\n-            Column names\n-        copy : bool\n-            Make a copy of the new columns. Default is True.\n-        rename_duplicate : bool\n-            Uniquify new column names if they duplicate the existing ones.\n-            Default is False.\n-\n-        See Also\n-        --------\n-        astropy.table.hstack, update, replace_column\n-\n-        Examples\n-        --------\n-        Create a table with two columns 'a' and 'b', then create columns 'c' and 'd'\n-        and append them to the end of the table::\n-\n-            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n-            >>> col_c = Column(name='c', data=['x', 'y'])\n-            >>> col_d = Column(name='d', data=['u', 'v'])\n-            >>> t.add_columns([col_c, col_d])\n-            >>> print(t)\n-             a   b   c   d\n-            --- --- --- ---\n-              1 0.1   x   u\n-              2 0.2   y   v\n-\n-        Add column 'c' at position 0 and column 'd' at position 1. Note that\n-        the columns are inserted before the given position::\n-\n-            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n-            >>> t.add_columns([['x', 'y'], ['u', 'v']], names=['c', 'd'],\n-            ...               indexes=[0, 1])\n-            >>> print(t)\n-             c   a   d   b\n-            --- --- --- ---\n-              x   1   u 0.1\n-              y   2   v 0.2\n-\n-        Add second column 'b' and column 'c' with ``rename_duplicate``::\n-\n-            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n-            >>> t.add_columns([[1.1, 1.2], ['x', 'y']], names=('b', 'c'),\n-            ...               rename_duplicate=True)\n-            >>> print(t)\n-             a   b  b_1  c\n-            --- --- --- ---\n-              1 0.1 1.1  x\n-              2 0.2 1.2  y\n-\n-        Add unnamed columns or mixin objects in the table using default names\n-        or by specifying explicit names with ``names``. Names can also be overridden::\n-\n-            >>> t = Table()\n-            >>> col_b = Column(name='b', data=['u', 'v'])\n-            >>> t.add_columns([[1, 2], col_b])\n-            >>> t.add_columns([[3, 4], col_b], names=['c', 'd'])\n-            >>> print(t)\n-            col0  b   c   d\n-            ---- --- --- ---\n-               1   u   3   u\n-               2   v   4   v\n-        \"\"\"\n-        if indexes is None:\n-            indexes = [len(self.columns)] * len(cols)\n-        elif len(indexes) != len(cols):\n-            raise ValueError('Number of indexes must match number of cols')\n-\n-        if names is None:\n-            names = (None,) * len(cols)\n-        elif len(names) != len(cols):\n-            raise ValueError('Number of names must match number of cols')\n-\n-        default_names = [f'col{ii + len(self.columns)}'\n-                         for ii in range(len(cols))]\n-\n-        for ii in reversed(np.argsort(indexes)):\n-            self.add_column(cols[ii], index=indexes[ii], name=names[ii],\n-                            default_name=default_names[ii],\n-                            rename_duplicate=rename_duplicate, copy=copy)\n-\n-    def _replace_column_warnings(self, name, col):\n-        \"\"\"\n-        Same as replace_column but issues warnings under various circumstances.\n-        \"\"\"\n-        warns = conf.replace_warnings\n-        refcount = None\n-        old_col = None\n-\n-        if 'refcount' in warns and name in self.colnames:\n-            refcount = sys.getrefcount(self[name])\n-\n-        if name in self.colnames:\n-            old_col = self[name]\n-\n-        # This may raise an exception (e.g. t['a'] = 1) in which case none of\n-        # the downstream code runs.\n-        self.replace_column(name, col)\n-\n-        if 'always' in warns:\n-            warnings.warn(f\"replaced column '{name}'\",\n-                          TableReplaceWarning, stacklevel=3)\n-\n-        if 'slice' in warns:\n-            try:\n-                # Check for ndarray-subclass slice.  An unsliced instance\n-                # has an ndarray for the base while sliced has the same class\n-                # as parent.\n-                if isinstance(old_col.base, old_col.__class__):\n-                    msg = (\"replaced column '{}' which looks like an array slice. \"\n-                           \"The new column no longer shares memory with the \"\n-                           \"original array.\".format(name))\n-                    warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n-            except AttributeError:\n-                pass\n-\n-        if 'refcount' in warns:\n-            # Did reference count change?\n-            new_refcount = sys.getrefcount(self[name])\n-            if refcount != new_refcount:\n-                msg = (\"replaced column '{}' and the number of references \"\n-                       \"to the column changed.\".format(name))\n-                warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n-\n-        if 'attributes' in warns:\n-            # Any of the standard column attributes changed?\n-            changed_attrs = []\n-            new_col = self[name]\n-            # Check base DataInfo attributes that any column will have\n-            for attr in DataInfo.attr_names:\n-                if getattr(old_col.info, attr) != getattr(new_col.info, attr):\n-                    changed_attrs.append(attr)\n-\n-            if changed_attrs:\n-                msg = (\"replaced column '{}' and column attributes {} changed.\"\n-                       .format(name, changed_attrs))\n-                warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n-\n-    def replace_column(self, name, col, copy=True):\n-        \"\"\"\n-        Replace column ``name`` with the new ``col`` object.\n-\n-        The behavior of ``copy`` for Column objects is:\n-        - copy=True: new class instance with a copy of data and deep copy of meta\n-        - copy=False: new class instance with same data and a key-only copy of meta\n-\n-        For mixin columns:\n-        - copy=True: new class instance with copy of data and deep copy of meta\n-        - copy=False: original instance (no copy at all)\n-\n-        Parameters\n-        ----------\n-        name : str\n-            Name of column to replace\n-        col : `~astropy.table.Column` or `~numpy.ndarray` or sequence\n-            New column object to replace the existing column.\n-        copy : bool\n-            Make copy of the input ``col``, default=True\n-\n-        See Also\n-        --------\n-        add_columns, astropy.table.hstack, update\n-\n-        Examples\n-        --------\n-        Replace column 'a' with a float version of itself::\n-\n-            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3]], names=('a', 'b'))\n-            >>> float_a = t['a'].astype(float)\n-            >>> t.replace_column('a', float_a)\n-        \"\"\"\n-        if name not in self.colnames:\n-            raise ValueError(f'column name {name} is not in the table')\n-\n-        if self[name].info.indices:\n-            raise ValueError('cannot replace a table index column')\n-\n-        col = self._convert_data_to_col(col, name=name, copy=copy)\n-        self._set_col_parent_table_and_mask(col)\n-\n-        # Ensure that new column is the right length, unless it is the only column\n-        # in which case re-sizing is allowed.\n-        if len(self.columns) > 1 and len(col) != len(self[name]):\n-            raise ValueError('length of new column must match table length')\n-\n-        self.columns.__setitem__(name, col, validated=True)\n-\n-    def remove_row(self, index):\n-        \"\"\"\n-        Remove a row from the table.\n-\n-        Parameters\n-        ----------\n-        index : int\n-            Index of row to remove\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b' and 'c'::\n-\n-            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n-            ...           names=('a', 'b', 'c'))\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1 0.1   x\n-              2 0.2   y\n-              3 0.3   z\n-\n-        Remove row 1 from the table::\n-\n-            >>> t.remove_row(1)\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1 0.1   x\n-              3 0.3   z\n-\n-        To remove several rows at the same time use remove_rows.\n-        \"\"\"\n-        # check the index against the types that work with np.delete\n-        if not isinstance(index, (int, np.integer)):\n-            raise TypeError(\"Row index must be an integer\")\n-        self.remove_rows(index)\n-\n-    def remove_rows(self, row_specifier):\n-        \"\"\"\n-        Remove rows from the table.\n-\n-        Parameters\n-        ----------\n-        row_specifier : slice or int or array of int\n-            Specification for rows to remove\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b' and 'c'::\n-\n-            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n-            ...           names=('a', 'b', 'c'))\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1 0.1   x\n-              2 0.2   y\n-              3 0.3   z\n-\n-        Remove rows 0 and 2 from the table::\n-\n-            >>> t.remove_rows([0, 2])\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              2 0.2   y\n-\n-\n-        Note that there are no warnings if the slice operator extends\n-        outside the data::\n-\n-            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n-            ...           names=('a', 'b', 'c'))\n-            >>> t.remove_rows(slice(10, 20, 1))\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1 0.1   x\n-              2 0.2   y\n-              3 0.3   z\n-        \"\"\"\n-        # Update indices\n-        for index in self.indices:\n-            index.remove_rows(row_specifier)\n-\n-        keep_mask = np.ones(len(self), dtype=bool)\n-        keep_mask[row_specifier] = False\n-\n-        columns = self.TableColumns()\n-        for name, col in self.columns.items():\n-            newcol = col[keep_mask]\n-            newcol.info.parent_table = self\n-            columns[name] = newcol\n-\n-        self._replace_cols(columns)\n-\n-        # Revert groups to default (ungrouped) state\n-        if hasattr(self, '_groups'):\n-            del self._groups\n-\n-    def iterrows(self, *names):\n-        \"\"\"\n-        Iterate over rows of table returning a tuple of values for each row.\n-\n-        This method is especially useful when only a subset of columns are needed.\n-\n-        The ``iterrows`` method can be substantially faster than using the standard\n-        Table row iteration (e.g. ``for row in tbl:``), since that returns a new\n-        ``~astropy.table.Row`` object for each row and accessing a column in that\n-        row (e.g. ``row['col0']``) is slower than tuple access.\n-\n-        Parameters\n-        ----------\n-        names : list\n-            List of column names (default to all columns if no names provided)\n-\n-        Returns\n-        -------\n-        rows : iterable\n-            Iterator returns tuples of row values\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b' and 'c'::\n-\n-            >>> t = Table({'a': [1, 2, 3],\n-            ...            'b': [1.0, 2.5, 3.0],\n-            ...            'c': ['x', 'y', 'z']})\n-\n-        To iterate row-wise using column names::\n-\n-            >>> for a, c in t.iterrows('a', 'c'):\n-            ...     print(a, c)\n-            1 x\n-            2 y\n-            3 z\n-\n-        \"\"\"\n-        if len(names) == 0:\n-            names = self.colnames\n-        else:\n-            for name in names:\n-                if name not in self.colnames:\n-                    raise ValueError(f'{name} is not a valid column name')\n-\n-        cols = (self[name] for name in names)\n-        out = zip(*cols)\n-        return out\n-\n-    def _set_of_names_in_colnames(self, names):\n-        \"\"\"Return ``names`` as a set if valid, or raise a `KeyError`.\n-\n-        ``names`` is valid if all elements in it are in ``self.colnames``.\n-        If ``names`` is a string then it is interpreted as a single column\n-        name.\n-        \"\"\"\n-        names = {names} if isinstance(names, str) else set(names)\n-        invalid_names = names.difference(self.colnames)\n-        if len(invalid_names) == 1:\n-            raise KeyError(f'column \"{invalid_names.pop()}\" does not exist')\n-        elif len(invalid_names) > 1:\n-            raise KeyError(f'columns {invalid_names} do not exist')\n-        return names\n-\n-    def remove_column(self, name):\n-        \"\"\"\n-        Remove a column from the table.\n-\n-        This can also be done with::\n-\n-          del table[name]\n-\n-        Parameters\n-        ----------\n-        name : str\n-            Name of column to remove\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b' and 'c'::\n-\n-            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n-            ...           names=('a', 'b', 'c'))\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1 0.1   x\n-              2 0.2   y\n-              3 0.3   z\n-\n-        Remove column 'b' from the table::\n-\n-            >>> t.remove_column('b')\n-            >>> print(t)\n-             a   c\n-            --- ---\n-              1   x\n-              2   y\n-              3   z\n-\n-        To remove several columns at the same time use remove_columns.\n-        \"\"\"\n-\n-        self.remove_columns([name])\n-\n-    def remove_columns(self, names):\n-        '''\n-        Remove several columns from the table.\n-\n-        Parameters\n-        ----------\n-        names : str or iterable of str\n-            Names of the columns to remove\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b' and 'c'::\n-\n-            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n-            ...     names=('a', 'b', 'c'))\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1 0.1   x\n-              2 0.2   y\n-              3 0.3   z\n-\n-        Remove columns 'b' and 'c' from the table::\n-\n-            >>> t.remove_columns(['b', 'c'])\n-            >>> print(t)\n-             a\n-            ---\n-              1\n-              2\n-              3\n-\n-        Specifying only a single column also works. Remove column 'b' from the table::\n-\n-            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n-            ...     names=('a', 'b', 'c'))\n-            >>> t.remove_columns('b')\n-            >>> print(t)\n-             a   c\n-            --- ---\n-              1   x\n-              2   y\n-              3   z\n-\n-        This gives the same as using remove_column.\n-        '''\n-        for name in self._set_of_names_in_colnames(names):\n-            self.columns.pop(name)\n-\n-    def _convert_string_dtype(self, in_kind, out_kind, encode_decode_func):\n-        \"\"\"\n-        Convert string-like columns to/from bytestring and unicode (internal only).\n-\n-        Parameters\n-        ----------\n-        in_kind : str\n-            Input dtype.kind\n-        out_kind : str\n-            Output dtype.kind\n-        \"\"\"\n-\n-        for col in self.itercols():\n-            if col.dtype.kind == in_kind:\n-                try:\n-                    # This requires ASCII and is faster by a factor of up to ~8, so\n-                    # try that first.\n-                    newcol = col.__class__(col, dtype=out_kind)\n-                except (UnicodeEncodeError, UnicodeDecodeError):\n-                    newcol = col.__class__(encode_decode_func(col, 'utf-8'))\n-\n-                    # Quasi-manually copy info attributes.  Unfortunately\n-                    # DataInfo.__set__ does not do the right thing in this case\n-                    # so newcol.info = col.info does not get the old info attributes.\n-                    for attr in col.info.attr_names - col.info._attrs_no_copy - set(['dtype']):\n-                        value = deepcopy(getattr(col.info, attr))\n-                        setattr(newcol.info, attr, value)\n-\n-                self[col.name] = newcol\n-\n-    def convert_bytestring_to_unicode(self):\n-        \"\"\"\n-        Convert bytestring columns (dtype.kind='S') to unicode (dtype.kind='U')\n-        using UTF-8 encoding.\n-\n-        Internally this changes string columns to represent each character\n-        in the string with a 4-byte UCS-4 equivalent, so it is inefficient\n-        for memory but allows scripts to manipulate string arrays with\n-        natural syntax.\n-        \"\"\"\n-        self._convert_string_dtype('S', 'U', np.char.decode)\n-\n-    def convert_unicode_to_bytestring(self):\n-        \"\"\"\n-        Convert unicode columns (dtype.kind='U') to bytestring (dtype.kind='S')\n-        using UTF-8 encoding.\n-\n-        When exporting a unicode string array to a file, it may be desirable\n-        to encode unicode columns as bytestrings.\n-        \"\"\"\n-        self._convert_string_dtype('U', 'S', np.char.encode)\n-\n-    def keep_columns(self, names):\n-        '''\n-        Keep only the columns specified (remove the others).\n-\n-        Parameters\n-        ----------\n-        names : str or iterable of str\n-            The columns to keep. All other columns will be removed.\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b' and 'c'::\n-\n-            >>> t = Table([[1, 2, 3],[0.1, 0.2, 0.3],['x', 'y', 'z']],\n-            ...           names=('a', 'b', 'c'))\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1 0.1   x\n-              2 0.2   y\n-              3 0.3   z\n-\n-        Keep only column 'a' of the table::\n-\n-            >>> t.keep_columns('a')\n-            >>> print(t)\n-             a\n-            ---\n-              1\n-              2\n-              3\n-\n-        Keep columns 'a' and 'c' of the table::\n-\n-            >>> t = Table([[1, 2, 3],[0.1, 0.2, 0.3],['x', 'y', 'z']],\n-            ...           names=('a', 'b', 'c'))\n-            >>> t.keep_columns(['a', 'c'])\n-            >>> print(t)\n-             a   c\n-            --- ---\n-              1   x\n-              2   y\n-              3   z\n-        '''\n-        names = self._set_of_names_in_colnames(names)\n-        for colname in self.colnames:\n-            if colname not in names:\n-                self.columns.pop(colname)\n-\n-    def rename_column(self, name, new_name):\n-        '''\n-        Rename a column.\n-\n-        This can also be done directly with by setting the ``name`` attribute\n-        for a column::\n-\n-          table[name].name = new_name\n-\n-        TODO: this won't work for mixins\n-\n-        Parameters\n-        ----------\n-        name : str\n-            The current name of the column.\n-        new_name : str\n-            The new name for the column\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b' and 'c'::\n-\n-            >>> t = Table([[1,2],[3,4],[5,6]], names=('a','b','c'))\n-            >>> print(t)\n-             a   b   c\n-            --- --- ---\n-              1   3   5\n-              2   4   6\n-\n-        Renaming column 'a' to 'aa'::\n-\n-            >>> t.rename_column('a' , 'aa')\n-            >>> print(t)\n-             aa  b   c\n-            --- --- ---\n-              1   3   5\n-              2   4   6\n-        '''\n-\n-        if name not in self.keys():\n-            raise KeyError(f\"Column {name} does not exist\")\n-\n-        self.columns[name].info.name = new_name\n-\n-    def rename_columns(self, names, new_names):\n-        '''\n-        Rename multiple columns.\n-\n-        Parameters\n-        ----------\n-        names : list, tuple\n-            A list or tuple of existing column names.\n-        new_names : list, tuple\n-            A list or tuple of new column names.\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b', 'c'::\n-\n-            >>> t = Table([[1,2],[3,4],[5,6]], names=('a','b','c'))\n-            >>> print(t)\n-              a   b   c\n-             --- --- ---\n-              1   3   5\n-              2   4   6\n-\n-        Renaming columns 'a' to 'aa' and 'b' to 'bb'::\n-\n-            >>> names = ('a','b')\n-            >>> new_names = ('aa','bb')\n-            >>> t.rename_columns(names, new_names)\n-            >>> print(t)\n-             aa  bb   c\n-            --- --- ---\n-              1   3   5\n-              2   4   6\n-        '''\n-\n-        if not self._is_list_or_tuple_of_str(names):\n-            raise TypeError(\"input 'names' must be a tuple or a list of column names\")\n-\n-        if not self._is_list_or_tuple_of_str(new_names):\n-            raise TypeError(\"input 'new_names' must be a tuple or a list of column names\")\n-\n-        if len(names) != len(new_names):\n-            raise ValueError(\"input 'names' and 'new_names' list arguments must be the same length\")\n-\n-        for name, new_name in zip(names, new_names):\n-            self.rename_column(name, new_name)\n-\n-    def _set_row(self, idx, colnames, vals):\n-        try:\n-            assert len(vals) == len(colnames)\n-        except Exception:\n-            raise ValueError('right hand side must be a sequence of values with '\n-                             'the same length as the number of selected columns')\n-\n-        # Keep track of original values before setting each column so that\n-        # setting row can be transactional.\n-        orig_vals = []\n-        cols = self.columns\n-        try:\n-            for name, val in zip(colnames, vals):\n-                orig_vals.append(cols[name][idx])\n-                cols[name][idx] = val\n-        except Exception:\n-            # If anything went wrong first revert the row update then raise\n-            for name, val in zip(colnames, orig_vals[:-1]):\n-                cols[name][idx] = val\n-            raise\n-\n-    def add_row(self, vals=None, mask=None):\n-        \"\"\"Add a new row to the end of the table.\n-\n-        The ``vals`` argument can be:\n-\n-        sequence (e.g. tuple or list)\n-            Column values in the same order as table columns.\n-        mapping (e.g. dict)\n-            Keys corresponding to column names.  Missing values will be\n-            filled with np.zeros for the column dtype.\n-        `None`\n-            All values filled with np.zeros for the column dtype.\n-\n-        This method requires that the Table object \"owns\" the underlying array\n-        data.  In particular one cannot add a row to a Table that was\n-        initialized with copy=False from an existing array.\n-\n-        The ``mask`` attribute should give (if desired) the mask for the\n-        values. The type of the mask should match that of the values, i.e. if\n-        ``vals`` is an iterable, then ``mask`` should also be an iterable\n-        with the same length, and if ``vals`` is a mapping, then ``mask``\n-        should be a dictionary.\n-\n-        Parameters\n-        ----------\n-        vals : tuple, list, dict or None\n-            Use the specified values in the new row\n-        mask : tuple, list, dict or None\n-            Use the specified mask values in the new row\n-\n-        Examples\n-        --------\n-        Create a table with three columns 'a', 'b' and 'c'::\n-\n-           >>> t = Table([[1,2],[4,5],[7,8]], names=('a','b','c'))\n-           >>> print(t)\n-            a   b   c\n-           --- --- ---\n-             1   4   7\n-             2   5   8\n-\n-        Adding a new row with entries '3' in 'a', '6' in 'b' and '9' in 'c'::\n-\n-           >>> t.add_row([3,6,9])\n-           >>> print(t)\n-             a   b   c\n-             --- --- ---\n-             1   4   7\n-             2   5   8\n-             3   6   9\n-        \"\"\"\n-        self.insert_row(len(self), vals, mask)\n-\n-    def insert_row(self, index, vals=None, mask=None):\n-        \"\"\"Add a new row before the given ``index`` position in the table.\n-\n-        The ``vals`` argument can be:\n-\n-        sequence (e.g. tuple or list)\n-            Column values in the same order as table columns.\n-        mapping (e.g. dict)\n-            Keys corresponding to column names.  Missing values will be\n-            filled with np.zeros for the column dtype.\n-        `None`\n-            All values filled with np.zeros for the column dtype.\n-\n-        The ``mask`` attribute should give (if desired) the mask for the\n-        values. The type of the mask should match that of the values, i.e. if\n-        ``vals`` is an iterable, then ``mask`` should also be an iterable\n-        with the same length, and if ``vals`` is a mapping, then ``mask``\n-        should be a dictionary.\n-\n-        Parameters\n-        ----------\n-        vals : tuple, list, dict or None\n-            Use the specified values in the new row\n-        mask : tuple, list, dict or None\n-            Use the specified mask values in the new row\n-        \"\"\"\n-        colnames = self.colnames\n-\n-        N = len(self)\n-        if index < -N or index > N:\n-            raise IndexError(\"Index {} is out of bounds for table with length {}\"\n-                             .format(index, N))\n-        if index < 0:\n-            index += N\n-\n-        if isinstance(vals, Mapping) or vals is None:\n-            # From the vals and/or mask mappings create the corresponding lists\n-            # that have entries for each table column.\n-            if mask is not None and not isinstance(mask, Mapping):\n-                raise TypeError(\"Mismatch between type of vals and mask\")\n-\n-            # Now check that the mask is specified for the same keys as the\n-            # values, otherwise things get really confusing.\n-            if mask is not None and set(vals.keys()) != set(mask.keys()):\n-                raise ValueError('keys in mask should match keys in vals')\n-\n-            if vals and any(name not in colnames for name in vals):\n-                raise ValueError('Keys in vals must all be valid column names')\n-\n-            vals_list = []\n-            mask_list = []\n-\n-            for name in colnames:\n-                if vals and name in vals:\n-                    vals_list.append(vals[name])\n-                    mask_list.append(False if mask is None else mask[name])\n-                else:\n-                    col = self[name]\n-                    if hasattr(col, 'dtype'):\n-                        # Make a placeholder zero element of the right type which is masked.\n-                        # This assumes the appropriate insert() method will broadcast a\n-                        # numpy scalar to the right shape.\n-                        vals_list.append(np.zeros(shape=(), dtype=col.dtype))\n-\n-                        # For masked table any unsupplied values are masked by default.\n-                        mask_list.append(self.masked and vals is not None)\n-                    else:\n-                        raise ValueError(f\"Value must be supplied for column '{name}'\")\n-\n-            vals = vals_list\n-            mask = mask_list\n-\n-        if isiterable(vals):\n-            if mask is not None and (not isiterable(mask) or isinstance(mask, Mapping)):\n-                raise TypeError(\"Mismatch between type of vals and mask\")\n-\n-            if len(self.columns) != len(vals):\n-                raise ValueError('Mismatch between number of vals and columns')\n-\n-            if mask is not None:\n-                if len(self.columns) != len(mask):\n-                    raise ValueError('Mismatch between number of masks and columns')\n-            else:\n-                mask = [False] * len(self.columns)\n-\n-        else:\n-            raise TypeError('Vals must be an iterable or mapping or None')\n-\n-        # Insert val at index for each column\n-        columns = self.TableColumns()\n-        for name, col, val, mask_ in zip(colnames, self.columns.values(), vals, mask):\n-            try:\n-                # If new val is masked and the existing column does not support masking\n-                # then upgrade the column to a mask-enabled type: either the table-level\n-                # default ColumnClass or else MaskedColumn.\n-                if mask_ and isinstance(col, Column) and not isinstance(col, MaskedColumn):\n-                    col_cls = (self.ColumnClass\n-                               if issubclass(self.ColumnClass, self.MaskedColumn)\n-                               else self.MaskedColumn)\n-                    col = col_cls(col, copy=False)\n-\n-                newcol = col.insert(index, val, axis=0)\n-\n-                if len(newcol) != N + 1:\n-                    raise ValueError('Incorrect length for column {} after inserting {}'\n-                                     ' (expected {}, got {})'\n-                                     .format(name, val, len(newcol), N + 1))\n-                newcol.info.parent_table = self\n-\n-                # Set mask if needed and possible\n-                if mask_:\n-                    if hasattr(newcol, 'mask'):\n-                        newcol[index] = np.ma.masked\n-                    else:\n-                        raise TypeError(\"mask was supplied for column '{}' but it does not \"\n-                                        \"support masked values\".format(col.info.name))\n-\n-                columns[name] = newcol\n-\n-            except Exception as err:\n-                raise ValueError(\"Unable to insert row because of exception in column '{}':\\n{}\"\n-                                 .format(name, err)) from err\n-\n-        for table_index in self.indices:\n-            table_index.insert_row(index, vals, self.columns.values())\n-\n-        self._replace_cols(columns)\n-\n-        # Revert groups to default (ungrouped) state\n-        if hasattr(self, '_groups'):\n-            del self._groups\n-\n-    def _replace_cols(self, columns):\n-        for col, new_col in zip(self.columns.values(), columns.values()):\n-            new_col.info.indices = []\n-            for index in col.info.indices:\n-                index.columns[index.col_position(col.info.name)] = new_col\n-                new_col.info.indices.append(index)\n-\n-        self.columns = columns\n-\n-    def update(self, other, copy=True):\n-        \"\"\"\n-        Perform a dictionary-style update and merge metadata.\n-\n-        The argument ``other`` must be a |Table|, or something that can be used\n-        to initialize a table. Columns from (possibly converted) ``other`` are\n-        added to this table. In case of matching column names the column from\n-        this table is replaced with the one from ``other``.\n-\n-        Parameters\n-        ----------\n-        other : table-like\n-            Data to update this table with.\n-        copy : bool\n-            Whether the updated columns should be copies of or references to\n-            the originals.\n-\n-        See Also\n-        --------\n-        add_columns, astropy.table.hstack, replace_column\n-\n-        Examples\n-        --------\n-        Update a table with another table::\n-\n-            >>> t1 = Table({'a': ['foo', 'bar'], 'b': [0., 0.]}, meta={'i': 0})\n-            >>> t2 = Table({'b': [1., 2.], 'c': [7., 11.]}, meta={'n': 2})\n-            >>> t1.update(t2)\n-            >>> t1\n-            <Table length=2>\n-             a      b       c\n-            str3 float64 float64\n-            ---- ------- -------\n-             foo     1.0     7.0\n-             bar     2.0    11.0\n-            >>> t1.meta\n-            {'i': 0, 'n': 2}\n-\n-        Update a table with a dictionary::\n-\n-            >>> t = Table({'a': ['foo', 'bar'], 'b': [0., 0.]})\n-            >>> t.update({'b': [1., 2.]})\n-            >>> t\n-            <Table length=2>\n-             a      b\n-            str3 float64\n-            ---- -------\n-             foo     1.0\n-             bar     2.0\n-        \"\"\"\n-        from .operations import _merge_table_meta\n-        if not isinstance(other, Table):\n-            other = self.__class__(other, copy=copy)\n-        common_cols = set(self.colnames).intersection(other.colnames)\n-        for name, col in other.items():\n-            if name in common_cols:\n-                self.replace_column(name, col, copy=copy)\n-            else:\n-                self.add_column(col, name=name, copy=copy)\n-        _merge_table_meta(self, [self, other], metadata_conflicts='silent')\n-\n-    def argsort(self, keys=None, kind=None, reverse=False):\n-        \"\"\"\n-        Return the indices which would sort the table according to one or\n-        more key columns.  This simply calls the `numpy.argsort` function on\n-        the table with the ``order`` parameter set to ``keys``.\n-\n-        Parameters\n-        ----------\n-        keys : str or list of str\n-            The column name(s) to order the table by\n-        kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n-            Sorting algorithm used by ``numpy.argsort``.\n-        reverse : bool\n-            Sort in reverse order (default=False)\n-\n-        Returns\n-        -------\n-        index_array : ndarray, int\n-            Array of indices that sorts the table by the specified key\n-            column(s).\n-        \"\"\"\n-        if isinstance(keys, str):\n-            keys = [keys]\n-\n-        # use index sorted order if possible\n-        if keys is not None:\n-            index = get_index(self, names=keys)\n-            if index is not None:\n-                idx = np.asarray(index.sorted_data())\n-                return idx[::-1] if reverse else idx\n-\n-        kwargs = {}\n-        if keys:\n-            # For multiple keys return a structured array which gets sorted,\n-            # while for a single key return a single ndarray.  Sorting a\n-            # one-column structured array is slower than ndarray (e.g. a\n-            # factor of ~6 for a 10 million long random array), and much slower\n-            # for in principle sortable columns like Time, which get stored as\n-            # object arrays.\n-            if len(keys) > 1:\n-                kwargs['order'] = keys\n-                data = self.as_array(names=keys)\n-            else:\n-                data = self[keys[0]]\n-        else:\n-            # No keys provided so sort on all columns.\n-            data = self.as_array()\n-\n-        if kind:\n-            kwargs['kind'] = kind\n-\n-        # np.argsort will look for a possible .argsort method (e.g., for Time),\n-        # and if that fails cast to an array and try sorting that way.\n-        idx = np.argsort(data, **kwargs)\n-\n-        return idx[::-1] if reverse else idx\n-\n-    def sort(self, keys=None, *, kind=None, reverse=False):\n-        '''\n-        Sort the table according to one or more keys. This operates\n-        on the existing table and does not return a new table.\n-\n-        Parameters\n-        ----------\n-        keys : str or list of str\n-            The key(s) to order the table by. If None, use the\n-            primary index of the Table.\n-        kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n-            Sorting algorithm used by ``numpy.argsort``.\n-        reverse : bool\n-            Sort in reverse order (default=False)\n-\n-        Examples\n-        --------\n-        Create a table with 3 columns::\n-\n-            >>> t = Table([['Max', 'Jo', 'John'], ['Miller', 'Miller', 'Jackson'],\n-            ...            [12, 15, 18]], names=('firstname', 'name', 'tel'))\n-            >>> print(t)\n-            firstname   name  tel\n-            --------- ------- ---\n-                  Max  Miller  12\n-                   Jo  Miller  15\n-                 John Jackson  18\n-\n-        Sorting according to standard sorting rules, first 'name' then 'firstname'::\n-\n-            >>> t.sort(['name', 'firstname'])\n-            >>> print(t)\n-            firstname   name  tel\n-            --------- ------- ---\n-                 John Jackson  18\n-                   Jo  Miller  15\n-                  Max  Miller  12\n-\n-        Sorting according to standard sorting rules, first 'firstname' then 'tel',\n-        in reverse order::\n-\n-            >>> t.sort(['firstname', 'tel'], reverse=True)\n-            >>> print(t)\n-            firstname   name  tel\n-            --------- ------- ---\n-                  Max  Miller  12\n-                 John Jackson  18\n-                   Jo  Miller  15\n-        '''\n-        if keys is None:\n-            if not self.indices:\n-                raise ValueError(\"Table sort requires input keys or a table index\")\n-            keys = [x.info.name for x in self.indices[0].columns]\n-\n-        if isinstance(keys, str):\n-            keys = [keys]\n-\n-        indexes = self.argsort(keys, kind=kind, reverse=reverse)\n-\n-        with self.index_mode('freeze'):\n-            for name, col in self.columns.items():\n-                # Make a new sorted column.  This requires that take() also copies\n-                # relevant info attributes for mixin columns.\n-                new_col = col.take(indexes, axis=0)\n-\n-                # First statement in try: will succeed if the column supports an in-place\n-                # update, and matches the legacy behavior of astropy Table.  However,\n-                # some mixin classes may not support this, so in that case just drop\n-                # in the entire new column. See #9553 and #9536 for discussion.\n-                try:\n-                    col[:] = new_col\n-                except Exception:\n-                    # In-place update failed for some reason, exception class not\n-                    # predictable for arbitrary mixin.\n-                    self[col.info.name] = new_col\n-\n-    def reverse(self):\n-        '''\n-        Reverse the row order of table rows.  The table is reversed\n-        in place and there are no function arguments.\n-\n-        Examples\n-        --------\n-        Create a table with three columns::\n-\n-            >>> t = Table([['Max', 'Jo', 'John'], ['Miller','Miller','Jackson'],\n-            ...         [12,15,18]], names=('firstname','name','tel'))\n-            >>> print(t)\n-            firstname   name  tel\n-            --------- ------- ---\n-                  Max  Miller  12\n-                   Jo  Miller  15\n-                 John Jackson  18\n-\n-        Reversing order::\n-\n-            >>> t.reverse()\n-            >>> print(t)\n-            firstname   name  tel\n-            --------- ------- ---\n-                 John Jackson  18\n-                   Jo  Miller  15\n-                  Max  Miller  12\n-        '''\n-        for col in self.columns.values():\n-            # First statement in try: will succeed if the column supports an in-place\n-            # update, and matches the legacy behavior of astropy Table.  However,\n-            # some mixin classes may not support this, so in that case just drop\n-            # in the entire new column. See #9836, #9553, and #9536 for discussion.\n-            new_col = col[::-1]\n-            try:\n-                col[:] = new_col\n-            except Exception:\n-                # In-place update failed for some reason, exception class not\n-                # predictable for arbitrary mixin.\n-                self[col.info.name] = new_col\n-\n-        for index in self.indices:\n-            index.reverse()\n-\n-    def round(self, decimals=0):\n-        '''\n-        Round numeric columns in-place to the specified number of decimals.\n-        Non-numeric columns will be ignored.\n-\n-        Examples\n-        --------\n-        Create three columns with different types:\n-\n-            >>> t = Table([[1, 4, 5], [-25.55, 12.123, 85],\n-            ...     ['a', 'b', 'c']], names=('a', 'b', 'c'))\n-            >>> print(t)\n-             a    b     c\n-            --- ------ ---\n-              1 -25.55   a\n-              4 12.123   b\n-              5   85.0   c\n-\n-        Round them all to 0:\n-\n-            >>> t.round(0)\n-            >>> print(t)\n-             a    b    c\n-            --- ----- ---\n-              1 -26.0   a\n-              4  12.0   b\n-              5  85.0   c\n-\n-        Round column 'a' to -1 decimal:\n-\n-            >>> t.round({'a':-1})\n-            >>> print(t)\n-             a    b    c\n-            --- ----- ---\n-              0 -26.0   a\n-              0  12.0   b\n-              0  85.0   c\n-\n-        Parameters\n-        ----------\n-        decimals: int, dict\n-            Number of decimals to round the columns to. If a dict is given,\n-            the columns will be rounded to the number specified as the value.\n-            If a certain column is not in the dict given, it will remain the\n-            same.\n-        '''\n-        if isinstance(decimals, Mapping):\n-            decimal_values = decimals.values()\n-            column_names = decimals.keys()\n-        elif isinstance(decimals, int):\n-            decimal_values = itertools.repeat(decimals)\n-            column_names = self.colnames\n-        else:\n-            raise ValueError(\"'decimals' argument must be an int or a dict\")\n-\n-        for colname, decimal in zip(column_names, decimal_values):\n-            col = self.columns[colname]\n-            if np.issubdtype(col.info.dtype, np.number):\n-                try:\n-                    np.around(col, decimals=decimal, out=col)\n-                except TypeError:\n-                    # Bug in numpy see https://github.com/numpy/numpy/issues/15438\n-                    col[()] = np.around(col, decimals=decimal)\n-\n-    def copy(self, copy_data=True):\n-        '''\n-        Return a copy of the table.\n-\n-        Parameters\n-        ----------\n-        copy_data : bool\n-            If `True` (the default), copy the underlying data array.\n-            Otherwise, use the same data array. The ``meta`` is always\n-            deepcopied regardless of the value for ``copy_data``.\n-        '''\n-        out = self.__class__(self, copy=copy_data)\n-\n-        # If the current table is grouped then do the same in the copy\n-        if hasattr(self, '_groups'):\n-            out._groups = groups.TableGroups(out, indices=self._groups._indices,\n-                                             keys=self._groups._keys)\n-        return out\n-\n-    def __deepcopy__(self, memo=None):\n-        return self.copy(True)\n-\n-    def __copy__(self):\n-        return self.copy(False)\n-\n-    def __lt__(self, other):\n-        return super().__lt__(other)\n-\n-    def __gt__(self, other):\n-        return super().__gt__(other)\n-\n-    def __le__(self, other):\n-        return super().__le__(other)\n-\n-    def __ge__(self, other):\n-        return super().__ge__(other)\n-\n-    def __eq__(self, other):\n-        return self._rows_equal(other)\n-\n-    def __ne__(self, other):\n-        return ~self.__eq__(other)\n-\n-    def _rows_equal(self, other):\n-        \"\"\"\n-        Row-wise comparison of table with any other object.\n-\n-        This is actual implementation for __eq__.\n-\n-        Returns a 1-D boolean numpy array showing result of row-wise comparison.\n-        This is the same as the ``==`` comparison for tables.\n-\n-        Parameters\n-        ----------\n-        other : Table or DataFrame or ndarray\n-             An object to compare with table\n-\n-        Examples\n-        --------\n-        Comparing one Table with other::\n-\n-            >>> t1 = Table([[1,2],[4,5],[7,8]], names=('a','b','c'))\n-            >>> t2 = Table([[1,2],[4,5],[7,8]], names=('a','b','c'))\n-            >>> t1._rows_equal(t2)\n-            array([ True,  True])\n-\n-        \"\"\"\n-\n-        if isinstance(other, Table):\n-            other = other.as_array()\n-\n-        if self.has_masked_columns:\n-            if isinstance(other, np.ma.MaskedArray):\n-                result = self.as_array() == other\n-            else:\n-                # If mask is True, then by definition the row doesn't match\n-                # because the other array is not masked.\n-                false_mask = np.zeros(1, dtype=[(n, bool) for n in self.dtype.names])\n-                result = (self.as_array().data == other) & (self.mask == false_mask)\n-        else:\n-            if isinstance(other, np.ma.MaskedArray):\n-                # If mask is True, then by definition the row doesn't match\n-                # because the other array is not masked.\n-                false_mask = np.zeros(1, dtype=[(n, bool) for n in other.dtype.names])\n-                result = (self.as_array() == other.data) & (other.mask == false_mask)\n-            else:\n-                result = self.as_array() == other\n-\n-        return result\n-\n-    def values_equal(self, other):\n-        \"\"\"\n-        Element-wise comparison of table with another table, list, or scalar.\n-\n-        Returns a ``Table`` with the same columns containing boolean values\n-        showing result of comparison.\n-\n-        Parameters\n-        ----------\n-        other : table-like object or list or scalar\n-             Object to compare with table\n-\n-        Examples\n-        --------\n-        Compare one Table with other::\n-\n-          >>> t1 = Table([[1, 2], [4, 5], [-7, 8]], names=('a', 'b', 'c'))\n-          >>> t2 = Table([[1, 2], [-4, 5], [7, 8]], names=('a', 'b', 'c'))\n-          >>> t1.values_equal(t2)\n-          <Table length=2>\n-           a     b     c\n-          bool  bool  bool\n-          ---- ----- -----\n-          True False False\n-          True  True  True\n-\n-        \"\"\"\n-        if isinstance(other, Table):\n-            names = other.colnames\n-        else:\n-            try:\n-                other = Table(other, copy=False)\n-                names = other.colnames\n-            except Exception:\n-                # Broadcast other into a dict, so e.g. other = 2 will turn into\n-                # other = {'a': 2, 'b': 2} and then equality does a\n-                # column-by-column broadcasting.\n-                names = self.colnames\n-                other = {name: other for name in names}\n-\n-        # Require column names match but do not require same column order\n-        if set(self.colnames) != set(names):\n-            raise ValueError('cannot compare tables with different column names')\n-\n-        eqs = []\n-        for name in names:\n-            try:\n-                np.broadcast(self[name], other[name])  # Check if broadcast-able\n-                # Catch the numpy FutureWarning related to equality checking,\n-                # \"elementwise comparison failed; returning scalar instead, but\n-                #  in the future will perform elementwise comparison\".  Turn this\n-                # into an exception since the scalar answer is not what we want.\n-                with warnings.catch_warnings(record=True) as warns:\n-                    warnings.simplefilter('always')\n-                    eq = self[name] == other[name]\n-                    if (warns and issubclass(warns[-1].category, FutureWarning)\n-                            and 'elementwise comparison failed' in str(warns[-1].message)):\n-                        raise FutureWarning(warns[-1].message)\n-            except Exception as err:\n-                raise ValueError(f'unable to compare column {name}') from err\n-\n-            # Be strict about the result from the comparison. E.g. SkyCoord __eq__ is just\n-            # broken and completely ignores that it should return an array.\n-            if not (isinstance(eq, np.ndarray)\n-                    and eq.dtype is np.dtype('bool')\n-                    and len(eq) == len(self)):\n-                raise TypeError(f'comparison for column {name} returned {eq} '\n-                                f'instead of the expected boolean ndarray')\n-\n-            eqs.append(eq)\n-\n-        out = Table(eqs, names=names)\n-\n-        return out\n-\n-    @property\n-    def groups(self):\n-        if not hasattr(self, '_groups'):\n-            self._groups = groups.TableGroups(self)\n-        return self._groups\n-\n-    def group_by(self, keys):\n-        \"\"\"\n-        Group this table by the specified ``keys``\n-\n-        This effectively splits the table into groups which correspond to unique\n-        values of the ``keys`` grouping object.  The output is a new\n-        `~astropy.table.TableGroups` which contains a copy of this table but\n-        sorted by row according to ``keys``.\n-\n-        The ``keys`` input to `group_by` can be specified in different ways:\n-\n-          - String or list of strings corresponding to table column name(s)\n-          - Numpy array (homogeneous or structured) with same length as this table\n-          - `~astropy.table.Table` with same length as this table\n-\n-        Parameters\n-        ----------\n-        keys : str, list of str, numpy array, or `~astropy.table.Table`\n-            Key grouping object\n-\n-        Returns\n-        -------\n-        out : `~astropy.table.Table`\n-            New table with groups set\n-        \"\"\"\n-        return groups.table_group_by(self, keys)\n-\n-    def to_pandas(self, index=None, use_nullable_int=True):\n-        \"\"\"\n-        Return a :class:`pandas.DataFrame` instance\n-\n-        The index of the created DataFrame is controlled by the ``index``\n-        argument.  For ``index=True`` or the default ``None``, an index will be\n-        specified for the DataFrame if there is a primary key index on the\n-        Table *and* if it corresponds to a single column.  If ``index=False``\n-        then no DataFrame index will be specified.  If ``index`` is the name of\n-        a column in the table then that will be the DataFrame index.\n-\n-        In addition to vanilla columns or masked columns, this supports Table\n-        mixin columns like Quantity, Time, or SkyCoord.  In many cases these\n-        objects have no analog in pandas and will be converted to a \"encoded\"\n-        representation using only Column or MaskedColumn.  The exception is\n-        Time or TimeDelta columns, which will be converted to the corresponding\n-        representation in pandas using ``np.datetime64`` or ``np.timedelta64``.\n-        See the example below.\n-\n-        Parameters\n-        ----------\n-        index : None, bool, str\n-            Specify DataFrame index mode\n-        use_nullable_int : bool, default=True\n-            Convert integer MaskedColumn to pandas nullable integer type.\n-            If ``use_nullable_int=False`` or the pandas version does not support\n-            nullable integer types (version < 0.24), then the column is converted\n-            to float with NaN for missing elements and a warning is issued.\n-\n-        Returns\n-        -------\n-        dataframe : :class:`pandas.DataFrame`\n-            A pandas :class:`pandas.DataFrame` instance\n-\n-        Raises\n-        ------\n-        ImportError\n-            If pandas is not installed\n-        ValueError\n-            If the Table has multi-dimensional columns\n-\n-        Examples\n-        --------\n-        Here we convert a table with a few mixins to a\n-        :class:`pandas.DataFrame` instance.\n-\n-          >>> import pandas as pd\n-          >>> from astropy.table import QTable\n-          >>> import astropy.units as u\n-          >>> from astropy.time import Time, TimeDelta\n-          >>> from astropy.coordinates import SkyCoord\n-\n-          >>> q = [1, 2] * u.m\n-          >>> tm = Time([1998, 2002], format='jyear')\n-          >>> sc = SkyCoord([5, 6], [7, 8], unit='deg')\n-          >>> dt = TimeDelta([3, 200] * u.s)\n-\n-          >>> t = QTable([q, tm, sc, dt], names=['q', 'tm', 'sc', 'dt'])\n-\n-          >>> df = t.to_pandas(index='tm')\n-          >>> with pd.option_context('display.max_columns', 20):\n-          ...     print(df)\n-                        q  sc.ra  sc.dec              dt\n-          tm\n-          1998-01-01  1.0    5.0     7.0 0 days 00:00:03\n-          2002-01-01  2.0    6.0     8.0 0 days 00:03:20\n-\n-        \"\"\"\n-        from pandas import DataFrame, Series\n-\n-        if index is not False:\n-            if index in (None, True):\n-                # Default is to use the table primary key if available and a single column\n-                if self.primary_key and len(self.primary_key) == 1:\n-                    index = self.primary_key[0]\n-                else:\n-                    index = False\n-            else:\n-                if index not in self.colnames:\n-                    raise ValueError('index must be None, False, True or a table '\n-                                     'column name')\n-\n-        def _encode_mixins(tbl):\n-            \"\"\"Encode a Table ``tbl`` that may have mixin columns to a Table with only\n-            astropy Columns + appropriate meta-data to allow subsequent decoding.\n-            \"\"\"\n-            from . import serialize\n-            from astropy.time import TimeBase, TimeDelta\n-\n-            # Convert any Time or TimeDelta columns and pay attention to masking\n-            time_cols = [col for col in tbl.itercols() if isinstance(col, TimeBase)]\n-            if time_cols:\n-\n-                # Make a light copy of table and clear any indices\n-                new_cols = []\n-                for col in tbl.itercols():\n-                    new_col = col_copy(col, copy_indices=False) if col.info.indices else col\n-                    new_cols.append(new_col)\n-                tbl = tbl.__class__(new_cols, copy=False)\n-\n-                # Certain subclasses (e.g. TimeSeries) may generate new indices on\n-                # table creation, so make sure there are no indices on the table.\n-                for col in tbl.itercols():\n-                    col.info.indices.clear()\n-\n-                for col in time_cols:\n-                    if isinstance(col, TimeDelta):\n-                        # Convert to nanoseconds (matches astropy datetime64 support)\n-                        new_col = (col.sec * 1e9).astype('timedelta64[ns]')\n-                        nat = np.timedelta64('NaT')\n-                    else:\n-                        new_col = col.datetime64.copy()\n-                        nat = np.datetime64('NaT')\n-                    if col.masked:\n-                        new_col[col.mask] = nat\n-                    tbl[col.info.name] = new_col\n-\n-            # Convert the table to one with no mixins, only Column objects.\n-            encode_tbl = serialize.represent_mixins_as_columns(tbl)\n-            return encode_tbl\n-\n-        tbl = _encode_mixins(self)\n-\n-        badcols = [name for name, col in self.columns.items() if len(col.shape) > 1]\n-        if badcols:\n-            raise ValueError(\n-                f'Cannot convert a table with multidimensional columns to a '\n-                f'pandas DataFrame. Offending columns are: {badcols}\\n'\n-                f'One can filter out such columns using:\\n'\n-                f'names = [name for name in tbl.colnames if len(tbl[name].shape) <= 1]\\n'\n-                f'tbl[names].to_pandas(...)')\n-\n-        out = OrderedDict()\n-\n-        for name, column in tbl.columns.items():\n-            if getattr(column.dtype, 'isnative', True):\n-                out[name] = column\n-            else:\n-                out[name] = column.data.byteswap().newbyteorder('=')\n-\n-            if isinstance(column, MaskedColumn) and np.any(column.mask):\n-                if column.dtype.kind in ['i', 'u']:\n-                    pd_dtype = column.dtype.name\n-                    if use_nullable_int:\n-                        # Convert int64 to Int64, uint32 to UInt32, etc for nullable types\n-                        pd_dtype = pd_dtype.replace('i', 'I').replace('u', 'U')\n-                    out[name] = Series(out[name], dtype=pd_dtype)\n-\n-                    # If pandas is older than 0.24 the type may have turned to float\n-                    if column.dtype.kind != out[name].dtype.kind:\n-                        warnings.warn(\n-                            f\"converted column '{name}' from {column.dtype} to {out[name].dtype}\",\n-                            TableReplaceWarning, stacklevel=3)\n-                elif column.dtype.kind not in ['f', 'c']:\n-                    out[name] = column.astype(object).filled(np.nan)\n-\n-        kwargs = {}\n-\n-        if index:\n-            idx = out.pop(index)\n-\n-            kwargs['index'] = idx\n-\n-            # We add the table index to Series inputs (MaskedColumn with int values) to override\n-            # its default RangeIndex, see #11432\n-            for v in out.values():\n-                if isinstance(v, Series):\n-                    v.index = idx\n-\n-        df = DataFrame(out, **kwargs)\n-        if index:\n-            # Explicitly set the pandas DataFrame index to the original table\n-            # index name.\n-            df.index.name = idx.info.name\n-\n-        return df\n-\n-    @classmethod\n-    def from_pandas(cls, dataframe, index=False, units=None):\n-        \"\"\"\n-        Create a `~astropy.table.Table` from a :class:`pandas.DataFrame` instance\n-\n-        In addition to converting generic numeric or string columns, this supports\n-        conversion of pandas Date and Time delta columns to `~astropy.time.Time`\n-        and `~astropy.time.TimeDelta` columns, respectively.\n-\n-        Parameters\n-        ----------\n-        dataframe : :class:`pandas.DataFrame`\n-            A pandas :class:`pandas.DataFrame` instance\n-        index : bool\n-            Include the index column in the returned table (default=False)\n-        units: dict\n-            A dict mapping column names to to a `~astropy.units.Unit`.\n-            The columns will have the specified unit in the Table.\n-\n-        Returns\n-        -------\n-        table : `~astropy.table.Table`\n-            A `~astropy.table.Table` (or subclass) instance\n-\n-        Raises\n-        ------\n-        ImportError\n-            If pandas is not installed\n-\n-        Examples\n-        --------\n-        Here we convert a :class:`pandas.DataFrame` instance\n-        to a `~astropy.table.QTable`.\n-\n-          >>> import numpy as np\n-          >>> import pandas as pd\n-          >>> from astropy.table import QTable\n-\n-          >>> time = pd.Series(['1998-01-01', '2002-01-01'], dtype='datetime64[ns]')\n-          >>> dt = pd.Series(np.array([1, 300], dtype='timedelta64[s]'))\n-          >>> df = pd.DataFrame({'time': time})\n-          >>> df['dt'] = dt\n-          >>> df['x'] = [3., 4.]\n-          >>> with pd.option_context('display.max_columns', 20):\n-          ...     print(df)\n-                  time              dt    x\n-          0 1998-01-01 0 days 00:00:01  3.0\n-          1 2002-01-01 0 days 00:05:00  4.0\n-\n-          >>> QTable.from_pandas(df)\n-          <QTable length=2>\n-                    time              dt       x\n-                    Time          TimeDelta float64\n-          ----------------------- --------- -------\n-          1998-01-01T00:00:00.000       1.0     3.0\n-          2002-01-01T00:00:00.000     300.0     4.0\n-\n-        \"\"\"\n-\n-        out = OrderedDict()\n-\n-        names = list(dataframe.columns)\n-        columns = [dataframe[name] for name in names]\n-        datas = [np.array(column) for column in columns]\n-        masks = [np.array(column.isnull()) for column in columns]\n-\n-        if index:\n-            index_name = dataframe.index.name or 'index'\n-            while index_name in names:\n-                index_name = '_' + index_name + '_'\n-            names.insert(0, index_name)\n-            columns.insert(0, dataframe.index)\n-            datas.insert(0, np.array(dataframe.index))\n-            masks.insert(0, np.zeros(len(dataframe), dtype=bool))\n-\n-        if units is None:\n-            units = [None] * len(names)\n-        else:\n-            if not isinstance(units, Mapping):\n-                raise TypeError('Expected a Mapping \"column-name\" -> \"unit\"')\n-\n-            not_found = set(units.keys()) - set(names)\n-            if not_found:\n-                warnings.warn(f'`units` contains additional columns: {not_found}')\n-\n-            units = [units.get(name) for name in names]\n-\n-        for name, column, data, mask, unit in zip(names, columns, datas, masks, units):\n-\n-            if column.dtype.kind in ['u', 'i'] and np.any(mask):\n-                # Special-case support for pandas nullable int\n-                np_dtype = str(column.dtype).lower()\n-                data = np.zeros(shape=column.shape, dtype=np_dtype)\n-                data[~mask] = column[~mask]\n-                out[name] = MaskedColumn(data=data, name=name, mask=mask, unit=unit, copy=False)\n-                continue\n-\n-            if data.dtype.kind == 'O':\n-                # If all elements of an object array are string-like or np.nan\n-                # then coerce back to a native numpy str/unicode array.\n-                string_types = (str, bytes)\n-                nan = np.nan\n-                if all(isinstance(x, string_types) or x is nan for x in data):\n-                    # Force any missing (null) values to b''.  Numpy will\n-                    # upcast to str/unicode as needed.\n-                    data[mask] = b''\n-\n-                    # When the numpy object array is represented as a list then\n-                    # numpy initializes to the correct string or unicode type.\n-                    data = np.array([x for x in data])\n-\n-            # Numpy datetime64\n-            if data.dtype.kind == 'M':\n-                from astropy.time import Time\n-                out[name] = Time(data, format='datetime64')\n-                if np.any(mask):\n-                    out[name][mask] = np.ma.masked\n-                out[name].format = 'isot'\n-\n-            # Numpy timedelta64\n-            elif data.dtype.kind == 'm':\n-                from astropy.time import TimeDelta\n-                data_sec = data.astype('timedelta64[ns]').astype(np.float64) / 1e9\n-                out[name] = TimeDelta(data_sec, format='sec')\n-                if np.any(mask):\n-                    out[name][mask] = np.ma.masked\n-\n-            else:\n-                if np.any(mask):\n-                    out[name] = MaskedColumn(data=data, name=name, mask=mask, unit=unit)\n-                else:\n-                    out[name] = Column(data=data, name=name, unit=unit)\n-\n-        return cls(out)\n-\n-    info = TableInfo()\n-\n-\n-class QTable(Table):\n-    \"\"\"A class to represent tables of heterogeneous data.\n-\n-    `~astropy.table.QTable` provides a class for heterogeneous tabular data\n-    which can be easily modified, for instance adding columns or new rows.\n-\n-    The `~astropy.table.QTable` class is identical to `~astropy.table.Table`\n-    except that columns with an associated ``unit`` attribute are converted to\n-    `~astropy.units.Quantity` objects.\n-\n-    See also:\n-\n-    - https://docs.astropy.org/en/stable/table/\n-    - https://docs.astropy.org/en/stable/table/mixin_columns.html\n-\n-    Parameters\n-    ----------\n-    data : numpy ndarray, dict, list, table-like object, optional\n-        Data to initialize table.\n-    masked : bool, optional\n-        Specify whether the table is masked.\n-    names : list, optional\n-        Specify column names.\n-    dtype : list, optional\n-        Specify column data types.\n-    meta : dict, optional\n-        Metadata associated with the table.\n-    copy : bool, optional\n-        Copy the input data. Default is True.\n-    rows : numpy ndarray, list of list, optional\n-        Row-oriented data for table instead of ``data`` argument.\n-    copy_indices : bool, optional\n-        Copy any indices in the input data. Default is True.\n-    **kwargs : dict, optional\n-        Additional keyword args when converting table-like object.\n-\n-    \"\"\"\n-\n-    def _is_mixin_for_table(self, col):\n-        \"\"\"\n-        Determine if ``col`` should be added to the table directly as\n-        a mixin column.\n-        \"\"\"\n-        return has_info_class(col, MixinInfo)\n-\n-    def _convert_col_for_table(self, col):\n-        if isinstance(col, Column) and getattr(col, 'unit', None) is not None:\n-            # We need to turn the column into a quantity; use subok=True to allow\n-            # Quantity subclasses identified in the unit (such as u.mag()).\n-            q_cls = Masked(Quantity) if isinstance(col, MaskedColumn) else Quantity\n-            try:\n-                qcol = q_cls(col.data, col.unit, copy=False, subok=True)\n-            except Exception as exc:\n-                warnings.warn(f\"column {col.info.name} has a unit but is kept as \"\n-                              f\"a {col.__class__.__name__} as an attempt to \"\n-                              f\"convert it to Quantity failed with:\\n{exc!r}\",\n-                              AstropyUserWarning)\n-            else:\n-                qcol.info = col.info\n-                qcol.info.indices = col.info.indices\n-                col = qcol\n-        else:\n-            col = super()._convert_col_for_table(col)\n-\n-        return col\n+            data_is_mixin = True\n\\ No newline at end of file\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-13398",
  "model_patch": "",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-13453",
  "model_patch": "diff --git a/astropy/io/ascii/html.py b/astropy/io/ascii/html.py\nindex 266cf229cc..b175b9498b 100644\n--- a/astropy/io/ascii/html.py\n+++ b/astropy/io/ascii/html.py\n@@ -354,6 +354,10 @@ class HTML(core.BaseReader):\n             self.data.fill_values = [self.data.fill_values]\n \n         self.data._set_fill_values(cols)\n+        \n+        # Set self.data.cols and apply column formats\n+        self.data.cols = cols\n+        self.data._set_col_formats()\n \n         lines = []\n \n@@ -429,6 +433,8 @@ class HTML(core.BaseReader):\n                                 for i in range(span):\n                                     # Split up multicolumns into separate columns\n                                     new_col = Column([el[i] for el in col])\n+                                    # Copy format from original column\n+                                    new_col.info.format = col.info.format\n \n                                     new_col_iter_str_vals = self.fill_values(\n                                         col, new_col.info.iter_str_vals())\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-13579",
  "model_patch": "diff --git a/astropy/wcs/wcsapi/wrappers/sliced_wcs.py b/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\nindex d7605b078c..d4d7445f06 100644\n--- a/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\n+++ b/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\n@@ -246,20 +246,94 @@ class SlicedLowLevelWCS(BaseWCSWrapper):\n         world_arrays = tuple(map(np.asanyarray, world_arrays))\n         world_arrays_new = []\n         iworld_curr = -1\n+        \n+        # For world dimensions that are kept, use the input values\n+        # For world dimensions that are dropped (sliced out), we need to provide\n+        # appropriate values. The issue is that for coupled WCS, the correct\n+        # world coordinate for a dropped dimension depends on the pixel coordinates\n+        # of kept dimensions, which we don't know yet.\n+        #\n+        # The original code used 1.0 as a placeholder, which doesn't work for\n+        # coupled WCS. The current code uses dropped_world_dimensions[\"value\"],\n+        # which calculates world coordinates at pixel=0 for kept dimensions.\n+        # This is better but still not perfect for strongly coupled WCS.\n+        #\n+        # For the specific bug report (astropy/astropy#13579), the issue is that\n+        # a WCS with PC matrix coupling between spatial and spectral dimensions\n+        # gives incorrect results when doing world_to_pixel on a sliced WCS.\n+        #\n+        # The fix is to use an iterative approach to find world coordinates for\n+        # dropped dimensions that are consistent with the solution.\n+        \n+        # Get initial values for dropped dimensions\n+        dropped_values = self.dropped_world_dimensions[\"value\"]\n+        \n+        # Build initial world arrays\n+        world_arrays_new = []\n+        iworld_curr = -1\n+        dropped_idx = 0\n         for iworld in range(self._wcs.world_n_dim):\n             if iworld in self._world_keep:\n                 iworld_curr += 1\n                 world_arrays_new.append(world_arrays[iworld_curr])\n             else:\n-                world_arrays_new.append(1.)\n-\n-        world_arrays_new = np.broadcast_arrays(*world_arrays_new)\n-        pixel_arrays = list(self._wcs.world_to_pixel_values(*world_arrays_new))\n-\n-        for ipixel in range(self._wcs.pixel_n_dim):\n-            if isinstance(self._slices_pixel[ipixel], slice) and self._slices_pixel[ipixel].start is not None:\n-                pixel_arrays[ipixel] -= self._slices_pixel[ipixel].start\n-\n+                world_arrays_new.append(dropped_values[dropped_idx])\n+                dropped_idx += 1\n+        \n+        # Use a simple iterative approach to improve the guess for dropped dimensions\n+        # This should converge quickly for most WCS, especially linear ones\n+        max_iter = 5\n+        tolerance = 1e-12\n+        \n+        for iteration in range(max_iter):\n+            # Broadcast to ensure consistent shapes\n+            world_bcast = np.broadcast_arrays(*world_arrays_new)\n+            \n+            # Solve for pixel coordinates\n+            pixel_arrays = list(self._wcs.world_to_pixel_values(*world_bcast))\n+            \n+            # Adjust for slice start\n+            for ipixel in range(self._wcs.pixel_n_dim):\n+                if isinstance(self._slices_pixel[ipixel], slice) and self._slices_pixel[ipixel].start is not None:\n+                    pixel_arrays[ipixel] -= self._slices_pixel[ipixel].start\n+            \n+            # Calculate what the world coordinates would be at these pixel coordinates\n+            # This gives us better estimates for dropped dimensions\n+            pixel_for_world = []\n+            for ipix in range(self._wcs.pixel_n_dim):\n+                if isinstance(self._slices_pixel[ipix], numbers.Integral):\n+                    pixel_for_world.append(self._slices_pixel[ipix])\n+                else:\n+                    pixel_for_world.append(pixel_arrays[ipix])\n+            \n+            world_calculated = self._wcs.pixel_to_world_values(*pixel_for_world)\n+            if not isinstance(world_calculated, tuple):\n+                world_calculated = (world_calculated,)\n+            \n+            # Check if we need to update world coordinates for dropped dimensions\n+            updated = False\n+            dropped_idx = 0\n+            for iworld in range(self._wcs.world_n_dim):\n+                if iworld not in self._world_keep:\n+                    old_val = world_arrays_new[iworld]\n+                    new_val = world_calculated[iworld]\n+                    \n+                    # Handle both scalar and array cases\n+                    if np.isscalar(old_val) and np.isscalar(new_val):\n+                        diff = abs(new_val - old_val)\n+                    else:\n+                        diff = np.max(np.abs(new_val - old_val))\n+                    \n+                    if diff > tolerance:\n+                        world_arrays_new[iworld] = new_val\n+                        updated = True\n+                    dropped_idx += 1\n+            \n+            # If no dropped dimensions needed updating, we've converged\n+            if not updated:\n+                break\n+        \n+        # Return only the kept pixel dimensions\n         # Detect the case of a length 0 array\n         if isinstance(pixel_arrays, np.ndarray) and not pixel_arrays.shape:\n             return pixel_arrays\n@@ -305,4 +379,4 @@ class SlicedLowLevelWCS(BaseWCSWrapper):\n \n     @property\n     def axis_correlation_matrix(self):\n-        return self._wcs.axis_correlation_matrix[self._world_keep][:, self._pixel_keep]\n+        return self._wcs.axis_correlation_matrix[self._world_keep][:, self._pixel_keep]\n\\ No newline at end of file\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-13977",
  "model_patch": "diff --git a/astropy/units/quantity.py b/astropy/units/quantity.py\nindex b98abfafb0..12c4b974ad 100644\n--- a/astropy/units/quantity.py\n+++ b/astropy/units/quantity.py\n@@ -667,1563 +667,11 @@ class Quantity(np.ndarray):\n         arrays = []\n         for input_, converter in zip(inputs, converters):\n             input_ = getattr(input_, \"value\", input_)\n-            arrays.append(converter(input_) if converter else input_)\n-\n-        # Call our superclass's __array_ufunc__\n-        result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n-        # If unit is None, a plain array is expected (e.g., comparisons), which\n-        # means we're done.\n-        # We're also done if the result was None (for method 'at') or\n-        # NotImplemented, which can happen if other inputs/outputs override\n-        # __array_ufunc__; hopefully, they can then deal with us.\n-        if unit is None or result is None or result is NotImplemented:\n-            return result\n-\n-        return self._result_as_quantity(result, unit, out)\n-\n-    def _result_as_quantity(self, result, unit, out):\n-        \"\"\"Turn result into a quantity with the given unit.\n-\n-        If no output is given, it will take a view of the array as a quantity,\n-        and set the unit.  If output is given, those should be quantity views\n-        of the result arrays, and the function will just set the unit.\n-\n-        Parameters\n-        ----------\n-        result : ndarray or tuple thereof\n-            Array(s) which need to be turned into quantity.\n-        unit : `~astropy.units.Unit`\n-            Unit for the quantities to be returned (or `None` if the result\n-            should not be a quantity).  Should be tuple if result is a tuple.\n-        out : `~astropy.units.Quantity` or None\n-            Possible output quantity. Should be `None` or a tuple if result\n-            is a tuple.\n-\n-        Returns\n-        -------\n-        out : `~astropy.units.Quantity`\n-           With units set.\n-        \"\"\"\n-        if isinstance(result, (tuple, list)):\n-            if out is None:\n-                out = (None,) * len(result)\n-            return result.__class__(\n-                self._result_as_quantity(result_, unit_, out_)\n-                for (result_, unit_, out_) in zip(result, unit, out)\n-            )\n-\n-        if out is None:\n-            # View the result array as a Quantity with the proper unit.\n-            return result if unit is None else self._new_view(result, unit)\n-\n-        elif isinstance(out, Quantity):\n-            # For given Quantity output, just set the unit. We know the unit\n-            # is not None and the output is of the correct Quantity subclass,\n-            # as it was passed through check_output.\n-            # (We cannot do this unconditionally, though, since it is possible\n-            # for out to be ndarray and the unit to be dimensionless.)\n-            out._set_unit(unit)\n-\n-        return out\n-\n-    def __quantity_subclass__(self, unit):\n-        \"\"\"\n-        Overridden by subclasses to change what kind of view is\n-        created based on the output unit of an operation.\n-\n-        Parameters\n-        ----------\n-        unit : UnitBase\n-            The unit for which the appropriate class should be returned\n-\n-        Returns\n-        -------\n-        tuple :\n-            - `~astropy.units.Quantity` subclass\n-            - bool: True if subclasses of the given class are ok\n-        \"\"\"\n-        return Quantity, True\n-\n-    def _new_view(self, obj=None, unit=None):\n-        \"\"\"\n-        Create a Quantity view of some array-like input, and set the unit\n-\n-        By default, return a view of ``obj`` of the same class as ``self`` and\n-        with the same unit.  Subclasses can override the type of class for a\n-        given unit using ``__quantity_subclass__``, and can ensure properties\n-        other than the unit are copied using ``__array_finalize__``.\n-\n-        If the given unit defines a ``_quantity_class`` of which ``self``\n-        is not an instance, a view using this class is taken.\n-\n-        Parameters\n-        ----------\n-        obj : ndarray or scalar, optional\n-            The array to create a view of.  If obj is a numpy or python scalar,\n-            it will be converted to an array scalar.  By default, ``self``\n-            is converted.\n-\n-        unit : unit-like, optional\n-            The unit of the resulting object.  It is used to select a\n-            subclass, and explicitly assigned to the view if given.\n-            If not given, the subclass and unit will be that of ``self``.\n-\n-        Returns\n-        -------\n-        view : `~astropy.units.Quantity` subclass\n-        \"\"\"\n-        # Determine the unit and quantity subclass that we need for the view.\n-        if unit is None:\n-            unit = self.unit\n-            quantity_subclass = self.__class__\n-        elif unit is self.unit and self.__class__ is Quantity:\n-            # The second part is because we should not presume what other\n-            # classes want to do for the same unit.  E.g., Constant will\n-            # always want to fall back to Quantity, and relies on going\n-            # through `__quantity_subclass__`.\n-            quantity_subclass = Quantity\n-        else:\n-            unit = Unit(unit)\n-            quantity_subclass = getattr(unit, \"_quantity_class\", Quantity)\n-            if isinstance(self, quantity_subclass):\n-                quantity_subclass, subok = self.__quantity_subclass__(unit)\n-                if subok:\n-                    quantity_subclass = self.__class__\n-\n-        # We only want to propagate information from ``self`` to our new view,\n-        # so obj should be a regular array.  By using ``np.array``, we also\n-        # convert python and numpy scalars, which cannot be viewed as arrays\n-        # and thus not as Quantity either, to zero-dimensional arrays.\n-        # (These are turned back into scalar in `.value`)\n-        # Note that for an ndarray input, the np.array call takes only double\n-        # ``obj.__class is np.ndarray``. So, not worth special-casing.\n-        if obj is None:\n-            obj = self.view(np.ndarray)\n-        else:\n-            obj = np.array(obj, copy=False, subok=True)\n-\n-        # Take the view, set the unit, and update possible other properties\n-        # such as ``info``, ``wrap_angle`` in `Longitude`, etc.\n-        view = obj.view(quantity_subclass)\n-        view._set_unit(unit)\n-        view.__array_finalize__(self)\n-        return view\n-\n-    def _set_unit(self, unit):\n-        \"\"\"Set the unit.\n-\n-        This is used anywhere the unit is set or modified, i.e., in the\n-        initilizer, in ``__imul__`` and ``__itruediv__`` for in-place\n-        multiplication and division by another unit, as well as in\n-        ``__array_finalize__`` for wrapping up views.  For Quantity, it just\n-        sets the unit, but subclasses can override it to check that, e.g.,\n-        a unit is consistent.\n-        \"\"\"\n-        if not isinstance(unit, UnitBase):\n-            if isinstance(self._unit, StructuredUnit) or isinstance(\n-                unit, StructuredUnit\n-            ):\n-                unit = StructuredUnit(unit, self.dtype)\n-            else:\n-                # Trying to go through a string ensures that, e.g., Magnitudes with\n-                # dimensionless physical unit become Quantity with units of mag.\n-                unit = Unit(str(unit), parse_strict=\"silent\")\n-                if not isinstance(unit, (UnitBase, StructuredUnit)):\n-                    raise UnitTypeError(\n-                        f\"{self.__class__.__name__} instances require normal units, \"\n-                        f\"not {unit.__class__} instances.\"\n-                    )\n-\n-        self._unit = unit\n-\n-    def __deepcopy__(self, memo):\n-        # If we don't define this, ``copy.deepcopy(quantity)`` will\n-        # return a bare Numpy array.\n-        return self.copy()\n-\n-    def __reduce__(self):\n-        # patch to pickle Quantity objects (ndarray subclasses), see\n-        # http://www.mail-archive.com/numpy-discussion@scipy.org/msg02446.html\n-\n-        object_state = list(super().__reduce__())\n-        object_state[2] = (object_state[2], self.__dict__)\n-        return tuple(object_state)\n-\n-    def __setstate__(self, state):\n-        # patch to unpickle Quantity objects (ndarray subclasses), see\n-        # http://www.mail-archive.com/numpy-discussion@scipy.org/msg02446.html\n-\n-        nd_state, own_state = state\n-        super().__setstate__(nd_state)\n-        self.__dict__.update(own_state)\n-\n-    info = QuantityInfo()\n-\n-    def _to_value(self, unit, equivalencies=[]):\n-        \"\"\"Helper method for to and to_value.\"\"\"\n-        if equivalencies == []:\n-            equivalencies = self._equivalencies\n-        if not self.dtype.names or isinstance(self.unit, StructuredUnit):\n-            # Standard path, let unit to do work.\n-            return self.unit.to(\n-                unit, self.view(np.ndarray), equivalencies=equivalencies\n-            )\n-\n-        else:\n-            # The .to() method of a simple unit cannot convert a structured\n-            # dtype, so we work around it, by recursing.\n-            # TODO: deprecate this?\n-            # Convert simple to Structured on initialization?\n-            result = np.empty_like(self.view(np.ndarray))\n-            for name in self.dtype.names:\n-                result[name] = self[name]._to_value(unit, equivalencies)\n-            return result\n-\n-    def to(self, unit, equivalencies=[], copy=True):\n-        \"\"\"\n-        Return a new `~astropy.units.Quantity` object with the specified unit.\n-\n-        Parameters\n-        ----------\n-        unit : unit-like\n-            An object that represents the unit to convert to. Must be\n-            an `~astropy.units.UnitBase` object or a string parseable\n-            by the `~astropy.units` package.\n-\n-        equivalencies : list of tuple\n-            A list of equivalence pairs to try if the units are not\n-            directly convertible.  See :ref:`astropy:unit_equivalencies`.\n-            If not provided or ``[]``, class default equivalencies will be used\n-            (none for `~astropy.units.Quantity`, but may be set for subclasses)\n-            If `None`, no equivalencies will be applied at all, not even any\n-            set globally or within a context.\n-\n-        copy : bool, optional\n-            If `True` (default), then the value is copied.  Otherwise, a copy\n-            will only be made if necessary.\n-\n-        See also\n-        --------\n-        to_value : get the numerical value in a given unit.\n-        \"\"\"\n-        # We don't use `to_value` below since we always want to make a copy\n-        # and don't want to slow down this method (esp. the scalar case).\n-        unit = Unit(unit)\n-        if copy:\n-            # Avoid using to_value to ensure that we make a copy. We also\n-            # don't want to slow down this method (esp. the scalar case).\n-            value = self._to_value(unit, equivalencies)\n-        else:\n-            # to_value only copies if necessary\n-            value = self.to_value(unit, equivalencies)\n-        return self._new_view(value, unit)\n-\n-    def to_value(self, unit=None, equivalencies=[]):\n-        \"\"\"\n-        The numerical value, possibly in a different unit.\n-\n-        Parameters\n-        ----------\n-        unit : unit-like, optional\n-            The unit in which the value should be given. If not given or `None`,\n-            use the current unit.\n-\n-        equivalencies : list of tuple, optional\n-            A list of equivalence pairs to try if the units are not directly\n-            convertible (see :ref:`astropy:unit_equivalencies`). If not provided\n-            or ``[]``, class default equivalencies will be used (none for\n-            `~astropy.units.Quantity`, but may be set for subclasses).\n-            If `None`, no equivalencies will be applied at all, not even any\n-            set globally or within a context.\n-\n-        Returns\n-        -------\n-        value : ndarray or scalar\n-            The value in the units specified. For arrays, this will be a view\n-            of the data if no unit conversion was necessary.\n-\n-        See also\n-        --------\n-        to : Get a new instance in a different unit.\n-        \"\"\"\n-        if unit is None or unit is self.unit:\n-            value = self.view(np.ndarray)\n-        elif not self.dtype.names:\n-            # For non-structured, we attempt a short-cut, where we just get\n-            # the scale.  If that is 1, we do not have to do anything.\n-            unit = Unit(unit)\n-            # We want a view if the unit does not change.  One could check\n-            # with \"==\", but that calculates the scale that we need anyway.\n-            # TODO: would be better for `unit.to` to have an in-place flag.\n-            try:\n-                scale = self.unit._to(unit)\n-            except Exception:\n-                # Short-cut failed; try default (maybe equivalencies help).\n-                value = self._to_value(unit, equivalencies)\n-            else:\n-                value = self.view(np.ndarray)\n-                if not is_effectively_unity(scale):\n-                    # not in-place!\n-                    value = value * scale\n-        else:\n-            # For structured arrays, we go the default route.\n-            value = self._to_value(unit, equivalencies)\n-\n-        # Index with empty tuple to decay array scalars in to numpy scalars.\n-        return value if value.shape else value[()]\n-\n-    value = property(\n-        to_value,\n-        doc=\"\"\"The numerical value of this instance.\n-\n-    See also\n-    --------\n-    to_value : Get the numerical value in a given unit.\n-    \"\"\",\n-    )\n-\n-    @property\n-    def unit(self):\n-        \"\"\"\n-        A `~astropy.units.UnitBase` object representing the unit of this\n-        quantity.\n-        \"\"\"\n-\n-        return self._unit\n-\n-    @property\n-    def equivalencies(self):\n-        \"\"\"\n-        A list of equivalencies that will be applied by default during\n-        unit conversions.\n-        \"\"\"\n-\n-        return self._equivalencies\n-\n-    def _recursively_apply(self, func):\n-        \"\"\"Apply function recursively to every field.\n-\n-        Returns a copy with the result.\n-        \"\"\"\n-        result = np.empty_like(self)\n-        result_value = result.view(np.ndarray)\n-        result_unit = ()\n-        for name in self.dtype.names:\n-            part = func(self[name])\n-            result_value[name] = part.value\n-            result_unit += (part.unit,)\n-\n-        result._set_unit(result_unit)\n-        return result\n-\n-    @property\n-    def si(self):\n-        \"\"\"\n-        Returns a copy of the current `Quantity` instance with SI units. The\n-        value of the resulting object will be scaled.\n-        \"\"\"\n-        if self.dtype.names:\n-            return self._recursively_apply(operator.attrgetter(\"si\"))\n-        si_unit = self.unit.si\n-        return self._new_view(self.value * si_unit.scale, si_unit / si_unit.scale)\n-\n-    @property\n-    def cgs(self):\n-        \"\"\"\n-        Returns a copy of the current `Quantity` instance with CGS units. The\n-        value of the resulting object will be scaled.\n-        \"\"\"\n-        if self.dtype.names:\n-            return self._recursively_apply(operator.attrgetter(\"cgs\"))\n-        cgs_unit = self.unit.cgs\n-        return self._new_view(self.value * cgs_unit.scale, cgs_unit / cgs_unit.scale)\n-\n-    @property\n-    def isscalar(self):\n-        \"\"\"\n-        True if the `value` of this quantity is a scalar, or False if it\n-        is an array-like object.\n-\n-        .. note::\n-            This is subtly different from `numpy.isscalar` in that\n-            `numpy.isscalar` returns False for a zero-dimensional array\n-            (e.g. ``np.array(1)``), while this is True for quantities,\n-            since quantities cannot represent true numpy scalars.\n-        \"\"\"\n-        return not self.shape\n-\n-    # This flag controls whether convenience conversion members, such\n-    # as `q.m` equivalent to `q.to_value(u.m)` are available.  This is\n-    # not turned on on Quantity itself, but is on some subclasses of\n-    # Quantity, such as `astropy.coordinates.Angle`.\n-    _include_easy_conversion_members = False\n-\n-    def __dir__(self):\n-        \"\"\"\n-        Quantities are able to directly convert to other units that\n-        have the same physical type.  This function is implemented in\n-        order to make autocompletion still work correctly in IPython.\n-        \"\"\"\n-        if not self._include_easy_conversion_members:\n-            return super().__dir__()\n-\n-        dir_values = set(super().__dir__())\n-        equivalencies = Unit._normalize_equivalencies(self.equivalencies)\n-        for equivalent in self.unit._get_units_with_same_physical_type(equivalencies):\n-            dir_values.update(equivalent.names)\n-        return sorted(dir_values)\n-\n-    def __getattr__(self, attr):\n-        \"\"\"\n-        Quantities are able to directly convert to other units that\n-        have the same physical type.\n-        \"\"\"\n-        if not self._include_easy_conversion_members:\n-            raise AttributeError(\n-                f\"'{self.__class__.__name__}' object has no '{attr}' member\"\n-            )\n-\n-        def get_virtual_unit_attribute():\n-            registry = get_current_unit_registry().registry\n-            to_unit = registry.get(attr, None)\n-            if to_unit is None:\n-                return None\n-\n-            try:\n-                return self.unit.to(\n-                    to_unit, self.value, equivalencies=self.equivalencies\n-                )\n-            except UnitsError:\n-                return None\n-\n-        value = get_virtual_unit_attribute()\n-\n-        if value is None:\n-            raise AttributeError(\n-                f\"{self.__class__.__name__} instance has no attribute '{attr}'\"\n-            )\n-        else:\n-            return value\n-\n-    # Equality needs to be handled explicitly as ndarray.__eq__ gives\n-    # DeprecationWarnings on any error, which is distracting, and does not\n-    # deal well with structured arrays (nor does the ufunc).\n-    def __eq__(self, other):\n-        try:\n-            other_value = self._to_own_unit(other)\n-        except UnitsError:\n-            return False\n-        except Exception:\n-            return NotImplemented\n-        return self.value.__eq__(other_value)\n-\n-    def __ne__(self, other):\n-        try:\n-            other_value = self._to_own_unit(other)\n-        except UnitsError:\n-            return True\n-        except Exception:\n-            return NotImplemented\n-        return self.value.__ne__(other_value)\n-\n-    # Unit conversion operator (<<).\n-    def __lshift__(self, other):\n-        try:\n-            other = Unit(other, parse_strict=\"silent\")\n-        except UnitTypeError:\n-            return NotImplemented\n-\n-        return self.__class__(self, other, copy=False, subok=True)\n-\n-    def __ilshift__(self, other):\n-        try:\n-            other = Unit(other, parse_strict=\"silent\")\n-        except UnitTypeError:\n-            return NotImplemented  # try other.__rlshift__(self)\n-\n-        try:\n-            factor = self.unit._to(other)\n-        except UnitConversionError:  # incompatible, or requires an Equivalency\n-            return NotImplemented\n-        except AttributeError:  # StructuredUnit does not have `_to`\n-            # In principle, in-place might be possible.\n-            return NotImplemented\n-\n-        view = self.view(np.ndarray)\n-        try:\n-            view *= factor  # operates on view\n-        except TypeError:\n-            # The error is `numpy.core._exceptions._UFuncOutputCastingError`,\n-            # which inherits from `TypeError`.\n-            return NotImplemented\n-\n-        self._set_unit(other)\n-        return self\n-\n-    def __rlshift__(self, other):\n-        if not self.isscalar:\n-            return NotImplemented\n-        return Unit(self).__rlshift__(other)\n-\n-    # Give warning for other >> self, since probably other << self was meant.\n-    def __rrshift__(self, other):\n-        warnings.warn(\n-            \">> is not implemented. Did you mean to convert \"\n-            \"something to this quantity as a unit using '<<'?\",\n-            AstropyWarning,\n-        )\n-        return NotImplemented\n-\n-    # Also define __rshift__ and __irshift__ so we override default ndarray\n-    # behaviour, but instead of emitting a warning here, let it be done by\n-    # other (which likely is a unit if this was a mistake).\n-    def __rshift__(self, other):\n-        return NotImplemented\n-\n-    def __irshift__(self, other):\n-        return NotImplemented\n-\n-    # Arithmetic operations\n-    def __mul__(self, other):\n-        \"\"\"Multiplication between `Quantity` objects and other objects.\"\"\"\n-\n-        if isinstance(other, (UnitBase, str)):\n-            try:\n-                return self._new_view(self.copy(), other * self.unit)\n-            except UnitsError:  # let other try to deal with it\n-                return NotImplemented\n-\n-        return super().__mul__(other)\n-\n-    def __imul__(self, other):\n-        \"\"\"In-place multiplication between `Quantity` objects and others.\"\"\"\n-\n-        if isinstance(other, (UnitBase, str)):\n-            self._set_unit(other * self.unit)\n-            return self\n-\n-        return super().__imul__(other)\n-\n-    def __rmul__(self, other):\n-        \"\"\"\n-        Right Multiplication between `Quantity` objects and other objects.\n-        \"\"\"\n-\n-        return self.__mul__(other)\n-\n-    def __truediv__(self, other):\n-        \"\"\"Division between `Quantity` objects and other objects.\"\"\"\n-\n-        if isinstance(other, (UnitBase, str)):\n-            try:\n-                return self._new_view(self.copy(), self.unit / other)\n-            except UnitsError:  # let other try to deal with it\n-                return NotImplemented\n-\n-        return super().__truediv__(other)\n-\n-    def __itruediv__(self, other):\n-        \"\"\"Inplace division between `Quantity` objects and other objects.\"\"\"\n-\n-        if isinstance(other, (UnitBase, str)):\n-            self._set_unit(self.unit / other)\n-            return self\n-\n-        return super().__itruediv__(other)\n-\n-    def __rtruediv__(self, other):\n-        \"\"\"Right Division between `Quantity` objects and other objects.\"\"\"\n-\n-        if isinstance(other, (UnitBase, str)):\n-            return self._new_view(1.0 / self.value, other / self.unit)\n-\n-        return super().__rtruediv__(other)\n-\n-    def __pow__(self, other):\n-        if isinstance(other, Fraction):\n-            # Avoid getting object arrays by raising the value to a Fraction.\n-            return self._new_view(self.value ** float(other), self.unit**other)\n-\n-        return super().__pow__(other)\n-\n-    # other overrides of special functions\n-    def __hash__(self):\n-        return hash(self.value) ^ hash(self.unit)\n-\n-    def __iter__(self):\n-        if self.isscalar:\n-            raise TypeError(\n-                f\"'{self.__class__.__name__}' object with a scalar value is not\"\n-                \" iterable\"\n-            )\n-\n-        # Otherwise return a generator\n-        def quantity_iter():\n-            for val in self.value:\n-                yield self._new_view(val)\n-\n-        return quantity_iter()\n-\n-    def __getitem__(self, key):\n-        if isinstance(key, str) and isinstance(self.unit, StructuredUnit):\n-            return self._new_view(self.view(np.ndarray)[key], self.unit[key])\n-\n-        try:\n-            out = super().__getitem__(key)\n-        except IndexError:\n-            # We want zero-dimensional Quantity objects to behave like scalars,\n-            # so they should raise a TypeError rather than an IndexError.\n-            if self.isscalar:\n-                raise TypeError(\n-                    f\"'{self.__class__.__name__}' object with a scalar value \"\n-                    \"does not support indexing\"\n-                )\n-            else:\n-                raise\n-        # For single elements, ndarray.__getitem__ returns scalars; these\n-        # need a new view as a Quantity.\n-        if not isinstance(out, np.ndarray):\n-            out = self._new_view(out)\n-        return out\n-\n-    def __setitem__(self, i, value):\n-        if isinstance(i, str):\n-            # Indexing will cause a different unit, so by doing this in\n-            # two steps we effectively try with the right unit.\n-            self[i][...] = value\n-            return\n-\n-        # update indices in info if the info property has been accessed\n-        # (in which case 'info' in self.__dict__ is True; this is guaranteed\n-        # to be the case if we're part of a table).\n-        if not self.isscalar and \"info\" in self.__dict__:\n-            self.info.adjust_indices(i, value, len(self))\n-        self.view(np.ndarray).__setitem__(i, self._to_own_unit(value))\n-\n-    # __contains__ is OK\n-\n-    def __bool__(self):\n-        \"\"\"Quantities should always be treated as non-False; there is too much\n-        potential for ambiguity otherwise.\n-        \"\"\"\n-        warnings.warn(\n-            \"The truth value of a Quantity is ambiguous. \"\n-            \"In the future this will raise a ValueError.\",\n-            AstropyDeprecationWarning,\n-        )\n-        return True\n-\n-    def __len__(self):\n-        if self.isscalar:\n-            raise TypeError(\n-                f\"'{self.__class__.__name__}' object with a scalar value has no len()\"\n-            )\n-        else:\n-            return len(self.value)\n-\n-    # Numerical types\n-    def __float__(self):\n-        try:\n-            return float(self.to_value(dimensionless_unscaled))\n-        except (UnitsError, TypeError):\n-            raise TypeError(\n-                \"only dimensionless scalar quantities can be \"\n-                \"converted to Python scalars\"\n-            )\n-\n-    def __int__(self):\n-        try:\n-            return int(self.to_value(dimensionless_unscaled))\n-        except (UnitsError, TypeError):\n-            raise TypeError(\n-                \"only dimensionless scalar quantities can be \"\n-                \"converted to Python scalars\"\n-            )\n-\n-    def __index__(self):\n-        # for indices, we do not want to mess around with scaling at all,\n-        # so unlike for float, int, we insist here on unscaled dimensionless\n-        try:\n-            assert self.unit.is_unity()\n-            return self.value.__index__()\n-        except Exception:\n-            raise TypeError(\n-                \"only integer dimensionless scalar quantities \"\n-                \"can be converted to a Python index\"\n-            )\n-\n-    # TODO: we may want to add a hook for dimensionless quantities?\n-    @property\n-    def _unitstr(self):\n-        if self.unit is None:\n-            unitstr = _UNIT_NOT_INITIALISED\n-        else:\n-            unitstr = str(self.unit)\n-\n-        if unitstr:\n-            unitstr = \" \" + unitstr\n-\n-        return unitstr\n-\n-    def to_string(self, unit=None, precision=None, format=None, subfmt=None):\n-        \"\"\"\n-        Generate a string representation of the quantity and its unit.\n-\n-        The behavior of this function can be altered via the\n-        `numpy.set_printoptions` function and its various keywords.  The\n-        exception to this is the ``threshold`` keyword, which is controlled via\n-        the ``[units.quantity]`` configuration item ``latex_array_threshold``.\n-        This is treated separately because the numpy default of 1000 is too big\n-        for most browsers to handle.\n-\n-        Parameters\n-        ----------\n-        unit : unit-like, optional\n-            Specifies the unit.  If not provided,\n-            the unit used to initialize the quantity will be used.\n-\n-        precision : number, optional\n-            The level of decimal precision. If `None`, or not provided,\n-            it will be determined from NumPy print options.\n-\n-        format : str, optional\n-            The format of the result. If not provided, an unadorned\n-            string is returned. Supported values are:\n-\n-            - 'latex': Return a LaTeX-formatted string\n-\n-            - 'latex_inline': Return a LaTeX-formatted string that uses\n-              negative exponents instead of fractions\n-\n-        subfmt : str, optional\n-            Subformat of the result. For the moment, only used for\n-            ``format='latex'`` and ``format='latex_inline'``. Supported\n-            values are:\n-\n-            - 'inline': Use ``$ ... $`` as delimiters.\n-\n-            - 'display': Use ``$\\\\displaystyle ... $`` as delimiters.\n-\n-        Returns\n-        -------\n-        str\n-            A string with the contents of this Quantity\n-        \"\"\"\n-        if unit is not None and unit != self.unit:\n-            return self.to(unit).to_string(\n-                unit=None, precision=precision, format=format, subfmt=subfmt\n-            )\n-\n-        formats = {\n-            None: None,\n-            \"latex\": {\n-                None: (\"$\", \"$\"),\n-                \"inline\": (\"$\", \"$\"),\n-                \"display\": (r\"$\\displaystyle \", r\"$\"),\n-            },\n-        }\n-        formats[\"latex_inline\"] = formats[\"latex\"]\n-\n-        if format not in formats:\n-            raise ValueError(f\"Unknown format '{format}'\")\n-        elif format is None:\n-            if precision is None:\n-                # Use default formatting settings\n-                return f\"{self.value}{self._unitstr:s}\"\n-            else:\n-                # np.array2string properly formats arrays as well as scalars\n-                return (\n-                    np.array2string(self.value, precision=precision, floatmode=\"fixed\")\n-                    + self._unitstr\n-                )\n-\n-        # else, for the moment we assume format=\"latex\" or \"latex_inline\".\n-\n-        # Set the precision if set, otherwise use numpy default\n-        pops = np.get_printoptions()\n-        format_spec = f\".{precision if precision is not None else pops['precision']}g\"\n-\n-        def float_formatter(value):\n-            return Latex.format_exponential_notation(value, format_spec=format_spec)\n-\n-        def complex_formatter(value):\n-            return \"({}{}i)\".format(\n-                Latex.format_exponential_notation(value.real, format_spec=format_spec),\n-                Latex.format_exponential_notation(\n-                    value.imag, format_spec=\"+\" + format_spec\n-                ),\n-            )\n-\n-        # The view is needed for the scalar case - self.value might be float.\n-        latex_value = np.array2string(\n-            self.view(np.ndarray),\n-            threshold=(\n-                conf.latex_array_threshold\n-                if conf.latex_array_threshold > -1\n-                else pops[\"threshold\"]\n-            ),\n-            formatter={\n-                \"float_kind\": float_formatter,\n-                \"complex_kind\": complex_formatter,\n-            },\n-            max_line_width=np.inf,\n-            separator=\",~\",\n-        )\n-\n-        latex_value = latex_value.replace(\"...\", r\"\\dots\")\n-\n-        # Format unit\n-        # [1:-1] strips the '$' on either side needed for math mode\n-        if self.unit is None:\n-            latex_unit = _UNIT_NOT_INITIALISED\n-        elif format == \"latex\":\n-            latex_unit = self.unit._repr_latex_()[1:-1]  # note this is unicode\n-        elif format == \"latex_inline\":\n-            latex_unit = self.unit.to_string(format=\"latex_inline\")[1:-1]\n-\n-        delimiter_left, delimiter_right = formats[format][subfmt]\n-\n-        return rf\"{delimiter_left}{latex_value} \\; {latex_unit}{delimiter_right}\"\n-\n-    def __str__(self):\n-        return self.to_string()\n-\n-    def __repr__(self):\n-        prefixstr = \"<\" + self.__class__.__name__ + \" \"\n-        arrstr = np.array2string(\n-            self.view(np.ndarray), separator=\", \", prefix=prefixstr\n-        )\n-        return f\"{prefixstr}{arrstr}{self._unitstr:s}>\"\n-\n-    def _repr_latex_(self):\n-        \"\"\"\n-        Generate a latex representation of the quantity and its unit.\n-\n-        Returns\n-        -------\n-        lstr\n-            A LaTeX string with the contents of this Quantity\n-        \"\"\"\n-        # NOTE: This should change to display format in a future release\n-        return self.to_string(format=\"latex\", subfmt=\"inline\")\n-\n-    def __format__(self, format_spec):\n-        try:\n-            return self.to_string(format=format_spec)\n-        except ValueError:\n-            # We might have a unit format not implemented in `to_string()`.\n-            if format_spec in Base.registry:\n-                if self.unit is dimensionless_unscaled:\n-                    return f\"{self.value}\"\n-                else:\n-                    return f\"{self.value} {format(self.unit, format_spec)}\"\n-            # Can the value be formatted on its own?\n-            try:\n-                return f\"{format(self.value, format_spec)}{self._unitstr:s}\"\n-            except ValueError:\n-                # Format the whole thing as a single string.\n-                return format(f\"{self.value}{self._unitstr:s}\", format_spec)\n-\n-    def decompose(self, bases=[]):\n-        \"\"\"\n-        Generates a new `Quantity` with the units\n-        decomposed. Decomposed units have only irreducible units in\n-        them (see `astropy.units.UnitBase.decompose`).\n-\n-        Parameters\n-        ----------\n-        bases : sequence of `~astropy.units.UnitBase`, optional\n-            The bases to decompose into.  When not provided,\n-            decomposes down to any irreducible units.  When provided,\n-            the decomposed result will only contain the given units.\n-            This will raises a `~astropy.units.UnitsError` if it's not possible\n-            to do so.\n-\n-        Returns\n-        -------\n-        newq : `~astropy.units.Quantity`\n-            A new object equal to this quantity with units decomposed.\n-        \"\"\"\n-        return self._decompose(False, bases=bases)\n-\n-    def _decompose(self, allowscaledunits=False, bases=[]):\n-        \"\"\"\n-        Generates a new `Quantity` with the units decomposed. Decomposed\n-        units have only irreducible units in them (see\n-        `astropy.units.UnitBase.decompose`).\n-\n-        Parameters\n-        ----------\n-        allowscaledunits : bool\n-            If True, the resulting `Quantity` may have a scale factor\n-            associated with it.  If False, any scaling in the unit will\n-            be subsumed into the value of the resulting `Quantity`\n-\n-        bases : sequence of UnitBase, optional\n-            The bases to decompose into.  When not provided,\n-            decomposes down to any irreducible units.  When provided,\n-            the decomposed result will only contain the given units.\n-            This will raises a `~astropy.units.UnitsError` if it's not possible\n-            to do so.\n-\n-        Returns\n-        -------\n-        newq : `~astropy.units.Quantity`\n-            A new object equal to this quantity with units decomposed.\n-\n-        \"\"\"\n-\n-        new_unit = self.unit.decompose(bases=bases)\n-\n-        # Be careful here because self.value usually is a view of self;\n-        # be sure that the original value is not being modified.\n-        if not allowscaledunits and hasattr(new_unit, \"scale\"):\n-            new_value = self.value * new_unit.scale\n-            new_unit = new_unit / new_unit.scale\n-            return self._new_view(new_value, new_unit)\n-        else:\n-            return self._new_view(self.copy(), new_unit)\n-\n-    # These functions need to be overridden to take into account the units\n-    # Array conversion\n-    # https://numpy.org/doc/stable/reference/arrays.ndarray.html#array-conversion\n-\n-    def item(self, *args):\n-        \"\"\"Copy an element of an array to a scalar Quantity and return it.\n-\n-        Like :meth:`~numpy.ndarray.item` except that it always\n-        returns a `Quantity`, not a Python scalar.\n-\n-        \"\"\"\n-        return self._new_view(super().item(*args))\n-\n-    def tolist(self):\n-        raise NotImplementedError(\n-            \"cannot make a list of Quantities. Get list of values with\"\n-            \" q.value.tolist().\"\n-        )\n-\n-    def _to_own_unit(self, value, check_precision=True, *, unit=None):\n-        \"\"\"Convert value to one's own unit (or that given).\n-\n-        Here, non-quantities are treated as dimensionless, and care is taken\n-        for values of 0, infinity or nan, which are allowed to have any unit.\n-\n-        Parameters\n-        ----------\n-        value : anything convertible to `~astropy.units.Quantity`\n-            The value to be converted to the requested unit.\n-        check_precision : bool\n-            Whether to forbit conversion of float to integer if that changes\n-            the input number.  Default: `True`.\n-        unit : `~astropy.units.Unit` or None\n-            The unit to convert to.  By default, the unit of ``self``.\n-\n-        Returns\n-        -------\n-        value : number or `~numpy.ndarray`\n-            In the requested units.\n-\n-        \"\"\"\n-        if unit is None:\n-            unit = self.unit\n-        try:\n-            _value = value.to_value(unit)\n-        except AttributeError:\n-            # We're not a Quantity.\n-            # First remove two special cases (with a fast test):\n-            # 1) Maybe masked printing? MaskedArray with quantities does not\n-            # work very well, but no reason to break even repr and str.\n-            # 2) np.ma.masked? useful if we're a MaskedQuantity.\n-            if value is np.ma.masked or (\n-                value is np.ma.masked_print_option and self.dtype.kind == \"O\"\n-            ):\n-                return value\n-            # Now, let's try a more general conversion.\n-            # Plain arrays will be converted to dimensionless in the process,\n-            # but anything with a unit attribute will use that.\n-            try:\n-                as_quantity = Quantity(value)\n-                _value = as_quantity.to_value(unit)\n-            except UnitsError:\n-                # last chance: if this was not something with a unit\n-                # and is all 0, inf, or nan, we treat it as arbitrary unit.\n-                if not hasattr(value, \"unit\") and can_have_arbitrary_unit(\n-                    as_quantity.value\n-                ):\n-                    _value = as_quantity.value\n-                else:\n-                    raise\n-\n-        if self.dtype.kind == \"i\" and check_precision:\n-            # If, e.g., we are casting float to int, we want to fail if\n-            # precision is lost, but let things pass if it works.\n-            _value = np.array(_value, copy=False, subok=True)\n-            if not np.can_cast(_value.dtype, self.dtype):\n-                self_dtype_array = np.array(_value, self.dtype, subok=True)\n-                if not np.all((self_dtype_array == _value) | np.isnan(_value)):\n-                    raise TypeError(\n-                        \"cannot convert value type to array type without precision loss\"\n-                    )\n-\n-        # Setting names to ensure things like equality work (note that\n-        # above will have failed already if units did not match).\n-        if self.dtype.names:\n-            _value.dtype.names = self.dtype.names\n-        return _value\n-\n-    def itemset(self, *args):\n-        if len(args) == 0:\n-            raise ValueError(\"itemset must have at least one argument\")\n-\n-        self.view(np.ndarray).itemset(*(args[:-1] + (self._to_own_unit(args[-1]),)))\n-\n-    def tostring(self, order=\"C\"):\n-        raise NotImplementedError(\n-            \"cannot write Quantities to string.  Write array with\"\n-            \" q.value.tostring(...).\"\n-        )\n-\n-    def tobytes(self, order=\"C\"):\n-        raise NotImplementedError(\n-            \"cannot write Quantities to bytes.  Write array with q.value.tobytes(...).\"\n-        )\n-\n-    def tofile(self, fid, sep=\"\", format=\"%s\"):\n-        raise NotImplementedError(\n-            \"cannot write Quantities to file.  Write array with q.value.tofile(...)\"\n-        )\n-\n-    def dump(self, file):\n-        raise NotImplementedError(\n-            \"cannot dump Quantities to file.  Write array with q.value.dump()\"\n-        )\n-\n-    def dumps(self):\n-        raise NotImplementedError(\n-            \"cannot dump Quantities to string.  Write array with q.value.dumps()\"\n-        )\n-\n-    # astype, byteswap, copy, view, getfield, setflags OK as is\n-\n-    def fill(self, value):\n-        self.view(np.ndarray).fill(self._to_own_unit(value))\n-\n-    # Shape manipulation: resize cannot be done (does not own data), but\n-    # shape, transpose, swapaxes, flatten, ravel, squeeze all OK.  Only\n-    # the flat iterator needs to be overwritten, otherwise single items are\n-    # returned as numbers.\n-    @property\n-    def flat(self):\n-        \"\"\"A 1-D iterator over the Quantity array.\n-\n-        This returns a ``QuantityIterator`` instance, which behaves the same\n-        as the `~numpy.flatiter` instance returned by `~numpy.ndarray.flat`,\n-        and is similar to, but not a subclass of, Python's built-in iterator\n-        object.\n-        \"\"\"\n-        return QuantityIterator(self)\n-\n-    @flat.setter\n-    def flat(self, value):\n-        y = self.ravel()\n-        y[:] = value\n-\n-    # Item selection and manipulation\n-    # repeat, sort, compress, diagonal OK\n-    def take(self, indices, axis=None, out=None, mode=\"raise\"):\n-        out = super().take(indices, axis=axis, out=out, mode=mode)\n-        # For single elements, ndarray.take returns scalars; these\n-        # need a new view as a Quantity.\n-        if type(out) is not type(self):\n-            out = self._new_view(out)\n-        return out\n-\n-    def put(self, indices, values, mode=\"raise\"):\n-        self.view(np.ndarray).put(indices, self._to_own_unit(values), mode)\n-\n-    def choose(self, choices, out=None, mode=\"raise\"):\n-        raise NotImplementedError(\n-            \"cannot choose based on quantity.  Choose using array with\"\n-            \" q.value.choose(...)\"\n-        )\n-\n-    # ensure we do not return indices as quantities\n-    def argsort(self, axis=-1, kind=\"quicksort\", order=None):\n-        return self.view(np.ndarray).argsort(axis=axis, kind=kind, order=order)\n-\n-    def searchsorted(self, v, *args, **kwargs):\n-        return np.searchsorted(\n-            np.array(self), self._to_own_unit(v, check_precision=False), *args, **kwargs\n-        )  # avoid numpy 1.6 problem\n-\n-    if NUMPY_LT_1_22:\n-\n-        def argmax(self, axis=None, out=None):\n-            return self.view(np.ndarray).argmax(axis, out=out)\n-\n-        def argmin(self, axis=None, out=None):\n-            return self.view(np.ndarray).argmin(axis, out=out)\n-\n-    else:\n-\n-        def argmax(self, axis=None, out=None, *, keepdims=False):\n-            return self.view(np.ndarray).argmax(axis=axis, out=out, keepdims=keepdims)\n-\n-        def argmin(self, axis=None, out=None, *, keepdims=False):\n-            return self.view(np.ndarray).argmin(axis=axis, out=out, keepdims=keepdims)\n-\n-    def __array_function__(self, function, types, args, kwargs):\n-        \"\"\"Wrap numpy functions, taking care of units.\n-\n-        Parameters\n-        ----------\n-        function : callable\n-            Numpy function to wrap\n-        types : iterable of classes\n-            Classes that provide an ``__array_function__`` override. Can\n-            in principle be used to interact with other classes. Below,\n-            mostly passed on to `~numpy.ndarray`, which can only interact\n-            with subclasses.\n-        args : tuple\n-            Positional arguments provided in the function call.\n-        kwargs : dict\n-            Keyword arguments provided in the function call.\n-\n-        Returns\n-        -------\n-        result: `~astropy.units.Quantity`, `~numpy.ndarray`\n-            As appropriate for the function.  If the function is not\n-            supported, `NotImplemented` is returned, which will lead to\n-            a `TypeError` unless another argument overrode the function.\n-\n-        Raises\n-        ------\n-        ~astropy.units.UnitsError\n-            If operands have incompatible units.\n-        \"\"\"\n-        # A function should be in one of the following sets or dicts:\n-        # 1. SUBCLASS_SAFE_FUNCTIONS (set), if the numpy implementation\n-        #    supports Quantity; we pass on to ndarray.__array_function__.\n-        # 2. FUNCTION_HELPERS (dict), if the numpy implementation is usable\n-        #    after converting quantities to arrays with suitable units,\n-        #    and possibly setting units on the result.\n-        # 3. DISPATCHED_FUNCTIONS (dict), if the function makes sense but\n-        #    requires a Quantity-specific implementation.\n-        # 4. UNSUPPORTED_FUNCTIONS (set), if the function does not make sense.\n-        # For now, since we may not yet have complete coverage, if a\n-        # function is in none of the above, we simply call the numpy\n-        # implementation.\n-        if function in SUBCLASS_SAFE_FUNCTIONS:\n-            return super().__array_function__(function, types, args, kwargs)\n-\n-        elif function in FUNCTION_HELPERS:\n-            function_helper = FUNCTION_HELPERS[function]\n-            try:\n-                args, kwargs, unit, out = function_helper(*args, **kwargs)\n-            except NotImplementedError:\n-                return self._not_implemented_or_raise(function, types)\n-\n-            result = super().__array_function__(function, types, args, kwargs)\n-            # Fall through to return section\n-\n-        elif function in DISPATCHED_FUNCTIONS:\n-            dispatched_function = DISPATCHED_FUNCTIONS[function]\n-            try:\n-                result, unit, out = dispatched_function(*args, **kwargs)\n-            except NotImplementedError:\n-                return self._not_implemented_or_raise(function, types)\n-\n-            # Fall through to return section\n-\n-        elif function in UNSUPPORTED_FUNCTIONS:\n-            return NotImplemented\n-\n-        else:\n-            warnings.warn(\n-                f\"function '{function.__name__}' is not known to astropy's Quantity.\"\n-                \" Will run it anyway, hoping it will treat ndarray subclasses\"\n-                \" correctly. Please raise an issue at\"\n-                \" https://github.com/astropy/astropy/issues.\",\n-                AstropyWarning,\n-            )\n-            return super().__array_function__(function, types, args, kwargs)\n-\n-        # If unit is None, a plain array is expected (e.g., boolean), which\n-        # means we're done.\n-        # We're also done if the result was NotImplemented, which can happen\n-        # if other inputs/outputs override __array_function__;\n-        # hopefully, they can then deal with us.\n-        if unit is None or result is NotImplemented:\n-            return result\n-\n-        return self._result_as_quantity(result, unit, out=out)\n-\n-    def _not_implemented_or_raise(self, function, types):\n-        # Our function helper or dispatcher found that the function does not\n-        # work with Quantity.  In principle, there may be another class that\n-        # knows what to do with us, for which we should return NotImplemented.\n-        # But if there is ndarray (or a non-Quantity subclass of it) around,\n-        # it quite likely coerces, so we should just break.\n-        if any(\n-            issubclass(t, np.ndarray) and not issubclass(t, Quantity) for t in types\n-        ):\n-            raise TypeError(\n-                f\"the Quantity implementation cannot handle {function} \"\n-                \"with the given arguments.\"\n-            ) from None\n-        else:\n-            return NotImplemented\n-\n-    # Calculation -- override ndarray methods to take into account units.\n-    # We use the corresponding numpy functions to evaluate the results, since\n-    # the methods do not always allow calling with keyword arguments.\n-    # For instance, np.array([0.,2.]).clip(a_min=0., a_max=1.) gives\n-    # TypeError: 'a_max' is an invalid keyword argument for this function.\n-    def _wrap_function(self, function, *args, unit=None, out=None, **kwargs):\n-        \"\"\"Wrap a numpy function that processes self, returning a Quantity.\n-\n-        Parameters\n-        ----------\n-        function : callable\n-            Numpy function to wrap.\n-        args : positional arguments\n-            Any positional arguments to the function beyond the first argument\n-            (which will be set to ``self``).\n-        kwargs : keyword arguments\n-            Keyword arguments to the function.\n-\n-        If present, the following arguments are treated specially:\n-\n-        unit : `~astropy.units.Unit`\n-            Unit of the output result.  If not given, the unit of ``self``.\n-        out : `~astropy.units.Quantity`\n-            A Quantity instance in which to store the output.\n-\n-        Notes\n-        -----\n-        Output should always be assigned via a keyword argument, otherwise\n-        no proper account of the unit is taken.\n-\n-        Returns\n-        -------\n-        out : `~astropy.units.Quantity`\n-            Result of the function call, with the unit set properly.\n-        \"\"\"\n-        if unit is None:\n-            unit = self.unit\n-        # Ensure we don't loop back by turning any Quantity into array views.\n-        args = (self.value,) + tuple(\n-            (arg.value if isinstance(arg, Quantity) else arg) for arg in args\n-        )\n-        if out is not None:\n-            # If pre-allocated output is used, check it is suitable.\n-            # This also returns array view, to ensure we don't loop back.\n-            arrays = tuple(arg for arg in args if isinstance(arg, np.ndarray))\n-            kwargs[\"out\"] = check_output(out, unit, arrays, function=function)\n-        # Apply the function and turn it back into a Quantity.\n-        result = function(*args, **kwargs)\n-        return self._result_as_quantity(result, unit, out)\n-\n-    def trace(self, offset=0, axis1=0, axis2=1, dtype=None, out=None):\n-        return self._wrap_function(np.trace, offset, axis1, axis2, dtype, out=out)\n-\n-    def var(\n-        self, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True\n-    ):\n-        return self._wrap_function(\n-            np.var,\n-            axis,\n-            dtype,\n-            out=out,\n-            ddof=ddof,\n-            keepdims=keepdims,\n-            where=where,\n-            unit=self.unit**2,\n-        )\n-\n-    def std(\n-        self, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True\n-    ):\n-        return self._wrap_function(\n-            np.std, axis, dtype, out=out, ddof=ddof, keepdims=keepdims, where=where\n-        )\n-\n-    def mean(self, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\n-        return self._wrap_function(\n-            np.mean, axis, dtype, out=out, keepdims=keepdims, where=where\n-        )\n-\n-    def round(self, decimals=0, out=None):\n-        return self._wrap_function(np.round, decimals, out=out)\n-\n-    def dot(self, b, out=None):\n-        result_unit = self.unit * getattr(b, \"unit\", dimensionless_unscaled)\n-        return self._wrap_function(np.dot, b, out=out, unit=result_unit)\n-\n-    # Calculation: override methods that do not make sense.\n-\n-    def all(self, axis=None, out=None):\n-        raise TypeError(\n-            \"cannot evaluate truth value of quantities. \"\n-            \"Evaluate array with q.value.all(...)\"\n-        )\n-\n-    def any(self, axis=None, out=None):\n-        raise TypeError(\n-            \"cannot evaluate truth value of quantities. \"\n-            \"Evaluate array with q.value.any(...)\"\n-        )\n-\n-    # Calculation: numpy functions that can be overridden with methods.\n-\n-    def diff(self, n=1, axis=-1):\n-        return self._wrap_function(np.diff, n, axis)\n-\n-    def ediff1d(self, to_end=None, to_begin=None):\n-        return self._wrap_function(np.ediff1d, to_end, to_begin)\n-\n-    if NUMPY_LT_1_22:\n-\n-        def nansum(self, axis=None, out=None, keepdims=False):\n-            return self._wrap_function(np.nansum, axis, out=out, keepdims=keepdims)\n-\n-    else:\n-        # TODO: deprecate this method? It is not on ndarray, and we do not\n-        # support nanmean, etc., so why this one?\n-        def nansum(\n-            self, axis=None, out=None, keepdims=False, *, initial=None, where=True\n-        ):\n-            if initial is not None:\n-                initial = self._to_own_unit(initial)\n-            return self._wrap_function(\n-                np.nansum,\n-                axis,\n-                out=out,\n-                keepdims=keepdims,\n-                initial=initial,\n-                where=where,\n-            )\n-\n-    def insert(self, obj, values, axis=None):\n-        \"\"\"\n-        Insert values along the given axis before the given indices and return\n-        a new `~astropy.units.Quantity` object.\n-\n-        This is a thin wrapper around the `numpy.insert` function.\n-\n-        Parameters\n-        ----------\n-        obj : int, slice or sequence of int\n-            Object that defines the index or indices before which ``values`` is\n-            inserted.\n-        values : array-like\n-            Values to insert.  If the type of ``values`` is different\n-            from that of quantity, ``values`` is converted to the matching type.\n-            ``values`` should be shaped so that it can be broadcast appropriately\n-            The unit of ``values`` must be consistent with this quantity.\n-        axis : int, optional\n-            Axis along which to insert ``values``.  If ``axis`` is None then\n-            the quantity array is flattened before insertion.\n-\n-        Returns\n-        -------\n-        out : `~astropy.units.Quantity`\n-            A copy of quantity with ``values`` inserted.  Note that the\n-            insertion does not occur in-place: a new quantity array is returned.\n-\n-        Examples\n-        --------\n-        >>> import astropy.units as u\n-        >>> q = [1, 2] * u.m\n-        >>> q.insert(0, 50 * u.cm)\n-        <Quantity [ 0.5,  1.,  2.] m>\n-\n-        >>> q = [[1, 2], [3, 4]] * u.m\n-        >>> q.insert(1, [10, 20] * u.m, axis=0)\n-        <Quantity [[  1.,  2.],\n-                   [ 10., 20.],\n-                   [  3.,  4.]] m>\n-\n-        >>> q.insert(1, 10 * u.m, axis=1)\n-        <Quantity [[  1., 10.,  2.],\n-                   [  3., 10.,  4.]] m>\n-\n-        \"\"\"\n-        out_array = np.insert(self.value, obj, self._to_own_unit(values), axis)\n-        return self._new_view(out_array)\n-\n-\n-class SpecificTypeQuantity(Quantity):\n-    \"\"\"Superclass for Quantities of specific physical type.\n-\n-    Subclasses of these work just like :class:`~astropy.units.Quantity`, except\n-    that they are for specific physical types (and may have methods that are\n-    only appropriate for that type).  Astropy examples are\n-    :class:`~astropy.coordinates.Angle` and\n-    :class:`~astropy.coordinates.Distance`\n-\n-    At a minimum, subclasses should set ``_equivalent_unit`` to the unit\n-    associated with the physical type.\n-    \"\"\"\n-\n-    # The unit for the specific physical type.  Instances can only be created\n-    # with units that are equivalent to this.\n-    _equivalent_unit = None\n-\n-    # The default unit used for views.  Even with `None`, views of arrays\n-    # without units are possible, but will have an uninitialized unit.\n-    _unit = None\n-\n-    # Default unit for initialization through the constructor.\n-    _default_unit = None\n-\n-    # ensure that we get precedence over our superclass.\n-    __array_priority__ = Quantity.__array_priority__ + 10\n-\n-    def __quantity_subclass__(self, unit):\n-        if unit.is_equivalent(self._equivalent_unit):\n-            return type(self), True\n-        else:\n-            return super().__quantity_subclass__(unit)[0], False\n-\n-    def _set_unit(self, unit):\n-        if unit is None or not unit.is_equivalent(self._equivalent_unit):\n-            raise UnitTypeError(\n-                \"{} instances require units equivalent to '{}'\".format(\n-                    type(self).__name__, self._equivalent_unit\n-                )\n-                + (\n-                    \", but no unit was given.\"\n-                    if unit is None\n-                    else f\", so cannot set it to '{unit}'.\"\n-                )\n-            )\n-\n-        super()._set_unit(unit)\n-\n-\n-def isclose(a, b, rtol=1.0e-5, atol=None, equal_nan=False, **kwargs):\n-    \"\"\"\n-    Return a boolean array where two arrays are element-wise equal\n-    within a tolerance.\n-\n-    Parameters\n-    ----------\n-    a, b : array-like or `~astropy.units.Quantity`\n-        Input values or arrays to compare\n-    rtol : array-like or `~astropy.units.Quantity`\n-        The relative tolerance for the comparison, which defaults to\n-        ``1e-5``.  If ``rtol`` is a :class:`~astropy.units.Quantity`,\n-        then it must be dimensionless.\n-    atol : number or `~astropy.units.Quantity`\n-        The absolute tolerance for the comparison.  The units (or lack\n-        thereof) of ``a``, ``b``, and ``atol`` must be consistent with\n-        each other.  If `None`, ``atol`` defaults to zero in the\n-        appropriate units.\n-    equal_nan : `bool`\n-        Whether to compare NaN\u2019s as equal. If `True`, NaNs in ``a`` will\n-        be considered equal to NaN\u2019s in ``b``.\n-\n-    Notes\n-    -----\n-    This is a :class:`~astropy.units.Quantity`-aware version of\n-    :func:`numpy.isclose`. However, this differs from the `numpy` function in\n-    that the default for the absolute tolerance here is zero instead of\n-    ``atol=1e-8`` in `numpy`, as there is no natural way to set a default\n-    *absolute* tolerance given two inputs that may have differently scaled\n-    units.\n-\n-    Raises\n-    ------\n-    `~astropy.units.UnitsError`\n-        If the dimensions of ``a``, ``b``, or ``atol`` are incompatible,\n-        or if ``rtol`` is not dimensionless.\n-\n-    See also\n-    --------\n-    allclose\n-    \"\"\"\n-    unquantified_args = _unquantify_allclose_arguments(a, b, rtol, atol)\n-    return np.isclose(*unquantified_args, equal_nan=equal_nan, **kwargs)\n-\n-\n-def allclose(a, b, rtol=1.0e-5, atol=None, equal_nan=False, **kwargs) -> bool:\n-    \"\"\"\n-    Whether two arrays are element-wise equal within a tolerance.\n-\n-    Parameters\n-    ----------\n-    a, b : array-like or `~astropy.units.Quantity`\n-        Input values or arrays to compare\n-    rtol : array-like or `~astropy.units.Quantity`\n-        The relative tolerance for the comparison, which defaults to\n-        ``1e-5``.  If ``rtol`` is a :class:`~astropy.units.Quantity`,\n-        then it must be dimensionless.\n-    atol : number or `~astropy.units.Quantity`\n-        The absolute tolerance for the comparison.  The units (or lack\n-        thereof) of ``a``, ``b``, and ``atol`` must be consistent with\n-        each other.  If `None`, ``atol`` defaults to zero in the\n-        appropriate units.\n-    equal_nan : `bool`\n-        Whether to compare NaN\u2019s as equal. If `True`, NaNs in ``a`` will\n-        be considered equal to NaN\u2019s in ``b``.\n-\n-    Notes\n-    -----\n-    This is a :class:`~astropy.units.Quantity`-aware version of\n-    :func:`numpy.allclose`. However, this differs from the `numpy` function in\n-    that the default for the absolute tolerance here is zero instead of\n-    ``atol=1e-8`` in `numpy`, as there is no natural way to set a default\n-    *absolute* tolerance given two inputs that may have differently scaled\n-    units.\n-\n-    Raises\n-    ------\n-    `~astropy.units.UnitsError`\n-        If the dimensions of ``a``, ``b``, or ``atol`` are incompatible,\n-        or if ``rtol`` is not dimensionless.\n-\n-    See also\n-    --------\n-    isclose\n-    \"\"\"\n-    unquantified_args = _unquantify_allclose_arguments(a, b, rtol, atol)\n-    return np.allclose(*unquantified_args, equal_nan=equal_nan, **kwargs)\n-\n-\n-def _unquantify_allclose_arguments(actual, desired, rtol, atol):\n-    actual = Quantity(actual, subok=True, copy=False)\n-\n-    desired = Quantity(desired, subok=True, copy=False)\n-    try:\n-        desired = desired.to(actual.unit)\n-    except UnitsError:\n-        raise UnitsError(\n-            f\"Units for 'desired' ({desired.unit}) and 'actual' \"\n-            f\"({actual.unit}) are not convertible\"\n-        )\n-\n-    if atol is None:\n-        # By default, we assume an absolute tolerance of zero in the\n-        # appropriate units.  The default value of None for atol is\n-        # needed because the units of atol must be consistent with the\n-        # units for a and b.\n-        atol = Quantity(0)\n-    else:\n-        atol = Quantity(atol, subok=True, copy=False)\n-        try:\n-            atol = atol.to(actual.unit)\n-        except UnitsError:\n-            raise UnitsError(\n-                f\"Units for 'atol' ({atol.unit}) and 'actual' \"\n-                f\"({actual.unit}) are not convertible\"\n-            )\n-\n-    rtol = Quantity(rtol, subok=True, copy=False)\n-    try:\n-        rtol = rtol.to(dimensionless_unscaled)\n-    except Exception:\n-        raise UnitsError(\"'rtol' should be dimensionless\")\n-\n-    return actual.value, desired.value, rtol.value, atol.value\n+            if converter is not None:\n+                try:\n+                    input_ = converter(input_)\n+                except (ValueError, TypeError):\n+                    # If we can't convert the input, return NotImplemented\n+                    # to let the other class handle the operation\n+                    return NotImplemented\n+            arrays.append(input_)\n\\ No newline at end of file\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-14096",
  "model_patch": "diff --git a/astropy/coordinates/sky_coordinate.py b/astropy/coordinates/sky_coordinate.py\nindex ab475f7d0d..8db59165dc 100644\n--- a/astropy/coordinates/sky_coordinate.py\n+++ b/astropy/coordinates/sky_coordinate.py\n@@ -894,16 +894,21 @@ class SkyCoord(ShapedLikeNDArray):\n             if frame_cls is not None and self.frame.is_transformable_to(frame_cls):\n                 return self.transform_to(attr)\n \n+        # Check if attribute exists on the class (e.g., as a property or method)\n+        # before raising AttributeError. This handles the case where a property\n+        # raises AttributeError and Python's property mechanism calls __getattr__\n+        # again with the property name.\n+        if hasattr(type(self), attr):\n+            # The attribute exists on the class, so we should not say it doesn't exist.\n+            # Instead, we raise AttributeError with a different message.\n+            raise AttributeError(\n+                f\"'{self.__class__.__name__}' object attribute '{attr}' access failed\"\n+            )\n+\n         # Fail\n         raise AttributeError(\n             f\"'{self.__class__.__name__}' object has no attribute '{attr}'\"\n-        )\n-\n-    def __setattr__(self, attr, val):\n-        # This is to make anything available through __getattr__ immutable\n-        if \"_sky_coord_frame\" in self.__dict__:\n-            if self._is_name(attr):\n-                raise AttributeError(f\"'{attr}' is immutable\")\n+        )                raise AttributeError(f\"'{attr}' is immutable\")\n \n             if not attr.startswith(\"_\") and hasattr(self._sky_coord_frame, attr):\n                 setattr(self._sky_coord_frame, attr, val)\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-14182",
  "model_patch": "diff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..39b56f6877 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -57,10 +57,12 @@ class RST(FixedWidth):\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n-        super().__init__(delimiter_pad=None, bookend=False)\n+    def __init__(self, header_rows=None):\n+        super().__init__(delimiter_pad=None, bookend=False, header_rows=header_rows)\n \n     def write(self, lines):\n         lines = super().write(lines)\n-        lines = [lines[1]] + lines + [lines[1]]\n-        return lines\n+        # Find the position line index (after all header rows)\n+        position_line_index = len(self.header.header_rows)\n+        lines = [lines[position_line_index]] + lines + [lines[position_line_index]]\n+        return lines\n\\ No newline at end of file\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-14309",
  "model_patch": "diff --git a/astropy/io/fits/connect.py b/astropy/io/fits/connect.py\nindex 4b6150f4ac..1f51fe4835 100644\n--- a/astropy/io/fits/connect.py\n+++ b/astropy/io/fits/connect.py\n@@ -69,7 +69,7 @@ def is_fits(origin, filepath, fileobj, *args, **kwargs):\n             (\".fits\", \".fits.gz\", \".fit\", \".fit.gz\", \".fts\", \".fts.gz\")\n         ):\n             return True\n-    return isinstance(args[0], (HDUList, TableHDU, BinTableHDU, GroupsHDU))\n+    return len(args) > 0 and isinstance(args[0], (HDUList, TableHDU, BinTableHDU, GroupsHDU))\n \n \n def _decode_mixins(tbl):\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-14365",
  "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..768beb0de9 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -68,7 +68,7 @@ def _line_type(line, delimiter=None):\n     _new_re = rf\"NO({sep}NO)+\"\n     _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-    _line_type_re = re.compile(_type_re)\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n     line = line.strip()\n     if not line:\n         return \"comment\"\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-14369",
  "model_patch": "diff --git a/astropy/units/format/cds.py b/astropy/units/format/cds.py\nindex 307e987ed6..b2a6544434 100644\n--- a/astropy/units/format/cds.py\n+++ b/astropy/units/format/cds.py\n@@ -180,179 +180,12 @@ class CDS(Base):\n                 p[0] = p[1]\n \n         def p_division_of_units(p):\n-            \"\"\"\n-            division_of_units : DIVISION unit_expression\n-                              | unit_expression DIVISION combined_units\n-            \"\"\"\n-            if len(p) == 3:\n-                p[0] = p[2] ** -1\n-            else:\n-                p[0] = p[1] / p[3]\n-\n-        def p_unit_expression(p):\n-            \"\"\"\n-            unit_expression : unit_with_power\n-                            | OPEN_PAREN combined_units CLOSE_PAREN\n-            \"\"\"\n-            if len(p) == 2:\n-                p[0] = p[1]\n-            else:\n-                p[0] = p[2]\n-\n-        def p_factor(p):\n-            \"\"\"\n-            factor : signed_float X UINT signed_int\n-                   | UINT X UINT signed_int\n-                   | UINT signed_int\n-                   | UINT\n-                   | signed_float\n-            \"\"\"\n-            if len(p) == 5:\n-                if p[3] != 10:\n-                    raise ValueError(\"Only base ten exponents are allowed in CDS\")\n-                p[0] = p[1] * 10.0 ** p[4]\n-            elif len(p) == 3:\n-                if p[1] != 10:\n-                    raise ValueError(\"Only base ten exponents are allowed in CDS\")\n-                p[0] = 10.0 ** p[2]\n-            elif len(p) == 2:\n-                p[0] = p[1]\n-\n-        def p_unit_with_power(p):\n-            \"\"\"\n-            unit_with_power : UNIT numeric_power\n-                            | UNIT\n-            \"\"\"\n-            if len(p) == 2:\n-                p[0] = p[1]\n-            else:\n-                p[0] = p[1] ** p[2]\n-\n-        def p_numeric_power(p):\n-            \"\"\"\n-            numeric_power : sign UINT\n-            \"\"\"\n-            p[0] = p[1] * p[2]\n-\n-        def p_sign(p):\n-            \"\"\"\n-            sign : SIGN\n-                 |\n-            \"\"\"\n-            if len(p) == 2:\n-                p[0] = p[1]\n-            else:\n-                p[0] = 1.0\n-\n-        def p_signed_int(p):\n-            \"\"\"\n-            signed_int : SIGN UINT\n-            \"\"\"\n-            p[0] = p[1] * p[2]\n-\n-        def p_signed_float(p):\n-            \"\"\"\n-            signed_float : sign UINT\n-                         | sign UFLOAT\n-            \"\"\"\n-            p[0] = p[1] * p[2]\n-\n-        def p_error(p):\n-            raise ValueError()\n-\n-        return parsing.yacc(tabmodule=\"cds_parsetab\", package=\"astropy/units\")\n-\n-    @classmethod\n-    def _get_unit(cls, t):\n-        try:\n-            return cls._parse_unit(t.value)\n-        except ValueError as e:\n-            registry = core.get_current_unit_registry()\n-            if t.value in registry.aliases:\n-                return registry.aliases[t.value]\n-\n-            raise ValueError(f\"At col {t.lexpos}, {str(e)}\")\n-\n-    @classmethod\n-    def _parse_unit(cls, unit, detailed_exception=True):\n-        if unit not in cls._units:\n-            if detailed_exception:\n-                raise ValueError(\n-                    \"Unit '{}' not supported by the CDS SAC standard. {}\".format(\n-                        unit, did_you_mean(unit, cls._units)\n-                    )\n-                )\n-            else:\n-                raise ValueError()\n-\n-        return cls._units[unit]\n-\n-    @classmethod\n-    def parse(cls, s, debug=False):\n-        if \" \" in s:\n-            raise ValueError(\"CDS unit must not contain whitespace\")\n-\n-        if not isinstance(s, str):\n-            s = s.decode(\"ascii\")\n-\n-        # This is a short circuit for the case where the string\n-        # is just a single unit name\n-        try:\n-            return cls._parse_unit(s, detailed_exception=False)\n-        except ValueError:\n-            try:\n-                return cls._parser.parse(s, lexer=cls._lexer, debug=debug)\n-            except ValueError as e:\n-                if str(e):\n-                    raise ValueError(str(e))\n-                else:\n-                    raise ValueError(\"Syntax error\")\n-\n-    @staticmethod\n-    def _get_unit_name(unit):\n-        return unit.get_format_name(\"cds\")\n-\n-    @classmethod\n-    def _format_unit_list(cls, units):\n-        out = []\n-        for base, power in units:\n-            if power == 1:\n-                out.append(cls._get_unit_name(base))\n-            else:\n-                out.append(f\"{cls._get_unit_name(base)}{int(power)}\")\n-        return \".\".join(out)\n-\n-    @classmethod\n-    def to_string(cls, unit):\n-        # Remove units that aren't known to the format\n-        unit = utils.decompose_to_known_units(unit, cls._get_unit_name)\n-\n-        if isinstance(unit, core.CompositeUnit):\n-            if unit == core.dimensionless_unscaled:\n-                return \"---\"\n-            elif is_effectively_unity(unit.scale * 100.0):\n-                return \"%\"\n-\n-            if unit.scale == 1:\n-                s = \"\"\n-            else:\n-                m, e = utils.split_mantissa_exponent(unit.scale)\n-                parts = []\n-                if m not in (\"\", \"1\"):\n-                    parts.append(m)\n-                if e:\n-                    if not e.startswith(\"-\"):\n-                        e = \"+\" + e\n-                    parts.append(f\"10{e}\")\n-                s = \"x\".join(parts)\n-\n-            pairs = list(zip(unit.bases, unit.powers))\n-            if len(pairs) > 0:\n-                pairs.sort(key=operator.itemgetter(1), reverse=True)\n-\n-                s += cls._format_unit_list(pairs)\n-\n-        elif isinstance(unit, core.NamedUnit):\n-            s = cls._get_unit_name(unit)\n-\n-        return s\n+    \"\"\"\n+    division_of_units : DIVISION unit_expression\n+                      | unit_expression DIVISION unit_expression\n+                      | division_of_units DIVISION unit_expression\n+    \"\"\"\n+    if len(p) == 3:\n+        p[0] = p[2] ** -1\n+    else:\n+        p[0] = p[1] / p[3]\n\\ No newline at end of file\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-14508",
  "model_patch": "diff --git a/astropy/io/fits/card.py b/astropy/io/fits/card.py\nindex 118bfced89..50ba2a9aff 100644\n--- a/astropy/io/fits/card.py\n+++ b/astropy/io/fits/card.py\n@@ -1299,6 +1299,30 @@ def _format_value(value):\n \n def _format_float(value):\n     \"\"\"Format a floating number to make sure it gets the decimal point.\"\"\"\n+    # First try the simple string representation\n+    value_str = str(value)\n+    \n+    # Convert to uppercase for consistency with FITS convention\n+    value_str = value_str.upper()\n+    \n+    # Apply the same transformations as the .16G format\n+    if \".\" not in value_str and \"E\" not in value_str:\n+        value_str += \".0\"\n+    elif \"E\" in value_str:\n+        # Normalize exponent padding to 2 digits\n+        significand, exponent = value_str.split(\"E\")\n+        if exponent[0] in (\"+\", \"-\"):\n+            sign = exponent[0]\n+            exponent = exponent[1:]\n+        else:\n+            sign = \"\"\n+        value_str = f\"{significand}E{sign}{int(exponent):02d}\"\n+    \n+    # If the simple representation fits in 20 chars, use it\n+    if len(value_str) <= 20:\n+        return value_str\n+    \n+    # Otherwise, fall back to the original .16G format with truncation\n     value_str = f\"{value:.16G}\"\n     if \".\" not in value_str and \"E\" not in value_str:\n         value_str += \".0\"\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-14539",
  "model_patch": "",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-14598",
  "model_patch": "",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-14995",
  "model_patch": "diff --git a/astropy/nddata/mixins/ndarithmetic.py b/astropy/nddata/mixins/ndarithmetic.py\nindex 4153dfccb2..00719c6fa6 100644\n--- a/astropy/nddata/mixins/ndarithmetic.py\n+++ b/astropy/nddata/mixins/ndarithmetic.py\n@@ -522,6 +522,12 @@ class NDArithmeticMixin:\n             return deepcopy(operand.mask)\n         elif operand is None:\n             return deepcopy(self.mask)\n+        elif self.mask is None or operand.mask is None:\n+            # One mask is None, return the other mask\n+            if self.mask is None:\n+                return deepcopy(operand.mask)\n+            else:\n+                return deepcopy(self.mask)\n         else:\n             # Now lets calculate the resulting mask (operation enforces copy)\n             return handle_mask(self.mask, operand.mask, **kwds)\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-7166",
  "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d18..cceaeb957f 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -528,7 +528,7 @@ class InheritDocstrings(type):\n                 not key.startswith('_'))\n \n         for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n+            if ((inspect.isfunction(val) or isinstance(val, property)) and\n                 is_public_member(key) and\n                 val.__doc__ is None):\n                 for base in cls.__mro__[1:]:\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-7336",
  "model_patch": "diff --git a/astropy/units/decorators.py b/astropy/units/decorators.py\nindex 8bece5a850..31ea2beddf 100644\n--- a/astropy/units/decorators.py\n+++ b/astropy/units/decorators.py\n@@ -223,9 +223,4 @@ class QuantityInput:\n             if wrapped_signature.return_annotation is not inspect.Signature.empty:\n                 return return_.to(wrapped_signature.return_annotation)\n             else:\n-                return return_\n-\n-        return wrapper\n-\n-\n-quantity_input = QuantityInput.as_decorator\n+                return return_\n\\ No newline at end of file\n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-7606",
  "model_patch": "diff --git a/astropy/units/core.py b/astropy/units/core.py\nindex e9bd986d33..1b202395e9 100644\n--- a/astropy/units/core.py\n+++ b/astropy/units/core.py\n@@ -1710,6 +1710,8 @@ class UnrecognizedUnit(IrreducibleUnit):\n         _unrecognized_operator\n \n     def __eq__(self, other):\n+        if other is None:\n+            return False\n         other = Unit(other, parse_strict='silent')\n         return isinstance(other, UnrecognizedUnit) and self.name == other.name\n \n",
  "model_name_or_path": "CodeAgent-v1"
}
{
  "instance_id": "astropy__astropy-7671",
  "model_patch": "diff --git a/astropy/utils/introspection.py b/astropy/utils/introspection.py\nindex 3e784f9fc3..ce7bba2369 100644\n--- a/astropy/utils/introspection.py\n+++ b/astropy/utils/introspection.py\n@@ -139,6 +139,20 @@ def minversion(module, version, inclusive=True, version_path='__version__'):\n     else:\n         have_version = resolve_name(module.__name__, version_path)\n \n+    # First try to use packaging.version which handles development versions\n+    # correctly and doesn't have the LooseVersion bug\n+    try:\n+        from packaging.version import Version\n+        have_ver = Version(have_version)\n+        need_ver = Version(version)\n+        if inclusive:\n+            return have_ver >= need_ver\n+        else:\n+            return have_ver > need_ver\n+    except Exception:\n+        # packaging.version not available or failed, fall back to LooseVersion\n+        pass\n+\n     if inclusive:\n         return LooseVersion(have_version) >= LooseVersion(version)\n     else:\n@@ -382,4 +396,4 @@ def _isinstancemethod(cls, obj):\n \n     # This shouldn't happen, though this is the most sensible response if\n     # it does.\n-    raise AttributeError(name)\n+    raise AttributeError(name)\n\\ No newline at end of file\n",
  "model_name_or_path": "CodeAgent-v1"
}
