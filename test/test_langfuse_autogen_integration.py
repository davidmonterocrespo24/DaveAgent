"""
Test de integraciÃ³n Langfuse + AutoGen

Este test verifica que:
1. Langfuse se integra correctamente con AutoGen via OpenLit
2. Las trazas de conversaciones se envÃ­an a Langfuse automÃ¡ticamente
3. Se capturan correctamente las llamadas al LLM
"""
import asyncio
import os
from dotenv import load_dotenv
from langfuse import Langfuse
import openlit

from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient


async def test_autogen_with_langfuse():
    """Test: AutoGen + Langfuse Integration"""
    print("=" * 80)
    print("TEST: IntegraciÃ³n AutoGen + Langfuse")
    print("=" * 80)
    
    # Cargar variables de entorno
    load_dotenv()
    
    try:
        # Step 1: Inicializar Langfuse
        print(f"\nğŸ“Š Paso 1: Inicializando Langfuse...")
        
        # Filtrar spans de AutoGen Runtime
        langfuse = Langfuse(
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            host=os.getenv("LANGFUSE_HOST"),
            blocked_instrumentation_scopes=["autogen SingleThreadedAgentRuntime"]
        )
        
        # Verificar autenticaciÃ³n
        if langfuse.auth_check():
            print("âœ… Langfuse autenticado correctamente")
        else:
            print("âŒ Fallo en autenticaciÃ³n de Langfuse")
            return False
        
        # Step 2: Inicializar OpenLit para instrumentaciÃ³n automÃ¡tica
        print(f"\nğŸ”§ Paso 2: Inicializando OpenLit instrumentation...")
        
        # OpenLit captura automÃ¡ticamente las operaciones de AutoGen
        # y exporta spans de OpenTelemetry a Langfuse
        openlit.init(
            tracer=langfuse._otel_tracer,
            disable_batch=True  # Procesar trazas inmediatamente
        )
        print("âœ… OpenLit inicializado - trazas automÃ¡ticas activadas")
        
        # Step 3: Crear cliente del modelo
        print(f"\nğŸ¤– Paso 3: Creando modelo cliente (DeepSeek)...")
        
        model_client = OpenAIChatCompletionClient(
            model="deepseek-chat",
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url="https://api.deepseek.com",
            model_capabilities={
                "vision": False,
                "function_calling": True,
                "json_output": True,
            }
        )
        
        print("âœ… Modelo cliente creado")
        
        # Step 4: Crear agente
        print(f"\nğŸ‘¤ Paso 4: Creando agente AutoGen...")
        
        agent = AssistantAgent(
            "assistant",
            model_client=model_client,
            system_message="You are a helpful assistant. Keep responses short and concise."
        )
        
        print("âœ… Agente creado")
        
        # Step 5: Ejecutar tarea simple
        print(f"\nğŸ’¬ Paso 5: Ejecutando conversaciÃ³n con agente...")
        print(f"  ğŸ“ Tarea: Say 'Hello World from Langfuse!'")
        
        # OpenLit capturarÃ¡ automÃ¡ticamente esta conversaciÃ³n
        # No necesitamos logging manual - OpenLit lo hace por nosotros
        result = await agent.run(task="Say 'Hello World from Langfuse!'")
        
        print(f"\nâœ… ConversaciÃ³n completada - OpenLit enviÃ³ trazas automÃ¡ticamente")
        
        print(f"\nğŸ“¨ Respuesta del agente:")
        for message in result.messages:
            if message.source != "user":
                print(f"  ğŸ¤– {message.content}")
        
        # Step 6: Cerrar cliente
        print(f"\nğŸ”’ Paso 6: Cerrando conexiones...")
        
        await model_client.close()
        
        # Flush Langfuse para asegurar que se envÃ­en todas las trazas
        langfuse.flush()
        
        print("âœ… Conexiones cerradas")
        print("âœ… Trazas enviadas a Langfuse via OpenLit")
        
        # Resumen
        print(f"\n" + "=" * 80)
        print("âœ… TEST PASADO: IntegraciÃ³n exitosa")
        print("=" * 80)
        print(f"\nğŸ’¡ Verifica tus trazas en el dashboard de Langfuse:")
        print(f"   {os.getenv('LANGFUSE_HOST')}")
        print(f"\nğŸ“Š DeberÃ­as ver (capturado automÃ¡ticamente por OpenLit):")
        print(f"   â€¢ âœ… Traza completa de la conversaciÃ³n")
        print(f"   â€¢ âœ… Llamadas al LLM (DeepSeek) vÃ­a OpenAI API")
        print(f"   â€¢ âœ… Inputs y outputs de cada mensaje")
        print(f"   â€¢ âœ… Tokens usados (prompt + completion)")
        print(f"   â€¢ âœ… Latencia y tiempos de respuesta")
        print(f"   â€¢ âœ… Metadata del agente y modelo")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Error en test: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """Ejecutar test de integraciÃ³n"""
    print("\n" + "ğŸ§ª" * 40)
    print("TEST DE INTEGRACIÃ“N: Langfuse + AutoGen + DeepSeek")
    print("ğŸ§ª" * 40 + "\n")
    
    success = await test_autogen_with_langfuse()
    
    if success:
        print("\nğŸ‰ Â¡Test de integraciÃ³n completado exitosamente!")
    else:
        print("\nâš ï¸ Test fallÃ³. Revisa los errores arriba.")
    
    return success


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
