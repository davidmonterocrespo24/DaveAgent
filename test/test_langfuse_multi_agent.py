"""
Test de conversaciÃ³n multi-agente con Langfuse

Este test verifica que:
1. Se capturan trazas de conversaciones complejas multi-agente automÃ¡ticamente
2. Se rastrean correctamente mÃºltiples llamadas al LLM via OpenLit
3. Se organizan las trazas por agente y tarea
"""
import asyncio
import os
from dotenv import load_dotenv
from langfuse import Langfuse
import openlit

from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination
from autogen_ext.models.openai import OpenAIChatCompletionClient


async def test_multi_agent_conversation():
    """Test: ConversaciÃ³n multi-agente con Langfuse tracing"""
    print("=" * 80)
    print("TEST: ConversaciÃ³n Multi-Agente + Langfuse")
    print("=" * 80)
    
    load_dotenv()
    
    try:
        # Step 1: Inicializar Langfuse
        print(f"\nğŸ“Š Paso 1: Inicializando Langfuse...")
        
        langfuse = Langfuse(
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            host=os.getenv("LANGFUSE_HOST"),
            blocked_instrumentation_scopes=["autogen SingleThreadedAgentRuntime"]
        )
        
        if langfuse.auth_check():
            print("âœ… Langfuse autenticado")
        else:
            print("âŒ Fallo en autenticaciÃ³n")
            return False
        
        # Step 2: Inicializar OpenLit
        print(f"\nğŸ”§ Paso 2: Inicializando OpenLit...")
        openlit.init(tracer=langfuse._otel_tracer, disable_batch=True)
        print("âœ… OpenLit inicializado - captura automÃ¡tica activada")
        
        # Step 3: Crear modelo cliente
        print(f"\nğŸ¤– Paso 3: Creando modelo cliente...")
        
        model_client = OpenAIChatCompletionClient(
            model="deepseek-chat",
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url="https://api.deepseek.com",
            model_capabilities={
                "vision": False,
                "function_calling": True,
                "json_output": True,
            }
        )
        
        print("âœ… Modelo cliente creado")
        
        # Step 4: Crear mÃºltiples agentes
        print(f"\nğŸ‘¥ Paso 4: Creando equipo de agentes...")
        
        # Agente de cÃ³digo
        coder = AssistantAgent(
            "Coder",
            model_client=model_client,
            system_message="""You are a Python coding expert. 
            Write clean, efficient Python code. 
            When done, say TASK_COMPLETED."""
        )
        
        # Agente revisor
        reviewer = AssistantAgent(
            "Reviewer",
            model_client=model_client,
            system_message="""You are a code reviewer. 
            Review code for bugs and best practices. 
            Provide brief feedback. 
            When done, say TASK_COMPLETED."""
        )
        
        print("âœ… Agentes creados: Coder y Reviewer")
        
        # Step 5: Crear equipo
        print(f"\nğŸ¯ Paso 5: Creando RoundRobinGroupChat...")
        
        termination = TextMentionTermination("TASK_COMPLETED") | MaxMessageTermination(6)
        
        team = RoundRobinGroupChat(
            participants=[coder, reviewer],
            termination_condition=termination
        )
        
        print("âœ… Equipo creado")
        
        # Step 6: Ejecutar conversaciÃ³n
        print(f"\nğŸ’¬ Paso 6: Ejecutando conversaciÃ³n multi-agente...")
        print(f"  ğŸ“ Tarea: Write a Python function to calculate fibonacci numbers")
        
        # OpenLit capturarÃ¡ automÃ¡ticamente toda esta conversaciÃ³n
        message_count = 0
        async for message in team.run_stream(
            task="Write a Python function to calculate fibonacci numbers up to n. Keep it short."
        ):
            if hasattr(message, 'source') and message.source != 'user':
                message_count += 1
                print(f"  ğŸ¤– [{message.source}] Mensaje #{message_count}")
        
        print(f"\nâœ… ConversaciÃ³n completada ({message_count} mensajes)")
        print(f"âœ… OpenLit capturÃ³ automÃ¡ticamente {message_count} interacciones")
        
        # Step 7: Cerrar conexiones
        print(f"\nğŸ”’ Paso 7: Cerrando conexiones...")
        await model_client.close()
        langfuse.flush()
        print("âœ… Conexiones cerradas")
        
        # Resumen
        print(f"\n" + "=" * 80)
        print("âœ… TEST PASADO: ConversaciÃ³n multi-agente rastreada exitosamente")
        print("=" * 80)
        print(f"\nğŸ’¡ Verifica en tu dashboard de Langfuse:")
        print(f"   {os.getenv('LANGFUSE_HOST')}")
        print(f"\nğŸ“Š DeberÃ­as ver:")
        print(f"   â€¢ Trazas de ambos agentes (Coder y Reviewer)")
        print(f"   â€¢ MÃºltiples llamadas al LLM")
        print(f"   â€¢ Flujo de conversaciÃ³n completo")
        print(f"   â€¢ Tokens totales utilizados")
        print(f"   â€¢ Latencia de cada llamada")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_multi_agent_with_tools():
    """Test: Multi-agente con herramientas (mÃ¡s complejo)"""
    print("\n" + "=" * 80)
    print("TEST: Multi-Agente con Herramientas + Langfuse")
    print("=" * 80)
    
    load_dotenv()
    
    try:
        # Inicializar Langfuse
        print(f"\nğŸ“Š Inicializando Langfuse...")
        langfuse = Langfuse(
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            host=os.getenv("LANGFUSE_HOST"),
            blocked_instrumentation_scopes=["autogen SingleThreadedAgentRuntime"]
        )
        
        if not langfuse.auth_check():
            print("âŒ Fallo en autenticaciÃ³n")
            return False
        
        # Inicializar OpenLit
        openlit.init(tracer=langfuse._otel_tracer, disable_batch=True)
        print("âœ… OpenLit inicializado")
        
        # Crear modelo
        model_client = OpenAIChatCompletionClient(
            model="deepseek-chat",
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url="https://api.deepseek.com",
            model_capabilities={
                "vision": False,
                "function_calling": True,
                "json_output": True,
            }
        )
        
        # Definir una herramienta simple
        def calculate_sum(a: int, b: int) -> int:
            """Calculate the sum of two numbers."""
            return a + b
        
        # Agente con herramientas
        print(f"\nğŸ¤– Creando agente con herramientas...")
        agent_with_tools = AssistantAgent(
            "MathAgent",
            model_client=model_client,
            tools=[calculate_sum],
            system_message="You are a math assistant. Use the calculate_sum tool when needed."
        )
        
        print("âœ… Agente creado con herramienta calculate_sum")
        
        # Ejecutar tarea
        print(f"\nğŸ’¬ Ejecutando tarea...")
        print(f"  ğŸ“ Tarea: Calculate 15 + 27 using the tool")
        
        result = await agent_with_tools.run(
            task="Calculate 15 + 27 using the calculate_sum tool"
        )
        
        print(f"\nğŸ“¨ Resultado:")
        for message in result.messages[-2:]:  # Ãšltimos 2 mensajes
            if hasattr(message, 'content'):
                print(f"  ğŸ¤– {message.content[:100]}")
        
        # Cerrar
        await model_client.close()
        langfuse.flush()
        
        print(f"\nâœ… TEST PASADO: Agente con herramientas rastreado exitosamente")
        print(f"ğŸ’¡ Dashboard: {os.getenv('LANGFUSE_HOST')}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """Ejecutar todos los tests multi-agente"""
    print("\n" + "ğŸ§ª" * 40)
    print("SUITE DE TESTS: Conversaciones Multi-Agente + Langfuse")
    print("ğŸ§ª" * 40 + "\n")
    
    results = []
    
    # Test 1: ConversaciÃ³n multi-agente bÃ¡sica
    print("\nğŸ”¹ TEST 1: ConversaciÃ³n Multi-Agente")
    results.append(("Multi-Agente BÃ¡sico", await test_multi_agent_conversation()))
    
    # Test 2: Multi-agente con herramientas
    print("\nğŸ”¹ TEST 2: Multi-Agente con Herramientas")
    results.append(("Multi-Agente con Tools", await test_multi_agent_with_tools()))
    
    # Resumen
    print("\n" + "=" * 80)
    print("RESUMEN DE TESTS")
    print("=" * 80)
    
    for test_name, passed in results:
        status = "âœ… PASADO" if passed else "âŒ FALLIDO"
        print(f"{status} - {test_name}")
    
    total_passed = sum(1 for _, passed in results if passed)
    total_tests = len(results)
    
    print(f"\nğŸ“Š Resultados: {total_passed}/{total_tests} tests pasados")
    
    if total_passed == total_tests:
        print("\nğŸ‰ Â¡Todos los tests de multi-agente pasaron!")
        print("ğŸ’¡ Langfuse estÃ¡ capturando correctamente todas las trazas complejas")
    else:
        print("\nâš ï¸ Algunos tests fallaron")
    
    return total_passed == total_tests


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
