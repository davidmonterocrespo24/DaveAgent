"""
Test para verificar que los datos aparecen en el dashboard de Langfuse

Este test crea traces VISIBLES en el dashboard usando la API directa.
"""
import os
from dotenv import load_dotenv
from langfuse import Langfuse
import time
from datetime import datetime


def test_create_visible_trace():
    """Crear una traza que DEFINITIVAMENTE aparezca en el dashboard"""
    print("\n" + "=" * 80)
    print("TEST: Crear Traza Visible en Dashboard de Langfuse")
    print("=" * 80)
    
    load_dotenv()
    
    try:
        # Inicializar Langfuse
        print("\nğŸ“Š Inicializando Langfuse...")
        langfuse = Langfuse(
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            host=os.getenv("LANGFUSE_HOST")
        )
        
        if not langfuse.auth_check():
            print("âŒ AutenticaciÃ³n fallida")
            return False
        
        print("âœ… Langfuse autenticado")
        
        # MÃ‰TODO 1: Crear trace manualmente
        print("\nğŸ“ MÃ©todo 1: Creando trace manual...")
        
        trace = langfuse.trace(
            name="test-trace-manual",
            user_id="user-123",
            metadata={
                "test": "dashboard_visibility",
                "environment": "testing",
                "timestamp": time.time()
            },
            tags=["test", "manual", "visibility"]
        )
        
        print(f"âœ… Trace creado - ID: {trace.id}")
        
        # Agregar una generaciÃ³n al trace
        generation = trace.generation(
            name="test-generation",
            model="deepseek-chat",
            input=[{"role": "user", "content": "Hello from Langfuse test!"}],
            output="This is a test response from DaveAgent",
            metadata={"tokens": 50, "latency_ms": 450}
        )
        
        print(f"âœ… Generation agregada al trace")
        
        # MÃ‰TODO 2: Crear span
        print("\nğŸ“ MÃ©todo 2: Creando span...")
        
        span = trace.span(
            name="test-span",
            input={"action": "test_dashboard"},
            output={"status": "success"}
        )
        
        print(f"âœ… Span creado")
        
        # MÃ‰TODO 3: Crear evento
        print("\nğŸ“ MÃ©todo 3: Creando evento...")
        
        event = trace.event(
            name="test-event",
            metadata={
                "message": "Test event for dashboard",
                "priority": "high"
            }
        )
        
        print(f"âœ… Evento creado")
        
        # MÃ‰TODO 4: Crear score (evaluaciÃ³n)
        print("\nğŸ“ MÃ©todo 4: Creando score...")
        
        langfuse.score(
            trace_id=trace.id,
            name="quality",
            value=0.95,
            comment="Test quality score"
        )
        
        print(f"âœ… Score agregado")
        
        # Flush para asegurar que todo se envÃ­e
        print("\nğŸ”„ Enviando datos a Langfuse...")
        langfuse.flush()
        
        print("âœ… Datos enviados")
        
        # InformaciÃ³n para el usuario
        print("\n" + "=" * 80)
        print("âœ… TEST COMPLETADO - Trace creado exitosamente")
        print("=" * 80)
        print(f"\nğŸ“Š Ve tu trace en el dashboard:")
        print(f"   {os.getenv('LANGFUSE_HOST')}")
        print(f"\nğŸ” Busca por:")
        print(f"   â€¢ Trace ID: {trace.id}")
        print(f"   â€¢ Name: test-trace-manual")
        print(f"   â€¢ User ID: user-123")
        print(f"   â€¢ Tags: test, manual, visibility")
        print(f"\nğŸ’¡ El trace contiene:")
        print(f"   âœ“ 1 Generation (LLM call simulado)")
        print(f"   âœ“ 1 Span (operaciÃ³n)")
        print(f"   âœ“ 1 Event (evento)")
        print(f"   âœ“ 1 Score (evaluaciÃ³n)")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_simple_trace():
    """Crear una traza simple y clara"""
    print("\n" + "=" * 80)
    print("TEST: Crear Traza Simple en Dashboard")
    print("=" * 80)
    
    load_dotenv()
    
    try:
        # Inicializar Langfuse
        print("\nğŸ“Š Inicializando Langfuse...")
        langfuse = Langfuse(
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            host=os.getenv("LANGFUSE_HOST")
        )
        
        if not langfuse.auth_check():
            print("âŒ AutenticaciÃ³n fallida")
            return False
        
        print("âœ… Langfuse autenticado")
        
        # Crear trace simple
        print("\nğŸ“ Creando trace simple...")
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        trace = langfuse.trace(
            name=f"DaveAgent Test - {timestamp}",
            user_id="david-test-user",
            session_id=f"session-{int(time.time())}",
            metadata={
                "test_type": "dashboard_visibility",
                "environment": "testing",
                "framework": "DaveAgent",
                "timestamp": timestamp
            },
            tags=["test", "daveagent", "visibility-check"]
        )
        
        print(f"âœ… Trace creado - ID: {trace.id}")
        print(f"   Name: DaveAgent Test - {timestamp}")
        print(f"   Session: session-{int(time.time())}")
        
        # Agregar una generaciÃ³n (simulando una llamada al LLM)
        print("\nğŸ“ Agregando generation (LLM call)...")
        
        generation = trace.generation(
            name="deepseek-test-call",
            model="deepseek-chat",
            input=[
                {"role": "system", "content": "You are DaveAgent, a helpful AI assistant"},
                {"role": "user", "content": "Hello! Can you see this in Langfuse?"}
            ],
            output="Yes! I can see this trace in the Langfuse dashboard. This is a test from DaveAgent.",
            metadata={
                "tokens_prompt": 25,
                "tokens_completion": 18,
                "tokens_total": 43,
                "latency_ms": 450,
                "cost_usd": 0.0001
            },
            usage={
                "prompt_tokens": 25,
                "completion_tokens": 18,
                "total_tokens": 43
            }
        )
        
        print(f"âœ… Generation agregada")
        
        # Agregar un span (operaciÃ³n)
        print("\nğŸ“ Agregando span...")
        
        span = trace.span(
            name="process-user-query",
            input={"query": "Test query from DaveAgent"},
            output={"result": "success", "response_length": 100},
            metadata={"operation": "query_processing"}
        )
        
        print(f"âœ… Span creado")
        
        # Agregar score
        print("\nğŸ“ Agregando score (evaluaciÃ³n)...")
        
        langfuse.score(
            trace_id=trace.id,
            name="response_quality",
            value=0.95,
            comment="Test score - excellent response"
        )
        
        print(f"âœ… Score agregado")
        
        # Flush
        print("\nğŸ”„ Enviando todo a Langfuse...")
        langfuse.flush()
        time.sleep(2)  # Esperar a que se procese
        
        print("âœ… Datos enviados y procesados")
        
        # InformaciÃ³n
        print("\n" + "=" * 80)
        print("âœ… TEST COMPLETADO")
        print("=" * 80)
        print(f"\nğŸ“Š Abre tu dashboard AHORA:")
        print(f"   {os.getenv('LANGFUSE_HOST')}")
        print(f"\nğŸ” Busca en el dashboard:")
        print(f"   â€¢ Trace Name: 'DaveAgent Test - {timestamp}'")
        print(f"   â€¢ User ID: david-test-user")
        print(f"   â€¢ Tags: test, daveagent, visibility-check")
        print(f"   â€¢ Trace ID: {trace.id}")
        print(f"\nğŸ“¦ El trace contiene:")
        print(f"   âœ“ 1 Generation (llamada a deepseek-chat)")
        print(f"   âœ“ 1 Span (operaciÃ³n de procesamiento)")
        print(f"   âœ“ 1 Score (evaluaciÃ³n de calidad: 0.95)")
        print(f"   âœ“ Metadata completa con tokens y latencia")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False


@observe()
def test_with_decorator():
    """Test usando decorator @observe() - mÃ¡s fÃ¡cil de usar"""
    print("\n" + "=" * 80)
    print("TEST: Usando @observe() Decorator")
    print("=" * 80)
    
    load_dotenv()
    
    try:
        print("\nğŸ“ Ejecutando funciÃ³n decorada con @observe()...")
        
        # Esta funciÃ³n serÃ¡ automÃ¡ticamente rastreada
        result = process_with_langfuse("Hello from decorator!")
        
        print(f"âœ… Resultado: {result}")
        
        # Actualizar el trace actual con metadata
        langfuse_context.update_current_trace(
            name="test-trace-decorator",
            user_id="user-456",
            session_id="session-test-001",
            tags=["decorator", "auto-trace"],
            metadata={"method": "decorator", "framework": "langfuse"}
        )
        
        print("âœ… Trace actualizado con metadata")
        
        # Flush
        from langfuse import Langfuse
        langfuse = Langfuse()
        langfuse.flush()
        
        print("\nâœ… TEST COMPLETADO con @observe()")
        print(f"ğŸ’¡ Busca en el dashboard: session-test-001")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False


@observe()
def process_with_langfuse(message: str) -> str:
    """FunciÃ³n automÃ¡ticamente rastreada por Langfuse"""
    # Simular procesamiento
    time.sleep(0.1)
    
    # Agregar score
    langfuse_context.score_current_observation(
        name="processing_quality",
        value=0.98
    )
    
    return f"Processed: {message}"


def main():
    """Ejecutar todos los tests"""
    print("\n" + "ğŸ”¬" * 40)
    print("SUITE: Tests de Visibilidad en Dashboard de Langfuse")
    print("ğŸ”¬" * 40)
    
    results = []
    
    # Test 1: Trace manual
    results.append(("Trace Manual", test_create_visible_trace()))
    
    # Test 2: Con decorator
    results.append(("Decorator @observe()", test_with_decorator()))
    
    # Resumen
    print("\n" + "=" * 80)
    print("RESUMEN")
    print("=" * 80)
    
    for test_name, passed in results:
        status = "âœ…" if passed else "âŒ"
        print(f"{status} {test_name}")
    
    total_passed = sum(1 for _, passed in results if passed)
    print(f"\nğŸ“Š {total_passed}/{len(results)} tests pasados")
    
    if total_passed == len(results):
        print("\nğŸ‰ Â¡Todos los traces fueron enviados!")
        print(f"\nğŸ“Š Abre tu dashboard ahora:")
        print(f"   {os.getenv('LANGFUSE_HOST')}")
        print(f"\nğŸ” DeberÃ­as ver:")
        print(f"   â€¢ Trace: test-trace-manual (con 4 elementos)")
        print(f"   â€¢ Trace: test-trace-decorator (con @observe)")
        print(f"   â€¢ Session: session-test-001")
    
    return total_passed == len(results)


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
